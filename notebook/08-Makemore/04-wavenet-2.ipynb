{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makemore: Wavenet\n",
    "\n",
    "- [Andrej Karpathy YouTube](https://www.youtube.com/watch?v=t3YJ5hKiMQ0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=6&ab_channel=AndrejKarpathy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "numpy    : 1.26.4\n",
      "pandas   : 2.2.1\n",
      "polars   : 0.20.18\n",
      "torch    : 2.2.2\n",
      "lightning: 2.2.1\n",
      "\n",
      "conda environment: torch_p11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,torch,lightning --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> list[str]:\n",
    "    \"\"\"Load text data from a file and return as a list of strings.\"\"\"\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        # Read all the lines as a list\n",
    "        data: list[str] = f.read().splitlines()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "fp: str = \"../../data/names.txt\"\n",
    "names: list[str] = load_data(file_path=fp)\n",
    "\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary Of Characters And Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_token: str = \".\"\n",
    "characters: list[str] = sorted(set(\"\".join(names)))\n",
    "# Add the special token to the beginning of the list.\n",
    "characters.insert(0, special_token)\n",
    "n_chars: int = len(characters)\n",
    "\n",
    "# Convert text to numbers.\n",
    "text_to_num: dict[str, int] = {text: idx for idx, text in enumerate(characters)}\n",
    "# Convert numbers to text\n",
    "num_to_text: dict[int, str] = {idx: text for text, idx in text_to_num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, TensorDataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def build_dataset(\n",
    "    names: list[str],\n",
    "    special_token: str = \".\",\n",
    "    block_size: int = 3,\n",
    "    print_info: bool = False,\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Builds a dataset of name sequences and their corresponding character indices.\n",
    "\n",
    "    Args:\n",
    "        names (list[str]): A list of names to build the dataset from.\n",
    "        special_token (str, optional): A special token to append to the end of each name. Defaults to \".\".\n",
    "        block_size (int, optional): The size of the context window for each input sequence. Defaults to 3.\n",
    "        print_info (bool, optional): Whether to print information about the dataset generation. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Tensor, Tensor]: A tuple containing the input sequences (X) and their corresponding target indices (Y).\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in names:\n",
    "        if print_info:\n",
    "            print(w)\n",
    "        context: list[int] = [0] * block_size\n",
    "\n",
    "        for ch in w + special_token:\n",
    "            idx: int = text_to_num.get(ch)\n",
    "            X.append(context)\n",
    "            Y.append(idx)\n",
    "\n",
    "            if print_info:\n",
    "                print(\n",
    "                    f\"{''.join([num_to_text.get(i) for i in context])} ---> {num_to_text.get(idx)}\"\n",
    "                )\n",
    "\n",
    "            # Crop and append, like a rolling window\n",
    "            context = context[1:] + [idx]\n",
    "\n",
    "    X: Tensor = torch.tensor(X)\n",
    "    Y: Tensor = torch.tensor(Y)\n",
    "    print(f\"\\n{X.shape=}, {Y.shape=}\")\n",
    "    return (X, Y)\n",
    "\n",
    "\n",
    "def split_data_into_train_dev_test(\n",
    "    data: Tensor | Dataset, test_size: float = 0.05, dev_size: float = 0.1, seed=42\n",
    ") -> tuple[Tensor, ...]:\n",
    "    \"\"\"\n",
    "    Splits a given PyTorch tensor `data` into training, development, and test sets.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "        data (torch.Tensor): The input tensor to be split.\n",
    "        test_size (float, optional): The fraction of the data to use for the test set. Defaults to 0.2.\n",
    "        dev_size (float, optional): The fraction of the data to use for the development set. Defaults to 0.1.\n",
    "        seed (int, optional): The random seed to use for reproducibility. Defaults to 42.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        tuple[torch.Tensor, torch.Tensor, torch.Tensor]: The training, development, and test sets as PyTorch tensors.\n",
    "    \"\"\"\n",
    "    if isinstance(data, Tensor):\n",
    "        X_train, X_test = train_test_split(data, test_size=test_size, random_state=seed)\n",
    "        X_train, X_dev = train_test_split(\n",
    "            X_train, test_size=dev_size, random_state=seed\n",
    "        )\n",
    "        result: tuple[Tensor, ...] = (X_train, X_dev, X_test)\n",
    "    if isinstance(data, Dataset):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data.data,\n",
    "            data.targets,\n",
    "            test_size=test_size,\n",
    "            random_state=seed,\n",
    "            stratify=data.targets,\n",
    "        )\n",
    "        X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "            X_train, y_train, test_size=dev_size, random_state=seed, stratify=y_train\n",
    "        )\n",
    "        result: tuple[Tensor, ...] = (X_train, X_dev, X_test, y_train, y_dev, y_test)\n",
    "\n",
    "    print(f\"{X_train.shape=}; {X_dev.shape=}; {X_test.shape=}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data: Tensor, targets: Tensor) -> None:\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(data.shape={self.data.shape}, \"\n",
    "            f\"target.shape={self.targets.shape=})\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.targets[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1d(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-5, momentum: float = 0.1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # Parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # Buffers (trained with running `momentum update`)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        if self.training:\n",
    "            if x.ndim == 2:\n",
    "                dim: tuple[int] | int = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)\n",
    "            # Calculate the batch mean and variance\n",
    "            x_mean: Tensor = x.mean(dim=dim, keepdim=True)\n",
    "            x_var: Tensor = x.var(dim=dim, keepdim=True)\n",
    "\n",
    "        else:\n",
    "            x_mean = self.running_mean\n",
    "            x_var = self.running_var\n",
    "\n",
    "        # Normalize the input\n",
    "        x_hat: Tensor = (x - x_mean) / (x_var + self.eps).sqrt()\n",
    "        self.output: Tensor = (self.gamma * x_hat) + self.beta\n",
    "\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                # Update running mean and variance\n",
    "                self.running_mean = (\n",
    "                    1 - self.momentum\n",
    "                ) * self.running_mean + self.momentum * x_mean\n",
    "                self.running_var = (\n",
    "                    1 - self.momentum\n",
    "                ) * self.running_var + self.momentum * x_var\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self) -> list[Tensor]:\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "class FlattenConsecutive(nn.Module):\n",
    "    \"\"\"A custom module that flattens consecutive elements in the input tensor along\n",
    "    the second dimension.\"\"\"\n",
    "\n",
    "    def __init__(self, n_c_elements: int) -> None:\n",
    "        \"\"\"\n",
    "        Note:\n",
    "            n_c_elements: the number of consecutive elements to concatenate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_c_elements = n_c_elements\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{__class__.__name__}({self.n_c_elements})\"\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        # B: batch size, L: sequence length, C: number of channels\n",
    "        B, L, C = x.shape\n",
    "        assert (\n",
    "            L % self.n_c_elements == 0\n",
    "        ), f\"The sequence length of the input tensor must be a multiple of {self.n_c_elements}.\"\n",
    "\n",
    "        x = x.view(B, L // self.n_c_elements, C * self.n_c_elements)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "\n",
    "        self.output = x\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self) -> list[Tensor]:\n",
    "        return []\n",
    "\n",
    "\n",
    "class Tanh(nn.Module):\n",
    "    \"\"\"A custom module that applies the hyperbolic tangent activation function to the input tensor.\"\"\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return torch.tanh(x)\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        self.output = torch.tanh(x)\n",
    "        return self.output\n",
    "\n",
    "\n",
    "def calculate_loss_upd(model: Any, X: Tensor, y: Tensor, training: True) -> Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the loss for the given input tensors `X` and `y`.\n",
    "\n",
    "    Args:\n",
    "        model (Any): The model to use for the forward pass.\n",
    "        X (torch.Tensor): The input tensor.\n",
    "        y (torch.Tensor): The target tensor.\n",
    "        training (bool): Indicates whether the model is in training mode or not.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The calculated loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the training mode to False\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, \"training\"):\n",
    "            layer.training = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        logits: Tensor = model(X)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss: Tensor = F.cross_entropy(logits, y)\n",
    "        result: str = (\n",
    "            f\"Training loss: {loss:.4f}\" if training else f\"Validation loss: {loss:.4f}\"\n",
    "        )\n",
    "        print(result)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1!\n",
    "\n",
    "- The current inplementation flattens the entire data into a 2-D array which is not optimal when the block_size is large.\n",
    "- Implement the Wavenet architecture as shown in the diagram below using PyTorch `Linear`, `Embedding` modules and `Sequential` container.\n",
    "\n",
    "```py\n",
    "# e.g. If the block_size is 3\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- Implement the [Wavenet](https://arxiv.org/pdf/1609.03499) architecture shown below:\n",
    "\n",
    "<img src=\"./images/Wavenet.png\" width=\"600\" height=\"300\" alt=\"Wavenet Architecture\">\n",
    "\n",
    "- The input is combined to form several bigrams which are further combined at every layer in the network.\n",
    "  - i.e. if you have 8 characters in the input layer, you will have 4 bigrams (e.g. `ab`, `cd`, `ef`, `gh`).\n",
    "  - `ab` is combined with `cd` to form `abcd`, `ef` is combined with `gh` to form `efgh` and so on.\n",
    "  - finally, `abcd` and `efgh` are combined and used to predict the output.\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "```text\n",
    "Combining each input layer with the next one to form bigrams:\n",
    "\n",
    "FlattenConsecutive(2):   (4, 4, 20)   # i.e. 4 groups (1 2)   (3 4)   (5 6)   (7 8) \n",
    "...\n",
    "FlattenConsecutive(2):   (4, 2, 600)   # i.e. 2 groups (1 2 3 4)   (5 6 7 8) \n",
    "...\n",
    "FlattenConsecutive(2):   (4, 600)   # (4, 1, 600) i.e. 1 group (1 2 3 4 5 6 7 8) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleWavenetModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hidden: int,\n",
    "        n_c_elements: int,\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Embedding(vocab_size, embedding_dim),\n",
    "            # === Input Layer\n",
    "            FlattenConsecutive(n_c_elements),\n",
    "            nn.Linear(embedding_dim * n_c_elements, num_hidden),\n",
    "            BatchNorm1d(num_hidden),\n",
    "            Tanh(),\n",
    "            # === layer 1\n",
    "            FlattenConsecutive(n_c_elements),\n",
    "            nn.Linear(num_hidden * n_c_elements, num_hidden),\n",
    "            BatchNorm1d(num_hidden),\n",
    "            Tanh(),\n",
    "            # === layer 3\n",
    "            FlattenConsecutive(n_c_elements),\n",
    "            nn.Linear(num_hidden * n_c_elements, num_hidden),\n",
    "            BatchNorm1d(num_hidden),\n",
    "            Tanh(),\n",
    "            # === layer 3\n",
    "            nn.Linear(num_hidden, vocab_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x: Tensor = self.layers(x)\n",
    "        return x\n",
    "\n",
    "    def calculate_number_of_parameters(self) -> int:\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "........ ---> e\n",
      ".......e ---> m\n",
      "......em ---> m\n",
      ".....emm ---> a\n",
      "....emma ---> .\n",
      "olivia\n",
      "........ ---> o\n",
      ".......o ---> l\n",
      "......ol ---> i\n",
      ".....oli ---> v\n",
      "....oliv ---> i\n",
      "...olivi ---> a\n",
      "..olivia ---> .\n",
      "\n",
      "X.shape=torch.Size([12, 8]), Y.shape=torch.Size([12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  5],\n",
       "         [ 0,  0,  0,  0,  0,  0,  5, 13],\n",
       "         [ 0,  0,  0,  0,  0,  5, 13, 13],\n",
       "         [ 0,  0,  0,  0,  5, 13, 13,  1],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0, 15],\n",
       "         [ 0,  0,  0,  0,  0,  0, 15, 12],\n",
       "         [ 0,  0,  0,  0,  0, 15, 12,  9],\n",
       "         [ 0,  0,  0,  0, 15, 12,  9, 22],\n",
       "         [ 0,  0,  0, 15, 12,  9, 22,  9],\n",
       "         [ 0,  0, 15, 12,  9, 22,  9,  1]]),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size: int = 8  # size of the context window for each input sequence\n",
    "\n",
    "# 8 characters are required to predict the next character\n",
    "build_dataset(names=names[:2], block_size=block_size, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X.shape=torch.Size([228152, 8]), Y.shape=torch.Size([228152])\n",
      "X_train.shape=torch.Size([195069, 8]); X_dev.shape=torch.Size([21675, 8]); X_test.shape=torch.Size([11408, 8])\n"
     ]
    }
   ],
   "source": [
    "block_size: int = 8  # size of the context window for each input sequence\n",
    "X, y = build_dataset(names=names, block_size=block_size, print_info=False)\n",
    "data: Dataset = MyDataset(X, y)\n",
    "\n",
    "X_train, X_dev, X_test, y_train, y_dev, y_test = split_data_into_train_dev_test(\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =============== DEBUG ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_s.shape = torch.Size([4, 8])\n",
      "X_s = tensor([[ 0,  0,  0,  0,  0,  0,  0,  1],\n",
      "        [ 0,  0,  0,  0,  2,  5, 14, 10],\n",
      "        [ 0,  0,  0,  1, 14, 14,  1, 13],\n",
      "        [ 0,  0, 11,  8,  5, 14,  1, 14]])\n",
      "\n",
      "logits.shape = torch.Size([4, 27])\n",
      "Number of parameters: 19,881\n"
     ]
    }
   ],
   "source": [
    "emb_dim: int = 10  # embedding dimension\n",
    "batch_size: int = 4\n",
    "n_c_elements: int = 2\n",
    "n_nodes: int = 64  # number of hidden nodes\n",
    "idx: Tensor = torch.randint(0, X_train.shape[0], (batch_size,))\n",
    "X_s, y_s = X_train[idx], y_train[idx]\n",
    "print(f\"{X_s.shape = }\")\n",
    "\n",
    "# 4 samples each containing a block size of `block_size`\n",
    "print(f\"{X_s = }\\n\")\n",
    "\n",
    "\n",
    "model: SimpleWavenetModel = SimpleWavenetModel(\n",
    "    num_hidden=n_nodes,\n",
    "    n_c_elements=n_c_elements,\n",
    "    vocab_size=n_chars,\n",
    "    embedding_dim=emb_dim,\n",
    ")\n",
    "logits: Tensor = model(X_s)\n",
    "print(f\"{logits.shape = }\")\n",
    "n_params: int = model.calculate_number_of_parameters()\n",
    "print(f\"Number of parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(27, 10):                                                              (27, 10)\n",
      "FlattenConsecutive(2):                                                          (4, 4, 20)\n",
      "Linear(in_features=20, out_features=64, bias=True):                             (64, 20)\n",
      "BatchNorm1d():                                                                  (4, 4, 64)\n",
      "Tanh():                                                                         (4, 4, 64)\n",
      "FlattenConsecutive(2):                                                          (4, 2, 128)\n",
      "Linear(in_features=128, out_features=64, bias=True):                            (64, 128)\n",
      "BatchNorm1d():                                                                  (4, 2, 64)\n",
      "Tanh():                                                                         (4, 2, 64)\n",
      "FlattenConsecutive(2):                                                          (4, 128)\n",
      "Linear(in_features=128, out_features=64, bias=True):                            (64, 128)\n",
      "BatchNorm1d():                                                                  (4, 64)\n",
      "Tanh():                                                                         (4, 64)\n",
      "Linear(in_features=64, out_features=27, bias=True):                             (27, 64)\n"
     ]
    }
   ],
   "source": [
    "# =============== DEBUG ================\n",
    "# Define a constant for the padding width\n",
    "PADDING_WIDTH: int = 80\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer_str: str = f\"{layer}:\"\n",
    "    try:\n",
    "        shape_str: str = f\"{tuple(layer.weight.shape)}\"\n",
    "    except Exception as e:\n",
    "        # print(f\"Error: {e}\")\n",
    "        shape_str: str = f\"{tuple(layer.output.shape)}\"\n",
    "    print(layer_str.ljust(PADDING_WIDTH) + shape_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 287,099\n",
      "\n",
      "Epoch: 0/120000 | Loss: 3.3661\n",
      "Epoch: 10000/120000 | Loss: 2.5303\n",
      "Epoch: 20000/120000 | Loss: 2.0550\n",
      "Epoch: 30000/120000 | Loss: 2.0839\n",
      "Epoch: 40000/120000 | Loss: 1.9445\n",
      "Epoch: 50000/120000 | Loss: 1.7075\n",
      "Epoch: 60000/120000 | Loss: 1.8154\n",
      "Epoch: 70000/120000 | Loss: 1.9305\n",
      "Epoch: 80000/120000 | Loss: 1.5670\n",
      "Epoch: 90000/120000 | Loss: 1.7447\n",
      "Epoch: 100000/120000 | Loss: 1.8336\n",
      "Epoch: 110000/120000 | Loss: 1.7710\n"
     ]
    }
   ],
   "source": [
    "# This cell took ~12 minutes to run.\n",
    "\n",
    "emb_dim: int = 32  # embedding dimension\n",
    "batch_size: int = 64\n",
    "n_c_elements: int = 2\n",
    "n_nodes: int = 256  # number of hidden nodes\n",
    "epochs: int = 120_000  # number of epochs\n",
    "learning_rate: float = 0.01  # learning rate\n",
    "\n",
    "\n",
    "model: SimpleWavenetModel = SimpleWavenetModel(\n",
    "    num_hidden=n_nodes,\n",
    "    n_c_elements=n_c_elements,\n",
    "    vocab_size=n_chars,\n",
    "    embedding_dim=emb_dim,\n",
    ")\n",
    "n_params: int = model.calculate_number_of_parameters()\n",
    "print(f\"Number of parameters: {n_params:,}\\n\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the scheduler\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[50_000, 100_000], gamma=0.1\n",
    ")\n",
    "\n",
    "# ==== Trainning Loop ====\n",
    "losses_all: list[float] = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Add mini-batches\n",
    "    idx: Tensor = torch.randint(0, X_train.shape[0], size=(batch_size,))\n",
    "    # X, y batch\n",
    "    Xb, yb = X_train[idx], y_train[idx]\n",
    "\n",
    "    # Forward pass\n",
    "    logits: Tensor = model(Xb)\n",
    "    loss: Tensor = F.cross_entropy(logits, yb)\n",
    "\n",
    "    # Backward pass\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # Record the loss\n",
    "    losses_all.append(loss.item())\n",
    "\n",
    "    if (epoch) % 10_000 == 0:\n",
    "        print(f\"Epoch: {epoch}/{epochs} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # if epoch > 50_000:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.7924\n",
      "Validation loss: 1.9734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.9734)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss_upd(model=model, X=X_train, y=y_train, training=True)\n",
    "calculate_loss_upd(model=model, X=X_dev, y=y_dev, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHqCAYAAADLbQ06AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYr0lEQVR4nO3deVxU5f4H8M/MwCzAMGyyCQq4oSK44b7mlplKmZnXcmmxFEqvt83bZnn7YYutFmWllmvademaWbjhiiiKigvubIqCyA7DMHN+fyBjE4goM5wZ+Lxfr3m9ZOacw/ch88Nznuc8j0QQBAFERERklaRiF0BERER3xqAmIiKyYgxqIiIiK8agJiIismIMaiIiIivGoCYiIrJiDGoiIiIrxqAmIiKyYgxqIiIiK8agJqIma+rUqXBychK7DKJaMaiJLGDZsmWQSCQ4fPiw2KWIaurUqZBIJDW+lEql2OUR2QQ7sQsgosZNoVDg+++/r/a+TCYToRoi28OgJiKLsrOzw5NPPil2GUQ2i7e+iUR09OhRjBw5Es7OznBycsKQIUMQHx9vcoxOp8O7776LNm3aQKlUwt3dHf369UNsbKzxmKysLEybNg1+fn5QKBTw8fHB2LFjcfny5Tt+748//hgSiQSpqanVPps7dy7kcjlu3rwJADh37hzGjRsHb29vKJVK+Pn54YknnkB+fr5Zfg5VQwW7d+/G888/D3d3dzg7O2Py5MnGGv7q66+/RseOHaFQKODr64vIyEjk5eVVO+7gwYN46KGH4OrqCkdHR4SGhuLzzz+vdlxmZiYiIiLg5OSEZs2a4eWXX4ZerzdL24jqiz1qIpGcPHkS/fv3h7OzM1599VXY29vj22+/xaBBgxAXF4eePXsCAObNm4fo6Gg8++yz6NGjBwoKCnD48GEcOXIEw4YNAwCMGzcOJ0+exIsvvoiAgABcv34dsbGxSEtLQ0BAQI3f//HHH8err76KtWvX4pVXXjH5bO3atRg+fDhcXV1RXl6OESNGQKvV4sUXX4S3tzcyMzOxefNm5OXlQaPR3LWtOTk51d6Ty+VwdnY2eS8qKgouLi6YN28eUlJSEBMTg9TUVOzatQsSicT483j33XcxdOhQzJgxw3jcoUOHsG/fPtjb2wMAYmNj8fDDD8PHxwezZs2Ct7c3Tp8+jc2bN2PWrFnG76nX6zFixAj07NkTH3/8MbZt24aFCxeiVatWmDFjxl3bRmRxAhGZ3dKlSwUAwqFDh+54TEREhCCXy4ULFy4Y37ty5YqgVquFAQMGGN8LCwsTRo0adcfr3Lx5UwAgfPTRR/dcZ+/evYVu3bqZvJeQkCAAEH766SdBEATh6NGjAgBh3bp193z9KVOmCABqfI0YMcJ4XNXPq1u3bkJ5ebnx/Q8//FAAIGzatEkQBEG4fv26IJfLheHDhwt6vd543KJFiwQAwpIlSwRBEISKigohMDBQaNmypXDz5k2TmgwGQ7X63nvvPZNjunTpUu3nQiQW3vomEoFer8eff/6JiIgIBAUFGd/38fHBP/7xD+zduxcFBQUAABcXF5w8eRLnzp2r8VoqlQpyuRy7du2q8TZxbSZMmIDExERcuHDB+N7PP/8MhUKBsWPHAoCxx/zHH3+gpKTknq4PAEqlErGxsdVeCxYsqHbs9OnTjT1iAJgxYwbs7OywZcsWAMC2bdtQXl6O2bNnQyq9/c/Xc889B2dnZ/z2228AKocULl26hNmzZ8PFxcXke1T1zP/qhRdeMPm6f//+uHjx4j23lcgSGNREIsjOzkZJSQnatWtX7bP27dvDYDAgPT0dAPDee+8hLy8Pbdu2RadOnfDKK6/g+PHjxuMVCgU++OAD/P777/Dy8sKAAQPw4YcfIisr6651jB8/HlKpFD///DMAQBAErFu3zjhuDgCBgYGYM2cOvv/+e3h4eGDEiBH46quv6jw+LZPJMHTo0Gqvzp07Vzu2TZs2Jl87OTnBx8fHONZeNZ7+95+bXC5HUFCQ8fOqXzxCQkLuWp9SqUSzZs1M3nN1db3nX3qILIVBTWTlBgwYgAsXLmDJkiUICQnB999/j65du5o88jR79mycPXsW0dHRUCqVeOutt9C+fXscPXq01mv7+vqif//+WLt2LQAgPj4eaWlpmDBhgslxCxcuxPHjx/Hvf/8bpaWleOmll9CxY0dkZGSYv8ENjI+JkbVjUBOJoFmzZnBwcEBKSkq1z86cOQOpVAp/f3/je25ubpg2bRpWr16N9PR0hIaGYt68eSbntWrVCv/617/w559/Ijk5GeXl5Vi4cOFda5kwYQKOHTuGlJQU/Pzzz3BwcMDo0aOrHdepUye8+eab2L17N/bs2YPMzEx888039974Wvz99n5RURGuXr1qnBDXsmVLAKj2cysvL8elS5eMn7dq1QoAkJycbNb6iMTAoCYSgUwmw/Dhw7Fp0yaTR6iuXbuGVatWoV+/fsZbzzdu3DA518nJCa1bt4ZWqwUAlJSUoKyszOSYVq1aQa1WG4+pzbhx4yCTybB69WqsW7cODz/8MBwdHY2fFxQUoKKiwuScTp06QSqV1un692Lx4sXQ6XTGr2NiYlBRUYGRI0cCAIYOHQq5XI4vvvgCgiAYj/vhhx+Qn5+PUaNGAQC6du2KwMBAfPbZZ9Ue2/rreUS2gI9nEVnQkiVLsHXr1mrvz5o1C//5z38QGxuLfv36YebMmbCzs8O3334LrVaLDz/80Hhshw4dMGjQIHTr1g1ubm44fPgwfvnlF0RFRQEAzp49iyFDhuDxxx9Hhw4dYGdnhw0bNuDatWt44okn7lqjp6cnBg8ejE8++QSFhYXVbnvv2LEDUVFRGD9+PNq2bYuKigosX74cMpkM48aNu+v1KyoqsGLFiho/e+SRR0x+KSgvLze2JSUlBV9//TX69euHMWPGAKi8EzF37ly8++67ePDBBzFmzBjjceHh4caFVaRSKWJiYjB69Gh07twZ06ZNg4+PD86cOYOTJ0/ijz/+uGvdRFZD5FnnRI1S1eNGd3qlp6cLgiAIR44cEUaMGCE4OTkJDg4OwuDBg4X9+/ebXOs///mP0KNHD8HFxUVQqVRCcHCw8P777xsfY8rJyREiIyOF4OBgwdHRUdBoNELPnj2FtWvX1rne7777TgAgqNVqobS01OSzixcvCk8//bTQqlUrQalUCm5ubsLgwYOFbdu23fW6tT2eBUC4dOmSyc8rLi5OmD59uuDq6io4OTkJkyZNEm7cuFHtuosWLRKCg4MFe3t7wcvLS5gxY0a1x7AEQRD27t0rDBs2TFCr1YKjo6MQGhoqfPnllyb1OTo6VjvvnXfeEfjPI1kLiSDwPhARiWvZsmWYNm0aDh06hO7du4tdDpFV4Rg1ERGRFWNQExERWTEGNRERkRXjGDUREZEVY4+aiIjIijGoiYiIrFiTW/DEYDDgypUrUKvVNe6iQ0REZGmCIKCwsBC+vr4mO8HVpMkF9ZUrV0zWUCYiIhJLeno6/Pz8aj2myQW1Wq0GUPnDqVpLmYiIqCEVFBTA39/fmEm1aXJBXXW729nZmUFNRESiqssQLCeTERERWTEGNRERkRVjUBMREVkxBjUREZEVY1ATERFZMQY1ERGRFWNQExERWTEGNRERkRVjUBMREVkxBjUREZEVEzWoo6OjER4eDrVaDU9PT0RERCAlJaXWc5YtWwaJRGLyUiqVDVQxERFRwxI1qOPi4hAZGYn4+HjExsZCp9Nh+PDhKC4urvU8Z2dnXL161fhKTU1toIqJiIgalqibcmzdutXk62XLlsHT0xOJiYkYMGDAHc+TSCTw9va2dHlERESis6ox6vz8fACAm5tbrccVFRWhZcuW8Pf3x9ixY3Hy5Mk7HqvValFQUGDyIiIishVWE9QGgwGzZ89G3759ERIScsfj2rVrhyVLlmDTpk1YsWIFDAYD+vTpg4yMjBqPj46OhkajMb78/f3NVnNyZj5+O34V568Xmu2aREREfyURBEEQuwgAmDFjBn7//Xfs3bsXfn5+dT5Pp9Ohffv2mDhxIubPn1/tc61WC61Wa/y6arPu/Pz8eu9H/a+1x/DfIxl4fWQwXhjYql7XIiKipqOgoAAajaZOWSTqGHWVqKgobN68Gbt3776nkAYAe3t7dOnSBefPn6/xc4VCAYVCYY4yq3GQywAAJeV6i1yfiIhI1FvfgiAgKioKGzZswI4dOxAYGHjP19Dr9Thx4gR8fHwsUGHtVLeCukzHoCYiIssQtUcdGRmJVatWYdOmTVCr1cjKygIAaDQaqFQqAMDkyZPRvHlzREdHAwDee+899OrVC61bt0ZeXh4++ugjpKam4tlnn23w+pX2lUFdyh41ERFZiKhBHRMTAwAYNGiQyftLly7F1KlTAQBpaWmQSm93/G/evInnnnsOWVlZcHV1Rbdu3bB//3506NChoco2UlUFNXvURERkIaIGdV3mse3atcvk608//RSffvqphSq6Nyr7yl8gGNRERGQpVvN4li1ykFf+nsNb30REZCkM6npQyjlGTURElsWgrgeOURMRkaUxqOuhKqj5eBYREVkKg7oeVHJOJiMiIstiUNdD1XPUXJmMiIgshUFdD1WzvssY1EREZCEM6nrgZDIiIrI0BnU9VAV1hUGATm8QuRoiImqMGNT1oJTf/vGxV01ERJbAoK4HuUwKqaTyz1z0hIiILIFBXQ8SiYTLiBIRkUUxqOtJyQllRERkQQzqeuKiJ0REZEkM6noyLiPKW99ERGQBDOp6UnF1MiIisiAGdT2p5ByjJiIiy2FQ1xNXJyMiIktiUNdTVY+aW10SEZElMKjryfh4FseoiYjIAhjU9cTJZEREZEkM6noyPp7FW99ERGQBDOp6cuCsbyIisiAGdT0p5RyjJiIiy2FQ1xMfzyIiIktiUNcTx6iJiMiSGNT1VPUcNWd9ExGRJTCo64m3vomIyJIY1PWk4mQyIiKyIAZ1PXGMmoiILIlBXU9K3vomIiILYlDXEyeTERGRJTGo68mBu2cREZEFMajrqWqMWqcXoNMbRK6GiIgaGwZ1PVWNUQPsVRMRkfkxqOtJYSeFRFL5Z04oIyIic2NQ15NEIrm96AknlBERkZkxqM2Aq5MREZGlMKjNgKuTERGRpTCozYA9aiIishQGtRmo+Cw1ERFZCIPaDKoe0eLqZEREZG6iBnV0dDTCw8OhVqvh6emJiIgIpKSk1Pn8NWvWQCKRICIiwnJF1gFnfRMRkaWIGtRxcXGIjIxEfHw8YmNjodPpMHz4cBQXF9/13MuXL+Pll19G//79G6DS2nEZUSIishQ7Mb/51q1bTb5etmwZPD09kZiYiAEDBtzxPL1ej0mTJuHdd9/Fnj17kJeXZ+FKa8fJZEREZClWNUadn58PAHBzc6v1uPfeew+enp545plnGqKsu1IaH8/iWt9ERGReovao/8pgMGD27Nno27cvQkJC7njc3r178cMPPyApKalO19VqtdBqtcavCwoK6ltqNVU96hJdhdmvTURETZvV9KgjIyORnJyMNWvW3PGYwsJCPPXUU/juu+/g4eFRp+tGR0dDo9EYX/7+/uYq2agqqMs4mYyIiMzMKnrUUVFR2Lx5M3bv3g0/P787HnfhwgVcvnwZo0ePNr5nMFTebrazs0NKSgpatWplcs7cuXMxZ84c49cFBQVmD2vjymQcoyYiIjMTNagFQcCLL76IDRs2YNeuXQgMDKz1+ODgYJw4ccLkvTfffBOFhYX4/PPPawxghUIBhUJh1rr/7vZkMo5RExGReYka1JGRkVi1ahU2bdoEtVqNrKwsAIBGo4FKpQIATJ48Gc2bN0d0dDSUSmW18WsXFxcAqHVc29K41jcREVmKqEEdExMDABg0aJDJ+0uXLsXUqVMBAGlpaZBKrWYovUa3e9ScTEZEROYl+q3vu9m1a1etny9btsw8xdSDkiuTERGRhVh3V9VG3J5MxjFqIiIyLwa1GXAJUSIishQGtRlwUw4iIrIUBrUZ3N7mkpPJiIjIvBjUZqAy3vrmGDUREZkXg9oMqm59l+sNqNAzrImIyHwY1GZQNZkMAMoqGNRERGQ+DGozUNjd/jFyQhkREZkTg9oMJBLJ7R20+IgWERGZEYPaTKomlJWwR01ERGbEoDaT2+t9M6iJiMh8GNRmwh20iIjIEhjUZsIxaiIisgQGtZnw1jcREVkCg9pMlJxMRkREFsCgNhOVfeWPkj1qIiIyJwa1mRjHqNmjJiIiM2JQm4lKbgeAPWoiIjIvBrWZcDIZERFZAoPaTFTyW2PUvPVNRERmxKA2E2OPmkFNRERmxKA2E+WtoC7hrW8iIjIjBrWZuDvJAQDXC8pEroSIiBoTBrWZBHk4AQAuZBeLXAkRETUmDGozCWrmCADIKdKioEwncjVERNRYMKjNRK20h6daAQC4yF41ERGZCYPajKp61ReuF4lcCRERNRYMajMKalY5Tn0xh0FNRETmwaA2o1ZVQc1b30REZCYMajOquvXNoCYiInNhUJtRq1uPaF26UQy9QRC5GiIiagwY1GbU3FUFuZ0U5RUGZN4sFbscIiJqBBjUZiSTShDofmvmNyeUERGRGTCozYyPaBERkTkxqM3MOKEshxPKiIio/hjUZnb7ES32qImIqP4Y1GYWxGepiYjIjBjUZlZ16/t6oRaF3JyDiIjqiUFtZs5KezTj5hxERGQmDGoLCPKomlDGcWoiIqofBrUFVI1TX7jOHjUREdUPg9oCWjVjj5qIiMxD1KCOjo5GeHg41Go1PD09ERERgZSUlFrPWb9+Pbp37w4XFxc4Ojqic+fOWL58eQNVXDet2KMmIiIzETWo4+LiEBkZifj4eMTGxkKn02H48OEoLr5zwLm5ueGNN97AgQMHcPz4cUybNg3Tpk3DH3/80YCV166dtxoAcD67CKXlepGrISIiWyYRBMFqtnnKzs6Gp6cn4uLiMGDAgDqf17VrV4waNQrz58+/67EFBQXQaDTIz8+Hs7Nzfcq9I0EQEP7+duQUafHfGb3RraWbRb4PERHZpnvJIqsao87PzwdQ2WuuC0EQsH37dqSkpNxTsFuaRCJBmJ8GAHA8I1/kaoiIyJbZiV1AFYPBgNmzZ6Nv374ICQmp9dj8/Hw0b94cWq0WMpkMX3/9NYYNG1bjsVqtFlqt1vh1QUGBWeu+k1A/F2w/c51BTURE9WI1QR0ZGYnk5GTs3bv3rseq1WokJSWhqKgI27dvx5w5cxAUFIRBgwZVOzY6OhrvvvuuBSquXah/ZY/6WEZeg39vIiJqPKxijDoqKgqbNm3C7t27ERgYeM/nP/vss0hPT69xQllNPWp/f3+LjlEDQG5xObrOjwUAHJ83HM5Ke4t9LyIisi02M0YtCAKioqKwYcMG7Nix475CGqi8bf7XMP4rhUIBZ2dnk1dDcHOUw89VBQBI5u1vIiK6T6Le+o6MjMSqVauwadMmqNVqZGVlAQA0Gg1UqsqQmzx5Mpo3b47o6GgAlbeyu3fvjlatWkGr1WLLli1Yvnw5YmJiRGvHnYT5uSDjZimOZeSjT2sPscshIiIbJGpQV4Xr38eWly5diqlTpwIA0tLSIJXe7vgXFxdj5syZyMjIgEqlQnBwMFasWIEJEyY0VNl1FuqnwW8nruI4x6mJiOg+WcUYdUNqiOeoqxy4cAMTv4tHcxcV9r3+gEW/FxER2Q6bGaNu7Dr5aSCRAJl5pcgpqnkMnYiIqDYMagtyUtgZ1/3m7W8iIrofDGoLC721QtmxdM78JiKie8egtrDQ5lVLieaJWwgREdkkBrWFhfq7AKhc87uJzdsjIiIzYFBbWAcfZ9hJJbhRXI7MvFKxyyEiIhvDoLYwpb0MwT6V+1Nzgw4iIrpXDOoGEOrnAgA4lp4nah1ERGR7GNQNoHNVUHNCGRER3SMGdQOo2vLyREY+9AZOKCMiorpjUDeANp5qOMhlKC7X42J2kdjlEBGRDWFQNwCZVIIQ38pedRLHqYmI6B4wqBtI1QplnPlNRET3gkHdQMJuLXzCCWVERHQvGNQNJOzWzO/TVwugrdCLWwwREdkMBnUD8XdTwdXBHjq9gNNXC8Uuh4iIbASDuoFIJBLjwifcoIOIiOqKQd2AqsapOfObiIjqikHdgMI485uIiO4Rg7oBVd36vpBdhMIynbjFEBGRTWBQN6BmagWau6ggCLz9TUREdcOgbmC9gtwBAHvP5YhcCRER2QIGdQMb0NYDABB3NlvkSoiIyBYwqBtY/zbNIJEAZ7IKkZVfJnY5RERk5RjUDczNUW6cVLabvWoiIroLBrUIBrZtBgCIO8egJiKi2jGoRVAV1HvP5aBCbxC5GiIismYMahGE+WmgUdkjv1SHY1z8hIiIasGgFoGdTIp+rStnf3OcmoiIasOgFolxnJpBTUREtWBQi2TAraA+lpGHm8XlIldDRETWikEtEm+NEsHeaggCsOc8VykjIqKaMahF1PfWOPWhS7kiV0JERNaKQS2iri1cAQBH0m6KXAkREVkrBrWIurZ0AVC5nGhJeYW4xRARkVViUIvIR6OCj0YJvUHAsXQ+T01ERNUxqEVWdfv7aDpvfxMRUXUMapF1aeECADiSmidqHUREZJ0Y1CLrUtWjTrsJQRBEroaIiKwNg1pkIc2dIZdJcaO4HGm5JWKXQ0REVoZBLTKFnQwdmzsD4GNaRERUHYPaChifp+Y4NRER/Q2D2gpUTSjjzG8iIvo7UYM6Ojoa4eHhUKvV8PT0REREBFJSUmo957vvvkP//v3h6uoKV1dXDB06FAkJCQ1UsWVU9ahPX+XCJ0REZErUoI6Li0NkZCTi4+MRGxsLnU6H4cOHo7i4+I7n7Nq1CxMnTsTOnTtx4MAB+Pv7Y/jw4cjMzGzAys3L10UFb+fKhU+OZ3DhEyIiuk0iWNEzQdnZ2fD09ERcXBwGDBhQp3P0ej1cXV2xaNEiTJ48+a7HFxQUQKPRID8/H87OzvUt2WxmrkzElhNZeKRLc0zpE4BgbzWU9jKxyyIiIgu4lyyya6Ca6iQ/v7I36ebmVudzSkpKoNPp7niOVquFVqs1fl1QUFC/Ii0kPMANW05kYcPRTGw4mgk7qQQvDGyFl0e0E7s0IiISkdVMJjMYDJg9ezb69u2LkJCQOp/32muvwdfXF0OHDq3x8+joaGg0GuPL39/fXCWb1YRwf/xzaFsMaNsMbo5yVBgELNp5HompnGBGRNSUWc2t7xkzZuD333/H3r174efnV6dzFixYgA8//BC7du1CaGhojcfU1KP29/e3ulvffyUIAl7773GsPZyBLi1csH5GH0gkErHLIiIiM7mXW99W0aOOiorC5s2bsXPnzjqH9Mcff4wFCxbgzz//vGNIA4BCoYCzs7PJy9pJJBK8PLwdHOQyHE3Lw28nropdEhERiUTUoBYEAVFRUdiwYQN27NiBwMDAOp334YcfYv78+di6dSu6d+9u4SrF4emsxPMDWgEAFvx+BmU6vcgVERGRGEQN6sjISKxYsQKrVq2CWq1GVlYWsrKyUFpaajxm8uTJmDt3rvHrDz74AG+99RaWLFmCgIAA4zlFRUViNMGinhsQCC9nBTJuluLH/ZfFLoeIiEQgalDHxMQgPz8fgwYNgo+Pj/H1888/G49JS0vD1atXTc4pLy/HY489ZnLOxx9/LEYTLMpBboeXh1fO+l608zx71URETZCoj2fVZR7brl27TL6+fPmyZYqxUuO6+uGT2LO4ml+Gg5dyMbBtM7FLIiKiBmQVk8nozqRSiTGc41KyRa6GiIgaGoPaBhiD+ux1kSshIqKGxqC2AX1ae0AmleBCdjHSc0vELoeIiBoQg9oGaFT26OLvAgDYfY63v4mImhIGtY2ouv29+yyDmoioKWFQ24iB7SqDet/5G9DpDSJXQ0REDYVBbSNCfDVwc5SjSFuBI9yog4ioybivoE5PT0dGRobx64SEBMyePRuLFy82W2FkSiqVYEAbDwBA3K3b30npefh+z0UuhEJE1Ijd14In//jHPzB9+nQ89dRTyMrKwrBhw9CxY0esXLkSWVlZePvtt81dJwEY0LYZNiZdwdaTWUi9UWLcrEOnFzBjUCuRqyMiIku4rx51cnIyevToAQBYu3YtQkJCsH//fqxcuRLLli0zZ330F/3bVI5TX8wuNtlR6+ClG2KVREREFnZfQa3T6aBQKAAA27Ztw5gxYwAAwcHBJutyk3k1UyvQr3Xl7e+BbZth4fgwAEBi6k0YDFaxrTgREZnZfd367tixI7755huMGjUKsbGxmD9/PgDgypUrcHd3N2uBZCrmya64UVSOAA9HVOgNeGtTMgrLKnD2eiGCva1/r20iIro399Wj/uCDD/Dtt99i0KBBmDhxIsLCKnt2v/76q/GWOFmGWmmPAA9HAICdTIouLVwAAIcvcyY4EVFjdF896kGDBiEnJwcFBQVwdXU1vj99+nQ4ODiYrTi6u24t3bDv/A0kpt7Ek71ail0OERGZ2X31qEtLS6HVao0hnZqais8++wwpKSnw9PQ0a4FUu/CAyv8Ghy7nilwJERFZwn0F9dixY/HTTz8BAPLy8tCzZ08sXLgQERERiImJMWuBVLsuLVwhlQAZN0txraBM7HKIiMjM7iuojxw5gv79+wMAfvnlF3h5eSE1NRU//fQTvvjiC7MWSLVzUtgZJ5FxnJqIqPG5r6AuKSmBWq0GAPz555949NFHIZVK0atXL6Smppq1QLq77rz9TUTUaN1XULdu3RobN25Eeno6/vjjDwwfPhwAcP36dTg78xGhhtY9wA1A5fPURETUuNxXUL/99tt4+eWXERAQgB49eqB3794AKnvXXbp0MWuBdHfdW1b2qE9dLUCxtkLkaoiIyJzu6/Gsxx57DP369cPVq1eNz1ADwJAhQ/DII4+YrTiqG18XFXw1SlzJL0NSeh763lq9jIiIbN99b3Pp7e2NLl264MqVK8adtHr06IHg4GCzFUd11+3W7e8953JEroSIiMzpvoLaYDDgvffeg0ajQcuWLdGyZUu4uLhg/vz5MBgM5q6R6qBqC8xv4i7g27gLEASu/U1E1Bjc163vN954Az/88AMWLFiAvn37AgD27t2LefPmoaysDO+//75Zi6S7e7SrH5Iz8/HjgVRE/34GqbkleG9MR9jJ7vumCRERWQGJcB9dL19fX3zzzTfGXbOqbNq0CTNnzkRmZqbZCjS3goICaDQa5OfnN8oZ6kv2XsL8305BEACJBJBJJJBKJegR4IZl08IZ3EREVuBesui+/tXOzc2tcSw6ODgYubl8lldMT/cLxLdPdoNaaQdBACoMAsorDNh7PgfbTl8TuzwiIrpH9xXUYWFhWLRoUbX3Fy1ahNDQ0HoXRfUzvKM3Dr0xFAlvDEH83CF4tl8gAOCHvZdEroyIiO7VfY1Rf/jhhxg1ahS2bdtmfIb6wIEDSE9Px5YtW8xaIN0fpb0MSnsZAOC5AUFYtv8yDl2+ieMZeQj1cxG3OCIiqrP76lEPHDgQZ8+exSOPPIK8vDzk5eXh0UcfxcmTJ7F8+XJz10j15OWsxMOhPgCApfsui1sMERHdk/uaTHYnx44dQ9euXaHX6811SbNr7JPJ7uRERj5GL9oLO6kE+15/AF7OSrFLIiJqsiw+mYxsTyc/DcIDXFFhELD8ADdOISKyFQzqJuTpvpWTylYeTMWF7CKRqyEiorpgUDchwzt6o6W7A26W6DDskzjMWZuE1BvFYpdFRES1uKdZ348++mitn+fl5dWnFrIwmVSCZdN64P3fTmPb6WtYfyQT649kQq20g5ezEj4aJWYPbYNuLd3ELpWIiG65p6DWaDR3/Xzy5Mn1KogsK9DDEd9P6Y5j6Xn4JPYs4s5mo7CsAoVlRTh/vQiZeaWI/edAyKQSsUslIiKYeda3LWiqs77vpKBMh+sFZbiaX4YXVx9FXokOnzwehke7+oldGhFRo8VZ31Rnzkp7tPZUo3+bZpg+IAgA8Pn2c6jQcxc0IiJrwKAmoym9A+DuKEfqjRKsP2K9G6sQETUlDGoyclTY4YWBrQAAX+w4h/IK9qqJiMTGoCYTT/ZqCQ8nBTJulmJ5PBdGISISG4OaTKjkMswcVNmrnr/5FCK+2ofNx69wzJqISCQMaqrmyV4tMbl3S8hlUiSl5yFq1VGM+mIvrheUiV0aEVGTI2pQR0dHIzw8HGq1Gp6enoiIiEBKSkqt55w8eRLjxo1DQEAAJBIJPvvss4YptgmR20nx3tgQ7Hv9Acwa0gauDvZIuVaIJ76LZ1gTETUwUYM6Li4OkZGRiI+PR2xsLHQ6HYYPH47i4jsva1lSUoKgoCAsWLAA3t7eDVht09NMrcA/h7XFpsh+aO6iwsXsYjyxmGFNRNSQrGrBk+zsbHh6eiIuLg4DBgy46/EBAQGYPXs2Zs+eXefvwQVP7k96bgmeWByPzLxSBHk4Ytm0Hmjh7iB2WURENslmFzzJz88HALi5ca1pa+Pv5oA103tV9qxzihHx9T4kXMoVuywiokbPaoLaYDBg9uzZ6Nu3L0JCQsx2Xa1Wi4KCApMX3R9/Nwf8d0YfdGquQW5xOSZ9H4+1h9PFLouIqFGzmqCOjIxEcnIy1qxZY9brRkdHQ6PRGF/+/v5mvX5T461RYu3zvTGqkw90egGv/nIci3dfELssIqJGyyqCOioqCps3b8bOnTvh52fezSDmzp2L/Px84ys9nT3A+lLJZfhyYhdEDW4NAPi/LWew6mCayFURETVO97TNpbkJgoAXX3wRGzZswK5duxAYGGj276FQKKBQKMx+3aZOKpXg5RHtoBcExOy6gDc2noCjQoaxnZuLXRoRUaMialBHRkZi1apV2LRpE9RqNbKysgBU7mutUqkAAJMnT0bz5s0RHR0NACgvL8epU6eMf87MzERSUhKcnJzQunVrcRrShL06oh2KyiqwPD4V/1p7DBqVPQa18xS7LCKiRkPUx7MkEkmN7y9duhRTp04FAAwaNAgBAQFYtmwZAODy5cs19rwHDhyIXbt23fV78vEs8zMYBPxr3TFsOJoJd0c5/vjnAHg48S4GEdGd3EsWWdVz1A2BQW0Z2go9xi7ahzNZhRja3gvfTe52x1/EiIiaOpt9jppsl8JOhk8ndIZcJsW209ew7nCG2CURETUKDGoym/Y+zpgzvC0A4N3/nUR6bonIFRER2T4GNZnVc/2DEB7giuJyPaJWHUGxtkLskoiIbBqDmsxKJpVg4fjO0KjscSwjHy+sSIS2Qi92WURENotBTWbXwt0BS6eFw0Euw55zOZi9JgkVegOOZ+Thkz9T8OHWMyivMIhdJhGRTeCsb7KYvedy8PSyQyjXG+CksEPRX26DzxrSBv8c1lbE6oiIxMNZ32QV+rXxwBcTO0MqAYq0FXCQy9CnlTsA4Kud53EmixukEBHdDXvUZHHH0vNQUKZDeIAbFHZSPL88EX+euoZQPw3Wz+gDOxl/XySipoU9arIqYf4u6N+mGZT2MkgkEvwnIgRqpR2OZ+Tjh72Xqh1foTfgs21nsfZwOvSGJvV7JBFRNQxqanCezkq8NaoDAOCT2LO4nFNs8vn/jl/BZ9vO4dVfjuORr/chKT1PhCqJiKwDg5pEMb67H/q0coe2woAV8akmn/158prxz8cz8vHI1/sQ/fvphi6RiMgqMKhJFBKJBFP6BAAAfjtxFYZbt7jLdHrEnc0GACyZ2h2Pdm0OQQC+jbuIk1fyxSqXiEg0DGoSzcC2zaBW2OFqfhkS024CAPZfyEFJuR4+GiUGt/PEJ493xsOhPgCA5QdSa7scEVGjxKAm0SjtZRjW0QsAsPnYFQC3b3sP7+Bl3H2rque9MSkTeSXlDV8oEZGIGNQkqtFhvgCA305kobzCgG2nK4N6WAdv4zHdW7oi2FuNMp2Bu3IRUZPDoCZR9WvtARcHe+QUafFN3AXkFJVDrbRDzyA34zF/Hc9eHp9qHM8mImoKGNQkKnuZFCNDKnvPX+44BwAYEuwJ+78tgjK2sy+clXZIyy0xTjY7ces57F8SM7Ar5TrOXStEE1u/h4iaADuxCyB6ONQXqxPSodNXhuzwjt7VjnGQ2+Hx7v74fu8lfPRHCj7bfg7Hani+elxXP3z0WCikUomlyyYiahDsUZPoegW5w8NJAQCQ20kxoG2zGo97sldLSCTAqasFOJaeB7lMigeCPdG/jQfa+zhDJpXgv0cy8N7mU+xZE1GjwR41iU4mlWBUJ2/8eCAVfVu5w0lR81/LAA9HPNc/CLvPZmNMZ1883t3fGPAAsPFoJmb/nIRl+y/DzVGOl4a0aagmEBFZDDflIKtwo0iLz7efw+TeAWjt6XTf11m27xLm/e8UAGD+2I54qneAmSokIjIfbspBNsfdSYH3xobUK6QBYGrfQMy61ZN++9eT+P3EVXOUR0QkGgY1NTqzh7bBpJ4tIAjArJ+TcPDiDbFLIiK6bwxqanQkEgneGxuC4R28UF5hwLM/HUZKVqHJMYIgYFNSJl5edwzXC8pEqpSI6O4Y1NQoyaQSfDGxC7q3dEVhWQXGf7Mf38ZdQJlOj8IyHf75cxJmrUnCL4kZmLv+BGeJE5HV4mQyatTySsoxeUkCjmdU7rzlq1HCTiZFWm4JZFIJJAAqDAK+faobRtTw/DYRkSVwMhnRLS4OcmyY2RcfPRYKH40SV/LLkJZbguYuKqx9vhemDwgCAMz79SSKtRU1XsNgEKDnsqVEJBI+R02Nnkwqwfju/hgd5ouVB9NwraAMkYNbQ6OyRwcfDX49dgUZN0vx+fZz+PdD7U3OPX21AM/+eBjuTnKsfq4XHO/wjDcRkaWwR01NhtJehmf6BeLfD7WHRmUPAFDJZZg/NgQA8MPeS9h/Icd4/NG0m5jw7QFk5pXieEY+5m8+JUrdRNS0MaipyRsc7IkHO3pDbxDwj+8OYuLiePy4/zKe/P4gCsoq0M5LDYkEWHMoHVuTs8z2fc9fL8TXu86jvMJgtmsSUePDoCYC8MG4UIzr6gc7qQQHLt7AO7+eRHG5Hn1auWP9zD54fkArAMDc9cdxrYbHucp0ehzPyENpud7k/dzicsz79SRidl0wmVleptNj6tJD+HBrCtYlplu2cURk0zjgRgRA42CPhY+HYc7wtvhhzyWsPZyO/m088OmEzlDayzBnWFvsPZ+N5MwCRK06gmf6BaKjrwYSCbAiPg1rDqUhr0QHH40Srz7YDmPDmmPP+Ry8vO4Ysgu1AABvjQKPdPEDAHy96wIybpYCAPZfuIFJPVuK1nYism58PIuoBoIgQCIx3Srz/PUiPPzlHpTpar5VbSeVoOLW7PCW7g5IvVECANCo7JFfqoNaYYcts/rDIAgY9ulu4y1vDyc5Dr0xtNr3I6LGi49nEdVTTaHZ2tMJq57rhSfC/RHS3Bn2sspjege549unuuH4vOF49cF2cFLYGUN6ap8A7H/9gcqFV7QVmP1zEub9ehLlFQb0DnKHwk6KnKJyXMguatD2EZHtYI+a6D6VVxhQpK2Am6Pc5P3sQi3WJKShW0tX9GntAQBIzy3BQ5/vQeGtZ7XtZRJsnT0Ab21Mxv4LNzA/IgRP9eLtb6Kmgj1qogYgt5NWC2kAaKZW4MUhbYwhDQD+bg54L6Kj8etn+wehVTMn9Ax0BwBuHEJEd8TJZEQNJKJzc5y/XoQL14vx4gOtAQC9gtwAAPEXc2scFyciYlATNRCJRIJXRgSbvBfm73JrnFqLC9nF9d6Pm4gaH976JhKR0l6GLi1cAAAHL/H2NxFVx6AmElmvoMpx6viLuSJXQkTWiEFNJLLbQX0DgiCgTKfHpqRMpN4oNjlObxDwxfZzmLv+OAzczYuoyeAYNZHIOvu7QG4nRXahFl9sP481h9JwNb8MjnIZPpnQGSM6ekNbocectcfw2/GrAIApfQIQ7M3HC4maAgY1kciU9jJ08XfBwUu5+HTbWQCVj34Vl+vx/PJERA1ujaPpN7Hv/O0x7PwSnVjlElEDE/XWd3R0NMLDw6FWq+Hp6YmIiAikpKTc9bx169YhODgYSqUSnTp1wpYtWxqgWiLLGdbBCwDg6mCPN0e1x9G3hmFa3wAAwKKd57Hv/A04ymXwcKp8bruwrEKsUomogYka1HFxcYiMjER8fDxiY2Oh0+kwfPhwFBcX3/Gc/fv3Y+LEiXjmmWdw9OhRREREICIiAsnJyQ1YOZF5TesbiDXTeyHu1cF4tn8QHBV2eGd0RywcHwa5nRTujnKsnt4L7X0qb3cXlLFHTdRUWNUSotnZ2fD09ERcXBwGDBhQ4zETJkxAcXExNm/ebHyvV69e6Ny5M7755pu7fg8uIUq25kaRFgp7GZwUdpi5MhFbTmTh3TEdMaVPgNilEdF9stklRPPz8wEAbm5udzzmwIEDGDp0qMl7I0aMwIEDB2o8XqvVoqCgwORFZEvcnRRwUlROJ3FW2gMACkrZoyZqKqwmqA0GA2bPno2+ffsiJCTkjsdlZWXBy8vL5D0vLy9kZWXVeHx0dDQ0Go3x5e/vb9a6iRqSWlkZ2FWbexBR42c1QR0ZGYnk5GSsWbPGrNedO3cu8vPzja/09HSzXp+oIalv9agLOUZN1GRYxeNZUVFR2Lx5M3bv3g0/P79aj/X29sa1a9dM3rt27Rq8vb1rPF6hUEChUJitViIxOd/qUReUskdN1FSI2qMWBAFRUVHYsGEDduzYgcDAwLue07t3b2zfvt3kvdjYWPTu3dtSZRJZjaoeNWd9EzUdovaoIyMjsWrVKmzatAlqtdo4zqzRaKBSqQAAkydPRvPmzREdHQ0AmDVrFgYOHIiFCxdi1KhRWLNmDQ4fPozFixeL1g6ihuKsqgpq9qiJmgpRe9QxMTHIz8/HoEGD4OPjY3z9/PPPxmPS0tJw9epV49d9+vTBqlWrsHjxYoSFheGXX37Bxo0ba52ARtRYGCeTsUdN1GSI2qOuyyPcu3btqvbe+PHjMX78eAtURGTdbj+exR41UVNhNbO+ieju2KMmanoY1EQ2pGqMWlthgLZCL3I1RNQQGNRENqRqhTKAG3MQNRUMaiIbIpNKjGHNoCZqGhjURDbm9qInHKcmagoY1EQ25vYyouxREzUFDGoiG+OsutWj5sxvoiaBQU1kY7gxB1HTwqAmsjHcmIOoaWFQE9kY9qiJmhYGNZGNqVqdjBtzEDUNDGoiG3N7By32qImaAgY1kY25vd43e9RETQGDmsjG3N5Biz1qoqaAQU1kY9ijJmpaGNRENoZj1ERNC4OayMY4s0dN1KQwqIlsjPNfnqMWBEHkaojI0hjURDamasETgwAUl+tFroaILI1BTWRjlPZS2EklALg6GVFTwKAmsjESieT2hDKu903U6DGoiWzQ7Ue02KMmauwY1EQ2yLjoCYOaqNFjUBPZIC56QtR0MKiJbBCXESVqOhjURDaIW10SNR0MaiIbxGVEiZoOBjWRDeIYNVHTwaAmskFq4zKiDGqixo5BTWSDqjbm4GQyosaPQU1kg9R/2ZiDiBo3BjWRDXJWcdY3UVPBoCayQc7sURM1GQxqIht0e8ET9qiJGjsGNZENqno8q1Snh05vELkaIrIkBjWRDXK6FdQAUMRxaqJGjUFNZIPsZVI4yGUAuDoZUWPHoCayUVydjKhpYFAT2SjuoEXUNDCoiWwUd9AiahoY1EQ2qplaAQBIvVEsciVEZEkMaiIbFR7gBgCIv3hD5EqIyJJEDerdu3dj9OjR8PX1hUQiwcaNG+96zldffYX27dtDpVKhXbt2+OmnnyxfKJEV6t3KHQCQcCmXz1ITNWKiBnVxcTHCwsLw1Vdf1en4mJgYzJ07F/PmzcPJkyfx7rvvIjIyEv/73/8sXCmR9Wnv7QwXB3sUl+txIjNf7HKIyELs7n6I5YwcORIjR46s8/HLly/H888/jwkTJgAAgoKCcOjQIXzwwQcYPXq0pcokskpSqQS9At2x9WQWDly4ga4tXMUuiYgswKbGqLVaLZRKpcl7KpUKCQkJ0OlqfkRFq9WioKDA5EXUWFTd/j5wgePURI2VTQX1iBEj8P333yMxMRGCIODw4cP4/vvvodPpkJOTU+M50dHR0Gg0xpe/v38DV01kOX1uBfXh1FxoK/QiV0NElmBTQf3WW29h5MiR6NWrF+zt7TF27FhMmTIFACCV1tyUuXPnIj8/3/hKT09vyJKJLKq1pxM8nBQo0xmQlJYndjlEZAE2FdQqlQpLlixBSUkJLl++jLS0NAQEBECtVqNZs2Y1nqNQKODs7GzyImosJBLJ7dvffEyLqFGyqaCuYm9vDz8/P8hkMqxZswYPP/zwHXvURI1d76DKoN7PcWqiRknUWd9FRUU4f/688etLly4hKSkJbm5uaNGiBebOnYvMzEzjs9Jnz55FQkICevbsiZs3b+KTTz5BcnIyfvzxR7GaQCS6qnHqpLQ8lOn0UNrLRK6IiMxJ1G7o4cOH0aVLF3Tp0gUAMGfOHHTp0gVvv/02AODq1atIS0szHq/X67Fw4UKEhYVh2LBhKCsrw/79+xEQECBG+URWoaW7A3w0SpTrDUhMvSl2OURkZhJBEASxi2hIBQUF0Gg0yM/P53g1NRpzfk7C+qOZeH5gEOaObC92OUR0F/eSRRzYJWoEHmjvCQD47fhVNLHfvYkaPQY1USMwtL0XnBR2yLhZytvfRI0Mg5qoEVDayzCiozcAYGNSpsjVEJE5MaiJGomxnX0BVN7+5m5aRI0Hg5qokejTyh0eTgrcLNFh99nsGo+Z9+tJPPXDQRRrKxq4OiK6XwxqokbCTibF6DAfAMDGpCvVPj9/vQjL9l/GnnM5WJ2QVu1zIrJODGqiRiSic3MAQOypLBT9rde87vDtde4X777ITTyIbASDmqgRCfXTIMDdAWU6A2JPZRnf1+kN+O+RDACAvUyC64Va/DexfpPO8kt0SEzNrdc1iOjuGNREjYhEIsHYW73qZftToTdUPlO988x15BSVw8NJgVdHBAMAvom7gIp6TDqbszYJ42IO4I+TWXc/mIjuG4OaqJF5ooc/nBR2OJaeh293XwAArL1123tc1+Z4sldLuDnKkZZbgs3HrxrPyy0ux+6z2fh613n88+ck/FlLAOeVlGPXrQlrqw5yvJvIkkTdlIOIzM9Ho8K8MR3x8rpj+DT2LNp7O2NnSmWoju/uD5Vchmf6BeKjP1LwxfZzSErPw77zOTh3vcjkOhuTMjF/bAie7NWy2vfYcea6sbe+51w2svLL4K1RWr5xRE0Qe9REjdC4rs0xoqMXdHoBz/10GHqDgG4tXdHa0wkA8GSvllAr7HAxpxjL9l82hnSghyMeDvXBgx29IQjAmxuTsWjHuWrLkv558prxzwYBWH80o+EaR9TEsEdN1AhJJBL83yOdkJiah5wiLQBgQnd/4+calT3eGt0BK+JT0am5Bv1ae6BXkDtcHeUAAEEQsPDPs1i08zw+/vMsSsr1ePXByrHtMp0ecbdue0/u3RI/HUjFL4kZmDGwFSQSSQO3lKjxY4+aqJFyd1Lgw8c6AQDUSjuMCvUx+fzx7v74Naof3n+kE0Z28jGGNFAZ9C+PaIc3R1XuxPX1rgs4mla5hvjeczko1enhq1HilRHtoLKX4WJ2MY6m5zVMw4iaGAY1USP2QLAXVj3bE6uf6wVHxb3fQHu2fxAe6+YHAHhv8ykIgoA/bz32NayDF9RKe4zsVLnG+LrDlbe/T17JxyvrjmFrMmeDE5kDb30TNXJ9WnvU6/xXRrTDlhNXcTQtDxuTMrHt9HUAwPBbm4A81s0P649kYvOxKwAErDmUDkEA1iVm4JUR7TBzEG+JE9UHe9REVCsvZyVmDmoFAPj3+mTkFpfDWWmHHoFuAIBege7wc1WhUFuB1QmVIR3mpwEAfPRHCl7/74m7bhJSUKbDz4fScL2wzLKNIbJBDGoiuqtn+wehuYsKpbrKZUeHtPeCvazynw+pVIJpfQMBAB19nbH2+d7YFNUP743tCKkE+PlwOqYsSUB2obbGaxsMAp7/KRGv/fcEhiyMw+qENBgMQo3H3snBizcwZtFevLj6KH7cfxnJmfkoLNNVm61OZIskQhP7m1xQUACNRoP8/Hw4OzuLXQ6Rzdh8/AqiVh0FAMRM6oqRnW5PThMEARk3S+HrooJMevs297ZT1/Di6qMo1enh4aTAZxM6o18b01vx3++5iP/8dtrkvR4Bbni0a3O4Oyng5ihHSHNnKOxkd6xt4uJ4HLh4o9r79jIJXB3kiOjSHP9+qP19tftOfjpwGbGnruHDx0Lho1GZ9drU+N1LFjGoiahOBEHAnLXHkJlXih+n9YBKfufg/Ktz1woRteooUq4VQiIBXhjYCpGDW8NJYYczWQUY8+U+lOsNmD+2I8r1Ahb+mYKSctMNQwI9HLH2+d5oplZUu/61gjL0it4OQQBmDmqF5CsFOJp2E4VlppuSrJ/ZB11buN7/D+AvjqTdxGMx+2EQKn+pWPVcT9jJeIOS6o5BXQsGNVHDKy3X473NJ7E6oXIpUzdHOV4YGIT1RzJxJqsQQ4I98f2U7pBIJMi4WYLvdl9E+s1S3CjS4lJOMQrKKhDS3BlrpveG099mry/ZewnvbT6Fri1csH5mX5PvebOkHB/9kYINRzPRO8gdq57raZzYtvPMdcSdzcasIW1MHk27mzKdHg99sQcXs4uN7700pA3mDGt7Tz+TI2k3kXApF8/1DzK5C0FNw71kEX8FJCKLU8lliH40FN882RUB7g7ILS7H/205gzNZhXB3lGPBuFBjgPq5OuDdsSFYMjUcm6L64deofnB3lCM5swAzViRWm5j267HKvbfHhPlW+56+Liq8PKId5DIpDly8gX3nK2+PH7qci+nLD2PZ/st49qfDKNPVfcvPj/5IwcXsYniqFXhvbEcAwJc7zmH/hZw6XyO/VIdnlh3Cgt/PYPPx6nuHV6nQG7Dg9zNYf4QrvzVlfDyLiBrMgyE+GNreC+uPZuLzbedwvbAMHz4WWuMt7SoBHo5YMjUcTyyOx55zOXjtv8excHwYJBIJ0m6UICk9D1IJMCrUt8bzm7uoMKlXCyzddxkf/XEGgc264YXlidDpK28mJqbexKw1R/H1pG537dkmXMrFkn2XAAAfjAvF4GBPJGfmY+3hDMxek4SILs1RUl6B0nIDVHIp1Ep7OCvtMayDJ1p7qo3Xidl1ATdLdAAql2Ot2vHs72JPXcM3cZUbq9jLpBgdVnMbqXHjrW8iEkWF3oDCsoo633beeeY6nr21bvnrI4PxwsBW+GrneXz0Rwr6tfbAimd73vHcnCItBny4EyXlejRTK5BdqEUHH2e8+mA7TP8pEeV6A6b2CcA7ozvc8Znv/FIdHv5yD9JzSzGhuz8+eCwUAFBSXoExi/bh/N82NfkrB7kMa5/vjZDmGmTmlWLwx7tQXlF5Z8BRLkPiW8OgtK8+5j/9p8P481TluupyOylWP9cL3Vq6okJvwPojmbiYU4zIwa2gVtrX6WdI1oNj1LVgUBPZruXxqXhrYzIkEmDJ1HB88Hvl7fMPxnXChPAWtZ678M8UfLnjPIDKMfJfo/rCz9UB/zt2BS+urpzN3trTCYPaNsOgdp7oFeRmnCAmCAKeX56IP09dg5+rCr/P6m8Sjqk3ivHj/lTYySRQ2cugtJehTKdHQZkOhy/fxInMfDRTK7B+Rh98GnsW649mokegG9JulCCroAxLp4ZjcLCnSb15JeUIf38bdHoBnf1dkJSeB3dHOeYMb4sf9lzCxZzKMfIwfxf8OC0cLg7Vf+Ep0+nxn99OoVirR5CHI1p5OqF7gCs81bXvdGYwCJBy3NyiGNS1YFAT2S5BEPDvDSewOiEdDnIZSsr1sJdJcPiNYdA41N6rzC/V4YGPdyG/VIcVz/ZEryB342fL9l3Cf347jYq/PL8d0twZn03ogtaeTli8+wL+b8sZyGVS/DKjN0L9XOpcc2GZDuO/OYAzWYXwc1UhM68UggBsiuyLXxIzsDw+FRN7+CP60VCT81YeTMUbG5LR3scZv7zQG49/ewAnrxQYP3dzlMMgCMgr0SHYW40Vz/aEh5PpEEJNj745ymVY9nQPhAe41VjvnnPZeGbZYTzdLxCvjwyuczvp3nAyGRE1ShKJBO+OCUG3lq7GR7gGtvW8a0gDlTuGbX6pH/785wCTkAaAqX0DkfjmMCz6Rxc81s0PaqUdkjML8PCXe/D+b6fwwdYUAMDbozvcU0gDgFppj6XTwuHtrETGzcqQHh3mizB/Fwzv6AWgcixa/7dFXjYezQQAPNLFF44KO/wwJRx+rio4ymWYNaQNdr862PjI2pmsQjz+7QFcK7i9sluRtgJf76oc3360a3OM6+qHIA9HFJfrMXVJAhJTc6vVqjcIeO9/p1CuN+CbuAtYdzj9ntpKlsGgJiKbIreTIubJrvB2rrx9+2jXmidi1cRHo0JQM6caP9M42OPhUF98PD4M2+YMRP82HijTGfDdnkvQGwQ80qU5JvWs/fZ6bd936bRwqBV2UNnL8OqIdgCAnoHuUCvtkFNUjqT0m8bj03NLcOjyTUgkwJiwyvZ5a5TYNmcgEt8ahn8OawsnhR3aeqmx7vneaO6iwsXsYjy/PBHaispfYJbuvYTc4nIEejjiw3GhWPh4GH57qT/6tnZHcbkeU5YcwpG0myZ1bjyaiXPXi1A1TP/GxmQcz8i7rzaT+TCoicjmeKqV+O/MPvh6UleMDPE2+/W9nJX4cVoPzBvdAQo7KUKaO+P9R0LqtblIex9n/DlnAP6YPQD+bg4AKn/peODW2PSfJ68Zj92UVNmb7tPKHd6a2+PJylvj338V4OGIVc/1hEZlj6T0PMz79STySsqxeM9FAMDsoW2MY+0quQzfTw5H7yB3FGkrMOWHBBy6XNmz1lbo8UnsWQCVG7EMbe+J8goDnl+eiO2nr+GT2LOYuDges9YcvafH2aj+OEZNRFSL0nI97GQS49rm5la1NGughyN2/GsgAGDoJ3G4kF2Mjx4Lxfju/nW6TtzZbExdmgBBAEL9NDiekY9gbzW2vNS/2sSwkvIKPL3sEOIv5kJpL0XMk92QmlOMef87BU+1AnGvDIbOYEDEon3GSWt/NaqTD76c2KVeE84MBgEGQWiyK7pxjJqIyExUcpnFQhoABrZtBrlMiks5xZi/+TRmrjyCC9nFUNhJ8eA93C0Y2LYZXh5eeUv9eEY+AGDOsLY1hqmD3A5Lp/bA4HbNUKYz4LkfD2Phrd70S0PaQCWXwVlpj8WTu8HLWQEfjRIRnX3x8vC2sJdJ8NuJq/i/LaerXbeuDAYB05cfRtf5sUi7UXLf12kquOAJEZGI1Ep79Gntjl0p2cbFVABgVKjPPT8fPXNQKyRn5uP35CyE+btgWAevOx6rksuweHJ3/GvtMfx67AoKyyrQ0t0BE8Jv9+Bbe6px8N9DTc7zd3PArDVJ+H7vJbg7KfBYNz+4O8rvqXf944HLxn3NfzxwGW893MHk8wq9ocn2tGvCW99ERCJLzszHoh3n4eYkR0s3BwR4OGJAm2Z13vjkr0rL9fglMR0PtPdCc5e77+qlNwj4z2+nsP5IJj57ojMGt/O86zkxuy7gg61njF/bSSXwd3PAF090Qadbe5HfyYXsIjz0+R5oby344qy0w8F/DzW2dfvpa5i+PBEzBrbCy7cm3ZlDhd6AZ348DJlUgu8md7+v9dXPZBUgyMMJcrv6/xLB56hrwaAmIqruXhY5EQQBX2w/jxUHU5FTpEVVivQKcsOa6b3veF6F3oDx3x7A0bQ89GvtgdTcYqTnluLDx0LxeHd/aCv0GLIwDhk3SwEA3zzZFQ+G+Nzxevdi77kcPPnDQQDAlxO73PNyrGU6Pfp9sANymRTLn+2JVnd4eqCuOEZNRET35F5uXUskEswa2gaH3hiKc/8Zia2z+8NeJkH8xVwcuGC6L3hyZj42JWXiv4kZeOfXkzialge1wg4fPhaKf/RoCQBYGZ8KAPhx/2Vk3CxFVSmvrDuO1BvVJ7Pdj1+PZRr//NXO87jXPuqahDTkFJVDKpWgxa1Z+w2FQU1ERPfNTiZFsLezcWz78+1njZ/9fCgND3+5F7PWJOFf645h5cE0AMA7YzrC10WFx7v7QS6T4lhGPuLOZhuXeP1PRCd0b+mKQm0FZq48ck+Pg+UWl2NFfCpuFGmN72kr9NianAUAkEqAM1mF2Jly3eTz4xl51XZmq1JeYcC3uysfd3t+YCuLTi6sCYOaiIjqbeag1ia96oRLuXhzYzKAyvXIB7RthsHtmuGfQ9ti3K1FatydFHioU+XM9hkrElFYVoFgbzUmhPtj0T+6wt1RjpNXCjB/86lq3+9KXinizmYbF3gBgP3nczDy8914c2MyZqw4Yuw17z6bg4KyCng5K/BMv0AAwKIdlb3qvJJyPP5tPMYs2oce72/D3PUnsP98jkmPe+PRTFzNL4OnWoHx3fws8wOsBWd9ExFRvfm6qDAh3B8r4tPwf1tOIzOvFDq9cNdnrp/s1RIbk64Yl4R9c1QHyKQSeGuU+OyJzpi8JAErD6ZhaHsv48Yl1wvLMParfcgu1EKjssfDoT5Q2cvww75LxvHyhMu5iD11DcM7euN/t/YsH9XJF88NCMKPB1JxJC0Pvx67gq93XkDKtUIAwM0SHVYnpGF1QuX3+2JiZyjsZIi5tdXoc/2DatzlzNLYoyYiIrOo6lWfyMxHbnE5Qpo74+PxYbWOf3dr6Ypg78q9uge1a4Z+bTyMn/Vv0wxP963sAb/23+PIKylHhd6Al1YfRXahFlJJ5WYrKw+m4fu9lSH9RLi/sde8YOsZFJTpEHtrq9AxnX3hqVZiwq1FZGatSULKtUJ4qhX4fVZ/rHy2J54I94fcToptp6/hicXx+OnAZVzKKYaLgz3+cZ9LyNYXe9RERGQWf+1VN1Mr8N3k7nd9xEwikeA/ESFYtv8yXnuw+m5dr4xoh10p13EhuxhvbTqJFm4qxF/MhYNcho2RfXG9QIv1RzJw8koBXhrSBqNCfVBYpsPGo5m4mF2MyJVHUKrTo4WbA8JuPTo2fUAQViWkQW8Q0MLNASue6YkW7pUTxPq29sD47n549sfDOJ6Rb1w8ZlqfQDgqxIlMPp5FRERmU1Cmw+K4ixjb2RdtvNRmueax9Dw8GrPfZIexLyZ2wZhaHrH66cBlvL3ppPHryMGt8MqI278IfL/nIhIu5WJ+RAi8nKvvz30ppxhTlyYg9UYJnBR22PfaA3Xapa2u+Bx1LRjURES255M/U/DFrVnhU3q3xLtjQ2o9Xqc3YMSnu41rlW+d3R/B3vf2b/6NIi2+2nkB/dt4GMfHzcVmnqPevXs3Ro8eDV9fX0gkEmzcuPGu56xcuRJhYWFwcHCAj48Pnn76ady4ceOu5xERke2KeqANHurkjYc6eePfo9rf9Xh7mRSvj6zsQXf0dUa7++jduzsp8PboDmYP6XslalAXFxcjLCwMX331VZ2O37dvHyZPnoxnnnkGJ0+exLp165CQkIDnnnvOwpUSEZGY5HZSfD2pG76e1A0Ku7rNvB7e0RvrXuiNH6aE12uLUrGJOpls5MiRGDlyZJ2PP3DgAAICAvDSSy8BAAIDA/H888/jgw8+sFSJRERkw8ID3MQuod5s6vGs3r17Iz09HVu2bIEgCLh27Rp++eUXPPTQQ2KXRkREZBE2FdR9+/bFypUrMWHCBMjlcnh7e0Oj0dR661yr1aKgoMDkRUREZCtsKqhPnTqFWbNm4e2330ZiYiK2bt2Ky5cv44UXXrjjOdHR0dBoNMaXv7//HY8lIiKyNlbzeJZEIsGGDRsQERFxx2OeeuoplJWVYd26dcb39u7di/79++PKlSvw8am+HZpWq4VWe3tx9oKCAvj7+/PxLCIiEs29PJ5lUyuTlZSUwM7OtGSZrHL2351+31AoFFAoFBavjYiIyBJEvfVdVFSEpKQkJCUlAQAuXbqEpKQkpKVVboU2d+5cTJ482Xj86NGjsX79esTExODixYvYt28fXnrpJfTo0QO+vve2CTgREZEtELVHffjwYQwePNj49Zw5cwAAU6ZMwbJly3D16lVjaAPA1KlTUVhYiEWLFuFf//oXXFxc8MADD/DxLCIiarSsZoy6oXAJUSIiEpvNLCFKREREtWNQExERWTEGNRERkRVjUBMREVkxBjUREZEVY1ATERFZMQY1ERGRFbOpJUTNoeqxce6iRUREYqnKoLosZdLkgrqwsBAAuIsWERGJrrCwEBqNptZjmtzKZAaDAVeuXIFarYZEIqnXtap24kpPT2+Sq5yx/Ww/28/2s/33135BEFBYWAhfX19IpbWPQje5HrVUKoWfn59Zr+ns7Nwk/6JWYfvZfraf7W+q6tP+u/Wkq3AyGRERkRVjUBMREVkxBnU9KBQKvPPOO1AoFGKXIgq2n+1n+9l+tt/y7W9yk8mIiIhsCXvUREREVoxBTUREZMUY1ERERFaMQV0PX331FQICAqBUKtGzZ08kJCSIXZJFREdHIzw8HGq1Gp6enoiIiEBKSorJMWVlZYiMjIS7uzucnJwwbtw4XLt2TaSKLWfBggWQSCSYPXu28b3G3vbMzEw8+eSTcHd3h0qlQqdOnXD48GHj54Ig4O2334aPjw9UKhWGDh2Kc+fOiVix+ej1erz11lsIDAyESqVCq1atMH/+fJNlHxtb+3fv3o3Ro0fD19cXEokEGzduNPm8Lu3Nzc3FpEmT4OzsDBcXFzzzzDMoKipqwFbcv9rar9Pp8Nprr6FTp05wdHSEr68vJk+ejCtXrphcw+ztF+i+rFmzRpDL5cKSJUuEkydPCs8995zg4uIiXLt2TezSzG7EiBHC0qVLheTkZCEpKUl46KGHhBYtWghFRUXGY1544QXB399f2L59u3D48GGhV69eQp8+fUSs2vwSEhKEgIAAITQ0VJg1a5bx/cbc9tzcXKFly5bC1KlThYMHDwoXL14U/vjjD+H8+fPGYxYsWCBoNBph48aNwrFjx4QxY8YIgYGBQmlpqYiVm8f7778vuLu7C5s3bxYuXbokrFu3TnBychI+//xz4zGNrf1btmwR3njjDWH9+vUCAGHDhg0mn9elvQ8++KAQFhYmxMfHC3v27BFat24tTJw4sYFbcn9qa39eXp4wdOhQ4eeffxbOnDkjHDhwQOjRo4fQrVs3k2uYu/0M6vvUo0cPITIy0vi1Xq8XfH19hejoaBGrahjXr18XAAhxcXGCIFT+5bW3txfWrVtnPOb06dMCAOHAgQNilWlWhYWFQps2bYTY2Fhh4MCBxqBu7G1/7bXXhH79+t3xc4PBIHh7ewsfffSR8b28vDxBoVAIq1evbogSLWrUqFHC008/bfLeo48+KkyaNEkQhMbf/r8HVV3ae+rUKQGAcOjQIeMxv//+uyCRSITMzMwGq90cavpF5e8SEhIEAEJqaqogCJZpP29934fy8nIkJiZi6NChxvekUimGDh2KAwcOiFhZw8jPzwcAuLm5AQASExOh0+lMfh7BwcFo0aJFo/l5REZGYtSoUSZtBBp/23/99Vd0794d48ePh6enJ7p06YLvvvvO+PmlS5eQlZVl0n6NRoOePXs2ivb36dMH27dvx9mzZwEAx44dw969ezFy5EgAjb/9f1eX9h44cAAuLi7o3r278ZihQ4dCKpXi4MGDDV6zpeXn50MikcDFxQWAZdrf5Nb6NoecnBzo9Xp4eXmZvO/l5YUzZ86IVFXDMBgMmD17Nvr27YuQkBAAQFZWFuRyufEvahUvLy9kZWWJUKV5rVmzBkeOHMGhQ4eqfdbY237x4kXExMRgzpw5+Pe//41Dhw7hpZdeglwux5QpU4xtrOn/hcbQ/tdffx0FBQUIDg6GTCaDXq/H+++/j0mTJgFAo2//39WlvVlZWfD09DT53M7ODm5ubo3uZ1JWVobXXnsNEydONK73bYn2M6jpnkRGRiI5ORl79+4Vu5QGkZ6ejlmzZiE2NhZKpVLschqcwWBA9+7d8X//938AgC5duiA5ORnffPMNpkyZInJ1lrd27VqsXLkSq1atQseOHZGUlITZs2fD19e3SbSf7kyn0+Hxxx+HIAiIiYmx6Pfire/74OHhAZlMVm1m77Vr1+Dt7S1SVZYXFRWFzZs3Y+fOnSY7kHl7e6O8vBx5eXkmxzeGn0diYiKuX7+Orl27ws7ODnZ2doiLi8MXX3wBOzs7eHl5Ndq2A4CPjw86dOhg8l779u2RlpYGAMY2Ntb/F1555RW8/vrreOKJJ9CpUyc89dRT+Oc//4no6GgAjb/9f1eX9np7e+P69esmn1dUVCA3N7fR/EyqQjo1NRWxsbEmu2dZov0M6vsgl8vRrVs3bN++3fiewWDA9u3b0bt3bxErswxBEBAVFYUNGzZgx44dCAwMNPm8W7dusLe3N/l5pKSkIC0tzeZ/HkOGDMGJEyeQlJRkfHXv3h2TJk0y/rmxth0A+vbtW+1RvLNnz6Jly5YAgMDAQHh7e5u0v6CgAAcPHmwU7S8pKam2V7BMJoPBYADQ+Nv/d3Vpb+/evZGXl4fExETjMTt27IDBYEDPnj0bvGZzqwrpc+fOYdu2bXB3dzf53CLtv68paCSsWbNGUCgUwrJly4RTp04J06dPF1xcXISsrCyxSzO7GTNmCBqNRti1a5dw9epV46ukpMR4zAsvvCC0aNFC2LFjh3D48GGhd+/eQu/evUWs2nL+OutbEBp32xMSEgQ7Ozvh/fffF86dOyesXLlScHBwEFasWGE8ZsGCBYKLi4uwadMm4fjx48LYsWNt+vGkv5oyZYrQvHlz4+NZ69evFzw8PIRXX33VeExja39hYaFw9OhR4ejRowIA4ZNPPhGOHj1qnNVcl/Y++OCDQpcuXYSDBw8Ke/fuFdq0aWMzj2fV1v7y8nJhzJgxgp+fn5CUlGTy76FWqzVew9ztZ1DXw5dffim0aNFCkMvlQo8ePYT4+HixS7IIADW+li5dajymtLRUmDlzpuDq6io4ODgIjzzyiHD16lXxiragvwd1Y2/7//73PyEkJERQKBRCcHCwsHjxYpPPDQaD8NZbbwleXl6CQqEQhgwZIqSkpIhUrXkVFBQIs2bNElq0aCEolUohKChIeOONN0z+UW5s7d+5c2eN/79PmTJFEIS6tffGjRvCxIkTBScnJ8HZ2VmYNm2aUFhYKEJr7l1t7b906dId/z3cuXOn8Rrmbj93zyIiIrJiHKMmIiKyYgxqIiIiK8agJiIismIMaiIiIivGoCYiIrJiDGoiIiIrxqAmIiKyYgxqIiIiK8agJqIGI5FIsHHjRrHLILIpDGqiJmLq1KmQSCTVXg8++KDYpRFRLbgfNVET8uCDD2Lp0qUm7ykUCpGqIaK6YI+aqAlRKBTw9vY2ebm6ugKovC0dExODkSNHQqVSISgoCL/88ovJ+SdOnMADDzwAlUoFd3d3TJ8+HUVFRSbHLFmyBB07doRCoYCPjw+ioqJMPs/JycEjjzwCBwcHtGnTBr/++qtlG01k4xjURGT01ltvYdy4cTh27BgmTZqEJ554AqdPnwYAFBcXY8SIEXB1dcWhQ4ewbt06bNu2zSSIY2JiEBkZienTp+PEiRP49ddf0bp1a5Pv8e677+Lxxx/H8ePH8dBDD2HSpEnIzc1t0HYS2ZR67wlGRDZhypQpgkwmExwdHU1e77//viAIlduZvvDCCybn9OzZU5gxY4YgCIKwePFiwdXVVSgqKjJ+/ttvvwlSqdS4D7uvr6/wxhtv3LEGAMKbb75p/LqoqEgAIPz+++9maydRY8MxaqImZPDgwYiJiTF5z83Nzfjn3r17m3zWu3dvJCUlAQBOnz6NsLAwODo6Gj/v27cvDAYDUlJSIJFIcOXKFQwZMqTWGkJDQ41/dnR0hLOzM65fv36/TSJq9BjURE2Io6NjtVvR5qJSqep0nL29vcnXEokEBoPBEiURNQocoyYio/j4+Gpft2/fHgDQvn17HDt2DMXFxcbP9+3bB6lUinbt2kGtViMgIADbt29v0JqJGjv2qImaEK1Wi6ysLJP37Ozs4OHhAQBYt24dunfvjn79+mHlypVISEjADz/8AACYNGkS3nnnHUyZMgXz5s1DdnY2XnzxRTz11FPw8vICAMybNw8vvPACPD09MXLkSBQWFmLfvn148cUXG7ahRI0Ig5qoCdm6dSt8fHxM3mvXrh3OnDkDoHJG9po1azBz5kz4+Phg9erV6NChAwDAwcEBf/zxB2bNmoXw8HA4ODhg3Lhx+OSTT4zXmjJlCsrKyvDpp5/i5ZdfhoeHBx577LGGayBRIyQRBEEQuwgiEp9EIsGGDRsQEREhdilE9BccoyYiIrJiDGoiIiIrxjFqIgIAcBSMyDqxR01ERGTFGNRERERWjEFNRERkxRjUREREVoxBTUREZMUY1ERERFaMQU1ERGTFGNRERERWjEFNRERkxf4fXveFi4+zfHMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_loss: Tensor = (\n",
    "    torch.tensor(losses_all, dtype=torch.float32).view(-1, 1_000).mean(dim=1)\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  # Create figure and axes\n",
    "ax.plot(avg_loss)  # Plot the data\n",
    "ax.set(xlabel=\"Epoch\", ylabel=\"Loss\", title=\"Loss vs Epoch\")  # Add labels\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karyia.\n",
      "kamaal.\n",
      "shafaai.\n",
      "jaelih.\n",
      "brolin.\n",
      "afp.\n",
      "alaizna.\n",
      "kayoa.\n",
      "medan.\n",
      "huxch.\n",
      "arysees.\n",
      "kodi.\n",
      "terriya.\n",
      "noam.\n",
      "codey.\n",
      "shan.\n",
      "aayden.\n",
      "slaira.\n",
      "tamya.\n",
      "yoorgi.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the model (Untrained model!)\n",
    "g = torch.Generator().manual_seed(5)\n",
    "n_names: int = 20\n",
    "\n",
    "# Set the training mode to False\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, \"training\"):\n",
    "        layer.training = False\n",
    "\n",
    "\n",
    "for _ in range(n_names):\n",
    "\n",
    "    out: list[str] = []\n",
    "    context: list[int] = [0] * block_size  # initialize with all ...\n",
    "    while True:\n",
    "        # Forward pass the neural net\n",
    "        x: Tensor = torch.tensor([context])\n",
    "        logits: Tensor = model(x)\n",
    "        probs: Tensor = F.softmax(logits, dim=1)\n",
    "\n",
    "        # Sample from the distribution\n",
    "        idx: int = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        # Shift the context window and track the samples\n",
    "        context = context[1:] + [idx]\n",
    "        out.append(idx)\n",
    "        # If we sample the special '.' token, break\n",
    "        if idx == 0:\n",
    "            break\n",
    "\n",
    "    # Decode and print the generated word\n",
    "    print(\"\".join(num_to_text.get(i) for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
