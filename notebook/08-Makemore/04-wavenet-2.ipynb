{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makemore: Wavenet\n",
    "\n",
    "- [Andrej Karpathy YouTube](https://www.youtube.com/watch?v=t3YJ5hKiMQ0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=6&ab_channel=AndrejKarpathy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "numpy    : 1.26.4\n",
      "pandas   : 2.2.1\n",
      "polars   : 0.20.18\n",
      "torch    : 2.2.2\n",
      "lightning: 2.2.1\n",
      "\n",
      "conda environment: torch_p11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,torch,lightning --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> list[str]:\n",
    "    \"\"\"Load text data from a file and return as a list of strings.\"\"\"\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        # Read all the lines as a list\n",
    "        data: list[str] = f.read().splitlines()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "fp: str = \"../../data/names.txt\"\n",
    "names: list[str] = load_data(file_path=fp)\n",
    "\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary Of Characters And Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_token: str = \".\"\n",
    "characters: list[str] = sorted(set(\"\".join(names)))\n",
    "# Add the special token to the beginning of the list.\n",
    "characters.insert(0, special_token)\n",
    "n_chars: int = len(characters)\n",
    "\n",
    "# Convert text to numbers.\n",
    "text_to_num: dict[str, int] = {text: idx for idx, text in enumerate(characters)}\n",
    "# Convert numbers to text\n",
    "num_to_text: dict[int, str] = {idx: text for text, idx in text_to_num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, TensorDataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def build_dataset(\n",
    "    names: list[str],\n",
    "    special_token: str = \".\",\n",
    "    block_size: int = 3,\n",
    "    print_info: bool = False,\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Builds a dataset of name sequences and their corresponding character indices.\n",
    "\n",
    "    Args:\n",
    "        names (list[str]): A list of names to build the dataset from.\n",
    "        special_token (str, optional): A special token to append to the end of each name. Defaults to \".\".\n",
    "        block_size (int, optional): The size of the context window for each input sequence. Defaults to 3.\n",
    "        print_info (bool, optional): Whether to print information about the dataset generation. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Tensor, Tensor]: A tuple containing the input sequences (X) and their corresponding target indices (Y).\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in names:\n",
    "        if print_info:\n",
    "            print(w)\n",
    "        context: list[int] = [0] * block_size\n",
    "\n",
    "        for ch in w + special_token:\n",
    "            idx: int = text_to_num.get(ch)\n",
    "            X.append(context)\n",
    "            Y.append(idx)\n",
    "\n",
    "            if print_info:\n",
    "                print(\n",
    "                    f\"{''.join([num_to_text.get(i) for i in context])} ---> {num_to_text.get(idx)}\"\n",
    "                )\n",
    "\n",
    "            # Crop and append, like a rolling window\n",
    "            context = context[1:] + [idx]\n",
    "\n",
    "    X: Tensor = torch.tensor(X)\n",
    "    Y: Tensor = torch.tensor(Y)\n",
    "    print(f\"\\n{X.shape=}, {Y.shape=}\")\n",
    "    return (X, Y)\n",
    "\n",
    "\n",
    "def split_data_into_train_dev_test(\n",
    "    data: Tensor | Dataset, test_size: float = 0.05, dev_size: float = 0.1, seed=42\n",
    ") -> tuple[Tensor, ...]:\n",
    "    \"\"\"\n",
    "    Splits a given PyTorch tensor `data` into training, development, and test sets.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "        data (torch.Tensor): The input tensor to be split.\n",
    "        test_size (float, optional): The fraction of the data to use for the test set. Defaults to 0.2.\n",
    "        dev_size (float, optional): The fraction of the data to use for the development set. Defaults to 0.1.\n",
    "        seed (int, optional): The random seed to use for reproducibility. Defaults to 42.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        tuple[torch.Tensor, torch.Tensor, torch.Tensor]: The training, development, and test sets as PyTorch tensors.\n",
    "    \"\"\"\n",
    "    if isinstance(data, Tensor):\n",
    "        X_train, X_test = train_test_split(data, test_size=test_size, random_state=seed)\n",
    "        X_train, X_dev = train_test_split(\n",
    "            X_train, test_size=dev_size, random_state=seed\n",
    "        )\n",
    "        result: tuple[Tensor, ...] = (X_train, X_dev, X_test)\n",
    "    if isinstance(data, Dataset):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data.data,\n",
    "            data.targets,\n",
    "            test_size=test_size,\n",
    "            random_state=seed,\n",
    "            stratify=data.targets,\n",
    "        )\n",
    "        X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "            X_train, y_train, test_size=dev_size, random_state=seed, stratify=y_train\n",
    "        )\n",
    "        result: tuple[Tensor, ...] = (X_train, X_dev, X_test, y_train, y_dev, y_test)\n",
    "\n",
    "    print(f\"{X_train.shape=}; {X_dev.shape=}; {X_test.shape=}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data: Tensor, targets: Tensor) -> None:\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(data.shape={self.data.shape}, \"\n",
    "            f\"target.shape={self.targets.shape=})\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.targets[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1d(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-5, momentum: float = 0.1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # Parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # Buffers (trained with running `momentum update`)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        if self.training:\n",
    "            if x.ndim == 2:\n",
    "                dim: tuple[int] | int = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)\n",
    "            # Calculate the batch mean and variance\n",
    "            x_mean: Tensor = x.mean(dim=dim, keepdim=True)\n",
    "            x_var: Tensor = x.var(dim=dim, keepdim=True)\n",
    "\n",
    "        else:\n",
    "            x_mean = self.running_mean\n",
    "            x_var = self.running_var\n",
    "\n",
    "        # Normalize the input\n",
    "        x_hat: Tensor = (x - x_mean) / (x_var + self.eps).sqrt()\n",
    "        self.output: Tensor = (self.gamma * x_hat) + self.beta\n",
    "\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                # Update running mean and variance\n",
    "                self.running_mean = (\n",
    "                    1 - self.momentum\n",
    "                ) * self.running_mean + self.momentum * x_mean\n",
    "                self.running_var = (\n",
    "                    1 - self.momentum\n",
    "                ) * self.running_var + self.momentum * x_var\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self) -> list[Tensor]:\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "class FlattenConsecutive(nn.Module):\n",
    "    \"\"\"A custom module that flattens consecutive elements in the input tensor along\n",
    "    the second dimension.\"\"\"\n",
    "\n",
    "    def __init__(self, n_c_elements: int) -> None:\n",
    "        \"\"\"\n",
    "        Note:\n",
    "            n_c_elements: the number of consecutive elements to concatenate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_c_elements = n_c_elements\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{__class__.__name__}({self.n_c_elements})\"\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        # B: batch size, L: sequence length, C: number of channels\n",
    "        B, L, C = x.shape\n",
    "        assert (\n",
    "            L % self.n_c_elements == 0\n",
    "        ), f\"The length of the input tensor must be a multiple of {self.n_c_elements}.\"\n",
    "\n",
    "        x = x.view(B, L // self.n_c_elements, C * self.n_c_elements)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "\n",
    "        self.output = x\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self) -> list[Tensor]:\n",
    "        return []\n",
    "\n",
    "\n",
    "class Tanh(nn.Module):\n",
    "    \"\"\"A custom module that applies the hyperbolic tangent activation function to the input tensor.\"\"\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return torch.tanh(x)\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        self.output = torch.tanh(x)\n",
    "        return self.output\n",
    "\n",
    "\n",
    "def calculate_loss_upd(model: Any, X: Tensor, y: Tensor, training: True) -> Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the loss for the given input tensors `X` and `y`.\n",
    "\n",
    "    Args:\n",
    "        model (Any): The model to use for the forward pass.\n",
    "        X (torch.Tensor): The input tensor.\n",
    "        y (torch.Tensor): The target tensor.\n",
    "        training (bool): Indicates whether the model is in training mode or not.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The calculated loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the training mode to False\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, \"training\"):\n",
    "            layer.training = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        logits: Tensor = model(X)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss: Tensor = F.cross_entropy(logits, y)\n",
    "        result: str = (\n",
    "            f\"Training loss: {loss:.4f}\" if training else f\"Validation loss: {loss:.4f}\"\n",
    "        )\n",
    "        print(result)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1!\n",
    "\n",
    "- The current inplementation flattens the entire data into a 2-D array which is not optimal when the block_size is large.\n",
    "\n",
    "```py\n",
    "# e.g. If the block_size is 3\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- Implement the [Wavenet](https://arxiv.org/pdf/1609.03499) architecture shown below:\n",
    "\n",
    "<img src=\"./images/Wavenet.png\" width=\"600\" height=\"300\" alt=\"Wavenet Architecture\">\n",
    "\n",
    "- The input is combined to form several bigrams which are further combined at every layer in the network.\n",
    "  - i.e. if you have 8 characters in the input layer, you will have 4 bigrams (e.g. `ab`, `cd`, `ef`, `gh`).\n",
    "  - `ab` is combined with `cd` to form `abcd`, `ef` is combined with `gh` to form `efgh` and so on.\n",
    "  - finally, `abcd` and `efgh` are combined and used to predict the output.\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "```text\n",
    "Combining each input layer with the next one to form bigrams:\n",
    "\n",
    "FlattenConsecutive(2):   (4, 4, 20)   # i.e. 4 groups (1 2)   (3 4)   (5 6)   (7 8) \n",
    "...\n",
    "FlattenConsecutive(2):   (4, 2, 600)   # i.e. 2 groups (1 2 3 4)   (5 6 7 8) \n",
    "...\n",
    "FlattenConsecutive(2):   (4, 600)   # (4, 1, 600) i.e. 1 group (1 2 3 4 5 6 7 8) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleWavenetModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        num_hidden: int,\n",
    "        n_c_elements: int,\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.num_hidden = num_hidden\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Embedding(vocab_size, embedding_dim),\n",
    "            # === Input Layer\n",
    "            FlattenConsecutive(n_c_elements),\n",
    "            nn.Linear(embedding_dim * n_c_elements, num_hidden),\n",
    "            BatchNorm1d(num_hidden),\n",
    "            Tanh(),\n",
    "            # === layer 1\n",
    "            FlattenConsecutive(n_c_elements),\n",
    "            nn.Linear(num_hidden * n_c_elements, num_hidden),\n",
    "            BatchNorm1d(num_hidden),\n",
    "            Tanh(),\n",
    "            # === layer 3\n",
    "            FlattenConsecutive(n_c_elements),\n",
    "            nn.Linear(num_hidden * n_c_elements, num_hidden),\n",
    "            BatchNorm1d(num_hidden),\n",
    "            Tanh(),\n",
    "            # === layer 3\n",
    "            nn.Linear(num_hidden, vocab_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x: Tensor = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "........ ---> e\n",
      ".......e ---> m\n",
      "......em ---> m\n",
      ".....emm ---> a\n",
      "....emma ---> .\n",
      "olivia\n",
      "........ ---> o\n",
      ".......o ---> l\n",
      "......ol ---> i\n",
      ".....oli ---> v\n",
      "....oliv ---> i\n",
      "...olivi ---> a\n",
      "..olivia ---> .\n",
      "\n",
      "X.shape=torch.Size([12, 8]), Y.shape=torch.Size([12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  5],\n",
       "         [ 0,  0,  0,  0,  0,  0,  5, 13],\n",
       "         [ 0,  0,  0,  0,  0,  5, 13, 13],\n",
       "         [ 0,  0,  0,  0,  5, 13, 13,  1],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0, 15],\n",
       "         [ 0,  0,  0,  0,  0,  0, 15, 12],\n",
       "         [ 0,  0,  0,  0,  0, 15, 12,  9],\n",
       "         [ 0,  0,  0,  0, 15, 12,  9, 22],\n",
       "         [ 0,  0,  0, 15, 12,  9, 22,  9],\n",
       "         [ 0,  0, 15, 12,  9, 22,  9,  1]]),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size: int = 8  # size of the context window for each input sequence\n",
    "\n",
    "# 8 characters are required to predict the next character\n",
    "build_dataset(names=names[:2], block_size=block_size, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X.shape=torch.Size([228152, 8]), Y.shape=torch.Size([228152])\n",
      "X_train.shape=torch.Size([195069, 8]); X_dev.shape=torch.Size([21675, 8]); X_test.shape=torch.Size([11408, 8])\n"
     ]
    }
   ],
   "source": [
    "block_size: int = 8  # size of the context window for each input sequence\n",
    "X, y = build_dataset(names=names, block_size=block_size, print_info=False)\n",
    "data: Dataset = MyDataset(X, y)\n",
    "\n",
    "X_train, X_dev, X_test, y_train, y_dev, y_test = split_data_into_train_dev_test(\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =============== DEBUG ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_s.shape = torch.Size([4, 8])\n",
      "X_s = tensor([[ 0,  0,  0, 26, 15, 19,  9,  1],\n",
      "        [ 0,  0,  0,  0,  0,  0,  4,  5],\n",
      "        [ 0,  0,  0,  0, 10,  1, 25,  3],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0, 10]])\n",
      "\n",
      "logits.shape = torch.Size([4, 27])\n",
      "Number of parameters: 20,265\n"
     ]
    }
   ],
   "source": [
    "emb_dim: int = 10  # embedding dimension\n",
    "batch_size: int = 4\n",
    "n_c_elements: int = 2\n",
    "n_nodes: int = 64  # number of hidden nodes\n",
    "idx: Tensor = torch.randint(0, X_train.shape[0], (batch_size,))\n",
    "X_s, y_s = X_train[idx], y_train[idx]\n",
    "print(f\"{X_s.shape = }\")\n",
    "\n",
    "# 4 samples each containing a block size of `block_size`\n",
    "print(f\"{X_s = }\\n\")\n",
    "\n",
    "\n",
    "model: SimpleWavenetModel = SimpleWavenetModel(\n",
    "    in_features=block_size,\n",
    "    num_hidden=n_nodes,\n",
    "    n_c_elements=n_c_elements,\n",
    "    vocab_size=n_chars,\n",
    "    embedding_dim=emb_dim,\n",
    ")\n",
    "logits: Tensor = model(X_s)\n",
    "print(f\"{logits.shape = }\")\n",
    "n_params: int = sum([p.numel() for layer in model.layers for p in layer.parameters()])\n",
    "print(f\"Number of parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(27, 10):                                                              (27, 10)\n",
      "FlattenConsecutive(2):                                                          (4, 4, 20)\n",
      "Linear(in_features=20, out_features=64, bias=True):                             (64, 20)\n",
      "BatchNorm1d():                                                                  (4, 4, 64)\n",
      "Tanh():                                                                         (4, 4, 64)\n",
      "FlattenConsecutive(2):                                                          (4, 2, 128)\n",
      "Linear(in_features=128, out_features=64, bias=True):                            (64, 128)\n",
      "BatchNorm1d():                                                                  (4, 2, 64)\n",
      "Tanh():                                                                         (4, 2, 64)\n",
      "FlattenConsecutive(2):                                                          (4, 128)\n",
      "Linear(in_features=128, out_features=64, bias=True):                            (64, 128)\n",
      "BatchNorm1d():                                                                  (4, 64)\n",
      "Tanh():                                                                         (4, 64)\n",
      "Linear(in_features=64, out_features=27, bias=True):                             (27, 64)\n"
     ]
    }
   ],
   "source": [
    "# =============== DEBUG ================\n",
    "# Define a constant for the padding width\n",
    "PADDING_WIDTH: int = 80\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer_str: str = f\"{layer}:\"\n",
    "    try:\n",
    "        shape_str: str = f\"{tuple(layer.weight.shape)}\"\n",
    "    except Exception as e:\n",
    "        # print(f\"Error: {e}\")\n",
    "        shape_str: str = f\"{tuple(layer.output.shape)}\"\n",
    "    print(layer_str.ljust(PADDING_WIDTH) + shape_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 20,265\n"
     ]
    }
   ],
   "source": [
    "n_params: int = sum([p.numel() for layer in model.layers for p in layer.parameters()])\n",
    "print(f\"Number of parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 284,323\n",
      "\n",
      "Epoch: 0/140000 | Loss: 3.3803\n",
      "Epoch: 10000/140000 | Loss: 2.2808\n",
      "Epoch: 20000/140000 | Loss: 2.1533\n",
      "Epoch: 30000/140000 | Loss: 1.9664\n",
      "Epoch: 40000/140000 | Loss: 1.9128\n",
      "Epoch: 50000/140000 | Loss: 1.8098\n",
      "Epoch: 60000/140000 | Loss: 2.3568\n",
      "Epoch: 70000/140000 | Loss: 1.8409\n",
      "Epoch: 80000/140000 | Loss: 2.1253\n",
      "Epoch: 90000/140000 | Loss: 1.7409\n",
      "Epoch: 100000/140000 | Loss: 2.0641\n",
      "Epoch: 110000/140000 | Loss: 1.7671\n",
      "Epoch: 120000/140000 | Loss: 1.8623\n",
      "Epoch: 130000/140000 | Loss: 1.7862\n"
     ]
    }
   ],
   "source": [
    "# This cell took ~12 minutes to run.\n",
    "\n",
    "emb_dim: int = 24  # embedding dimension\n",
    "batch_size: int = 32\n",
    "n_c_elements: int = 2\n",
    "n_nodes: int = 256  # number of hidden nodes\n",
    "epochs: int = 140_000  # number of epochs\n",
    "learning_rate: float = 0.01  # learning rate\n",
    "\n",
    "\n",
    "model: SimpleWavenetModel = SimpleWavenetModel(\n",
    "    in_features=block_size,\n",
    "    num_hidden=n_nodes,\n",
    "    n_c_elements=n_c_elements,\n",
    "    vocab_size=n_chars,\n",
    "    embedding_dim=emb_dim,\n",
    ")\n",
    "n_params: int = sum([p.numel() for layer in model.layers for p in layer.parameters()])\n",
    "print(f\"Number of parameters: {n_params:,}\\n\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the scheduler\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[30_000, 100_000], gamma=0.1\n",
    ")\n",
    "\n",
    "# ==== Trainning Loop ====\n",
    "losses_all: list[float] = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Add mini-batches\n",
    "    idx: Tensor = torch.randint(0, X_train.shape[0], size=(batch_size,))\n",
    "    # X, y batch\n",
    "    Xb, yb = X_train[idx], y_train[idx]\n",
    "\n",
    "    # Forward pass\n",
    "    logits: Tensor = model(Xb)\n",
    "    loss: Tensor = F.cross_entropy(logits, yb)\n",
    "\n",
    "    # Backward pass\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # Record the loss\n",
    "    losses_all.append(loss.item())\n",
    "\n",
    "    if (epoch) % 10_000 == 0:\n",
    "        print(f\"Epoch: {epoch}/{epochs} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # if epoch > 50_000:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9087\n",
      "Validation loss: 2.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.0019)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss_upd(model=model, X=X_train, y=y_train, training=True)\n",
    "calculate_loss_upd(model=model, X=X_dev, y=y_dev, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_loss: Tensor = (\n",
    "    torch.tensor(losses_all, dtype=torch.float32).view(-1, 1_000).mean(dim=1)\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  # Create figure and axes\n",
    "ax.plot(avg_loss)  # Plot the data\n",
    "ax.set(xlabel=\"Epoch\", ylabel=\"Loss\", title=\"Loss vs Epoch\")  # Add labels\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karyi.\n",
      "zipman.\n",
      "esma.\n",
      "gamelle.\n",
      "shrith.\n",
      "hadley.\n",
      "alysen.\n",
      "mikioa.\n",
      "medan.\n",
      "ducce.\n",
      "arysees.\n",
      "kodi.\n",
      "terriya.\n",
      "noam.\n",
      "codecis.\n",
      "zahaan.\n",
      "talil.\n",
      "sidnova.\n",
      "siyon.\n",
      "gilis.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the model (Untrained model!)\n",
    "g = torch.Generator().manual_seed(5)\n",
    "n_names: int = 20\n",
    "\n",
    "# Set the training mode to False\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, \"training\"):\n",
    "        layer.training = False\n",
    "\n",
    "\n",
    "for _ in range(n_names):\n",
    "\n",
    "    out: list[str] = []\n",
    "    context: list[int] = [0] * block_size  # initialize with all ...\n",
    "    while True:\n",
    "        # Forward pass the neural net\n",
    "        x: Tensor = torch.tensor([context])\n",
    "        logits: Tensor = model(x)\n",
    "        probs: Tensor = F.softmax(logits, dim=1)\n",
    "\n",
    "        # Sample from the distribution\n",
    "        idx: int = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        # Shift the context window and track the samples\n",
    "        context = context[1:] + [idx]\n",
    "        out.append(idx)\n",
    "        # If we sample the special '.' token, break\n",
    "        if idx == 0:\n",
    "            break\n",
    "\n",
    "    # Decode and print the generated word\n",
    "    print(\"\".join(num_to_text.get(i) for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
