{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makemore: Wavenet\n",
    "\n",
    "- [Andrej Karpathy YouTube](https://www.youtube.com/watch?v=t3YJ5hKiMQ0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=6&ab_channel=AndrejKarpathy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "numpy    : 1.26.4\n",
      "pandas   : 2.2.1\n",
      "polars   : 0.20.18\n",
      "torch    : 2.2.2\n",
      "lightning: 2.2.1\n",
      "\n",
      "conda environment: torch_p11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,torch,lightning --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> list[str]:\n",
    "    \"\"\"Load text data from a file and return as a list of strings.\"\"\"\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        # Read all the lines as a list\n",
    "        data: list[str] = f.read().splitlines()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "fp: str = \"../../../data/names.txt\"\n",
    "names: list[str] = load_data(file_path=fp)\n",
    "\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary Of Characters And Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_token: str = \".\"\n",
    "characters: list[str] = sorted(set(\"\".join(names)))\n",
    "# Add the special token to the beginning of the list.\n",
    "characters.insert(0, special_token)\n",
    "n_chars: int = len(characters)\n",
    "\n",
    "# Convert text to numbers.\n",
    "text_to_num: dict[str, int] = {text: idx for idx, text in enumerate(characters)}\n",
    "# Convert numbers to text\n",
    "num_to_text: dict[int, str] = {idx: text for text, idx in text_to_num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, TensorDataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def build_dataset(\n",
    "    names: list[str],\n",
    "    special_token: str = \".\",\n",
    "    block_size: int = 3,\n",
    "    print_info: bool = False,\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Builds a dataset of name sequences and their corresponding character indices.\n",
    "\n",
    "    Args:\n",
    "        names (list[str]): A list of names to build the dataset from.\n",
    "        special_token (str, optional): A special token to append to the end of each name. Defaults to \".\".\n",
    "        block_size (int, optional): The size of the context window for each input sequence. Defaults to 3.\n",
    "        print_info (bool, optional): Whether to print information about the dataset generation. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Tensor, Tensor]: A tuple containing the input sequences (X) and their corresponding target indices (Y).\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in names:\n",
    "        if print_info:\n",
    "            print(w)\n",
    "        context: list[str] = [0] * block_size\n",
    "\n",
    "        for ch in w + special_token:\n",
    "            ix: int = text_to_num.get(ch)\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "\n",
    "            if print_info:\n",
    "                print(\n",
    "                    f\"{''.join([num_to_text.get(i) for i in context])} ---> {num_to_text.get(ix)}\"\n",
    "                )\n",
    "\n",
    "            # Crop and append, like a rolling window\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X: Tensor = torch.tensor(X)\n",
    "    Y: Tensor = torch.tensor(Y)\n",
    "    print(f\"\\n{X.shape=}, {Y.shape=}\")\n",
    "    return (X, Y)\n",
    "\n",
    "\n",
    "def split_data_into_train_dev_test(\n",
    "    data: Tensor | Dataset, test_size: float = 0.05, dev_size: float = 0.1, seed=42\n",
    ") -> tuple[Tensor, ...]:\n",
    "    \"\"\"\n",
    "    Splits a given PyTorch tensor `data` into training, development, and test sets.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "        data (torch.Tensor): The input tensor to be split.\n",
    "        test_size (float, optional): The fraction of the data to use for the test set. Defaults to 0.2.\n",
    "        dev_size (float, optional): The fraction of the data to use for the development set. Defaults to 0.1.\n",
    "        seed (int, optional): The random seed to use for reproducibility. Defaults to 42.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        tuple[torch.Tensor, torch.Tensor, torch.Tensor]: The training, development, and test sets as PyTorch tensors.\n",
    "    \"\"\"\n",
    "    if isinstance(data, Tensor):\n",
    "        X_train, X_test = train_test_split(data, test_size=test_size, random_state=seed)\n",
    "        X_train, X_dev = train_test_split(\n",
    "            X_train, test_size=dev_size, random_state=seed\n",
    "        )\n",
    "        result: tuple[Tensor, ...] = (X_train, X_dev, X_test)\n",
    "    if isinstance(data, Dataset):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data.data,\n",
    "            data.targets,\n",
    "            test_size=test_size,\n",
    "            random_state=seed,\n",
    "            stratify=data.targets,\n",
    "        )\n",
    "        X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "            X_train, y_train, test_size=dev_size, random_state=seed, stratify=y_train\n",
    "        )\n",
    "        result: tuple[Tensor, ...] = (X_train, X_dev, X_test, y_train, y_dev, y_test)\n",
    "\n",
    "    print(f\"{X_train.shape=}; {X_dev.shape=}; {X_test.shape=}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data: Tensor, targets: Tensor) -> None:\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(data.shape={self.data.shape}, \"\n",
    "            f\"target.shape={self.targets.shape=})\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.targets[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class CustomModule(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def __repr__(self) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def parameters(self) -> list[Tensor]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Linear(CustomModule):\n",
    "    \"\"\"\n",
    "    A linear layer implementation.\n",
    "\n",
    "    This class implements a linear layer, which performs a linear transformation on the input tensor. It takes in the number\n",
    "    of input features and output features, and optionally a bias term. The weights and biases are initialized randomly.\n",
    "\n",
    "    The `__call__` method applies the linear transformation to the input tensor and returns the output tensor.\n",
    "\n",
    "    The `parameters` method returns a list of the learnable parameters (weights and biases) of the layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, in_features: int, out_features: int, bias: bool = True, seed: int = 42\n",
    "    ) -> None:\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        # Kaiming's initialization\n",
    "        self.weight = (\n",
    "            torch.randn(in_features, out_features, generator=torch.manual_seed(seed))\n",
    "            / in_features**0.5\n",
    "        )\n",
    "        self.bias = (\n",
    "            torch.randn(out_features, generator=torch.manual_seed(seed))\n",
    "            if bias\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        self.output: Tensor = torch.matmul(x, self.weight)\n",
    "        if self.bias is not None:\n",
    "            self.output += self.bias\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self) -> list[Tensor]:\n",
    "        return [self.weight] + ([self.bias] if self.bias is not None else [])\n",
    "\n",
    "\n",
    "class BatchNorm1d(CustomModule):\n",
    "    def __init__(self, dim: int, eps: float = 1e-5, momentum: float = 0.1) -> None:\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # Parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # Buffers (trained with running `momentum update`)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        if self.training:\n",
    "            if x.ndim == 2:\n",
    "                dim: tuple[int] | int = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)\n",
    "            # Calculate the batch mean and variance\n",
    "            x_mean: Tensor = x.mean(dim=dim, keepdim=True)\n",
    "            x_var: Tensor = x.var(dim=dim, keepdim=True)\n",
    "\n",
    "        else:\n",
    "            x_mean = self.running_mean\n",
    "            x_var = self.running_var\n",
    "\n",
    "        # Normalize the input\n",
    "        x_hat: Tensor = (x - x_mean) / (x_var + self.eps).sqrt()\n",
    "        self.output: Tensor = (self.gamma * x_hat) + self.beta\n",
    "\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                # Update running mean and variance\n",
    "                self.running_mean = (\n",
    "                    1 - self.momentum\n",
    "                ) * self.running_mean + self.momentum * x_mean\n",
    "                self.running_var = (\n",
    "                    1 - self.momentum\n",
    "                ) * self.running_var + self.momentum * x_var\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self) -> list[Tensor]:\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "class Tanh(CustomModule):\n",
    "    \"\"\"A custom module that applies the hyperbolic tangent activation function to the input tensor.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        self.output = torch.tanh(x)\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self) -> list[Tensor]:\n",
    "        return []\n",
    "\n",
    "\n",
    "class Embedding(CustomModule):\n",
    "    \"\"\"A custom module that creates an embedding lookup table from a given\n",
    "    vocabulary size and embedding dimension.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, seed: int = 42) -> None:\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.weight = torch.randn(\n",
    "            (vocab_size, embedding_dim), generator=torch.manual_seed(seed)\n",
    "        )\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.vocab_size}, {self.embedding_dim})\"\n",
    "\n",
    "    def __call__(self, idx: int) -> Tensor:\n",
    "        self.output = self.weight[idx]\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self) -> list[Tensor]:\n",
    "        \"\"\"Get all the parameters.\"\"\"\n",
    "        return [self.weight]\n",
    "\n",
    "\n",
    "class Flatten(CustomModule):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{__class__.__name__}()\"\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        self.output = x.view(x.shape[0], -1)\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Get all the parameters.\"\"\"\n",
    "        return []\n",
    "\n",
    "\n",
    "class Sequential(CustomModule):\n",
    "    \"\"\"A custom module that applies a sequence of other custom modules to the input tensor.\"\"\"\n",
    "\n",
    "    def __init__(self, layers: list[CustomModule]) -> None:\n",
    "        self.layers = layers\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{__class__.__name__}({len(self.layers)})\"\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Get parameters of all layers and stretch them out into one list.\"\"\"\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n",
      "\n",
      "X.shape=torch.Size([32, 3]), Y.shape=torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "X, y = build_dataset(names=names[:5], block_size=3, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X.shape=torch.Size([228152, 3]), Y.shape=torch.Size([228152])\n",
      "X_train.shape=torch.Size([195069, 3]); X_dev.shape=torch.Size([21675, 3]); X_test.shape=torch.Size([11408, 3])\n"
     ]
    }
   ],
   "source": [
    "X, y = build_dataset(names=names, block_size=3, print_info=False)\n",
    "data: Dataset = MyDataset(X, y)\n",
    "\n",
    "X_train, X_dev, X_test, y_train, y_dev, y_test = split_data_into_train_dev_test(\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment!\n",
    "\n",
    "- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 18,024\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "g = torch.Generator().manual_seed(5)\n",
    "\n",
    "emb_dim: int = 10  # embedding dimension\n",
    "block_size: int = 3  # size of the context window for each input sequence\n",
    "M: int = emb_dim * block_size  # number of inputs\n",
    "n_nodes: int = 300  # number of hidden nodes\n",
    "learning_rate: float = 0.1  # learning rate\n",
    "batch_size: int = 32  # batch size\n",
    "epochs: int = 140_000  # number of epochs\n",
    "\n",
    "layers: list[Any] = [\n",
    "    Embedding(vocab_size=n_chars, embedding_dim=emb_dim, seed=42),\n",
    "    Flatten(),\n",
    "    Linear(in_features=M, out_features=n_nodes, bias=False),\n",
    "    BatchNorm1d(dim=n_nodes),\n",
    "    Tanh(),\n",
    "    Linear(in_features=n_nodes, out_features=n_chars, bias=False),\n",
    "    BatchNorm1d(dim=n_chars),\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Make last layer less confident\n",
    "    # layers[-1].weight *= 0.1  # Default: w/o BatchNorm\n",
    "    layers[-1].gamma *= 0.1  # with BatchNorm\n",
    "\n",
    "    # Apply gain to the other layers\n",
    "    for layer in layers[:-1]:\n",
    "        if isinstance(layer, Linear):\n",
    "            # Scale the weights of all other linear layers by a gain factor.\n",
    "            # layer.weight *= 5 / 3 # Default: w/o BatchNorm\n",
    "            layer.weight *= 1.0  # with BatchNorm: No scaling\n",
    "\n",
    "# Parameters Collection\n",
    "parameters: list[Tensor] = [p for layer in layers for p in layer.parameters()]\n",
    "print(f\"Total params: {sum(p.numel() for p in parameters):,}\")\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/140000 | Loss: 3.3159\n"
     ]
    }
   ],
   "source": [
    "# Use The optimal learning rate to train the model\n",
    "losses_all: list[float] = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Add mini-batches\n",
    "    idx: Tensor = torch.randint(0, X_train.shape[0], size=(batch_size,))\n",
    "    # X, y batch\n",
    "    Xb, yb = X_train[idx], y_train[idx]\n",
    "\n",
    "    # Forward pass\n",
    "    x: Tensor = Xb\n",
    "    for layer in layers:\n",
    "        x: Tensor = layer(x)  # Logits: Apply the linear layer\n",
    "    loss: Tensor = F.cross_entropy(x, yb)\n",
    "\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        # Reset gradients\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # learning rate decay\n",
    "    learning_rate: float = (\n",
    "        0.1 if epoch < 70_000 else (0.01 if epoch < 85_000 else 0.001)\n",
    "    )\n",
    "\n",
    "    # Update the parameters\n",
    "    for p in parameters:\n",
    "        p.data -= learning_rate * p.grad\n",
    "\n",
    "    # Record the loss\n",
    "    losses_all.append(loss.item())\n",
    "\n",
    "    if (epoch) % 10_000 == 0:\n",
    "        print(f\"Epoch: {epoch}/{epochs} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    if epoch > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7592,  1.0786,  0.8008,  1.6781,  1.2758,  1.2908,  0.6107,  1.3340,\n",
       "        -0.2326,  0.0402], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embeddings of index 2\n",
    "layers[0](2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafyuw.\n",
      ".\n",
      "parales.\n",
      "zfgfixo.\n",
      "erihrbvblxf.\n",
      "yfp.\n",
      "ajnven.\n",
      "opzioa.\n",
      "medai.\n",
      "huccndarnldesqucdicucunnye.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the model\n",
    "\n",
    "for layer in layers:\n",
    "    layer.training = False\n",
    "\n",
    "\n",
    "g = torch.Generator().manual_seed(5)\n",
    "n_names: int = 10\n",
    "\n",
    "for _ in range(n_names):\n",
    "\n",
    "    out: list[str] = []\n",
    "    context: list[int] = [0] * block_size  # initialize with all ...\n",
    "    while True:\n",
    "        # forward pass the neural net\n",
    "        x: Tensor = torch.tensor([context])\n",
    "\n",
    "        for layer in layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        logits: Tensor = x\n",
    "        probs: Tensor = F.softmax(logits, dim=1)\n",
    "        # sample from the distribution\n",
    "        idx: int = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        # Shift the context window and track the samples\n",
    "        context = context[1:] + [idx]\n",
    "        out.append(idx)\n",
    "        # If we sample the special '.' token, break\n",
    "        if idx == 0:\n",
    "            break\n",
    "\n",
    "    # Decode and print the generated word\n",
    "    print(\"\".join(num_to_text.get(i) for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2!\n",
    "\n",
    "- The current inplementation flattens the entire data into a 2-D array which is not optimal when the block_size is large.\n",
    "\n",
    "```py\n",
    "# e.g. If the block_size is 3\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- Implement the [Wavenet](https://arxiv.org/pdf/1609.03499) architecture shown below:\n",
    "\n",
    "<img src=\"../images/Wavenet.png\" width=\"500\">\n",
    "\n",
    "- The input is combined to form several bigrams which are further combined at every layer in the network.\n",
    "  - i.e. if you have 8 characters in the input layer, you will have 4 bigrams (e.g. `ab`, `cd`, `ef`, `gh`).\n",
    "  - `ab` is combined with `cd` to form `abcd`, `ef` is combined with `gh` to form `efgh` and so on.\n",
    "  - finally, `abcd` and `efgh` are combined and used to predict the output.\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "```text\n",
    "Combining each input layer with the next one to form bigrams:\n",
    "\n",
    "FlattenConsecutive(2):   (4, 4, 20)   # i.e. 4 groups (1 2)   (3 4)   (5 6)   (7 8) \n",
    "...\n",
    "FlattenConsecutive(2):   (4, 2, 600)   # i.e. 2 groups (1 2 3 4)   (5 6 7 8) \n",
    "...\n",
    "FlattenConsecutive(2):   (4, 600)   # (4, 1, 600) i.e. 1 group (1 2 3 4 5 6 7 8) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 123,597\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "g = torch.Generator().manual_seed(5)\n",
    "\n",
    "emb_dim: int = 10  # embedding dimension\n",
    "block_size: int = 8  # size of the context window for each input sequence\n",
    "M: int = emb_dim * block_size  # number of inputs\n",
    "n_nodes: int = 300  # number of hidden nodes\n",
    "learning_rate: float = 0.1  # learning rate\n",
    "batch_size: int = 32  # batch size\n",
    "epochs: int = 140_000  # number of epochs\n",
    "\n",
    "# NEW!\n",
    "model: Sequential = Sequential(\n",
    "    layers=[\n",
    "        Embedding(vocab_size=n_chars, embedding_dim=emb_dim, seed=42),\n",
    "        Flatten(),\n",
    "        Linear(in_features=M, out_features=n_nodes, bias=False),\n",
    "        BatchNorm1d(dim=n_nodes),\n",
    "        Tanh(),\n",
    "        Linear(in_features=n_nodes, out_features=n_nodes, bias=False),\n",
    "        BatchNorm1d(dim=n_nodes),\n",
    "        Tanh(),\n",
    "        Linear(in_features=n_nodes, out_features=n_chars, bias=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Make last layer less confident\n",
    "    model.layers[-1].weight *= 0.1  # Default: w/o BatchNorm\n",
    "\n",
    "# Parameters Collection\n",
    "parameters: list[Tensor] = model.parameters()  # NEW!\n",
    "print(f\"Total params: {sum(p.numel() for p in parameters):,}\")\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X.shape=torch.Size([228152, 8]), Y.shape=torch.Size([228152])\n",
      "X_train.shape=torch.Size([195069, 8]); X_dev.shape=torch.Size([21675, 8]); X_test.shape=torch.Size([11408, 8])\n"
     ]
    }
   ],
   "source": [
    "X, y = build_dataset(names=names, block_size=block_size, print_info=False)\n",
    "data: Dataset = MyDataset(X, y)\n",
    "\n",
    "X_train, X_dev, X_test, y_train, y_dev, y_test = split_data_into_train_dev_test(\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "........ ---> e\n",
      ".......e ---> m\n",
      "......em ---> m\n",
      ".....emm ---> a\n",
      "....emma ---> .\n",
      "olivia\n",
      "........ ---> o\n",
      ".......o ---> l\n",
      "......ol ---> i\n",
      ".....oli ---> v\n",
      "....oliv ---> i\n",
      "...olivi ---> a\n",
      "..olivia ---> .\n",
      "\n",
      "X.shape=torch.Size([12, 8]), Y.shape=torch.Size([12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  5],\n",
       "         [ 0,  0,  0,  0,  0,  0,  5, 13],\n",
       "         [ 0,  0,  0,  0,  0,  5, 13, 13],\n",
       "         [ 0,  0,  0,  0,  5, 13, 13,  1],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0, 15],\n",
       "         [ 0,  0,  0,  0,  0,  0, 15, 12],\n",
       "         [ 0,  0,  0,  0,  0, 15, 12,  9],\n",
       "         [ 0,  0,  0,  0, 15, 12,  9, 22],\n",
       "         [ 0,  0,  0, 15, 12,  9, 22,  9],\n",
       "         [ 0,  0, 15, 12,  9, 22,  9,  1]]),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 characters are required to predict the next character\n",
    "build_dataset(names=names[:2], block_size=block_size, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_s.shape = torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  5, 12,  9, 19],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0, 15, 12],\n",
       "        [ 0,  0,  1,  4,  4, 25, 12,  9]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size: int = 4\n",
    "idx: Tensor = torch.randint(0, X_train.shape[0], (batch_size,))\n",
    "X_s, y_s = X_train[idx], y_train[idx]\n",
    "logits: Tensor = model(X_s)\n",
    "print(f\"{X_s.shape = }\")\n",
    "\n",
    "# 4 samples each containing a block size of `block_size`\n",
    "X_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr>\n",
    "\n",
    "```py\n",
    "M: int = emb_dim * block_size  # number of inputs\n",
    "\n",
    "model: Sequential = Sequential(\n",
    "    layers=[\n",
    "        Embedding(vocab_size=n_chars, embedding_dim=emb_dim, seed=42), # 1st layer\n",
    "        Flatten(),  # 2nd layer\n",
    "        Linear(in_features=M, out_features=n_nodes, bias=False), # 3rd layer\n",
    "        BatchNorm1d(dim=n_nodes), # 4th layer\n",
    "        Tanh(),  \n",
    "        Linear(in_features=n_nodes, out_features=n_chars, bias=False),\n",
    "        BatchNorm1d(dim=n_chars), \n",
    "    ]\n",
    ")\n",
    "```\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Embedding(27, 10),\n",
       " Flatten(),\n",
       " Linear(80, 300),\n",
       " BatchNorm1d(),\n",
       " Tanh(),\n",
       " Linear(300, 300),\n",
       " BatchNorm1d(),\n",
       " Tanh(),\n",
       " Linear(300, 27)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st layer: Output of Embedding layer\n",
    "model.layers[0].output.shape  # (Batch_size, block_size, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd layer: Output of Flatten layer\n",
    "# It has been reshaped to ( batch_size, (block_size, emb_dim) ) from (batch_size, block_size, emb_dim)\n",
    "# It was flattened because the next (Linear) layer expects a 2-D input\n",
    "model.layers[1].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd layer: Output of Linear layer\n",
    "# Matrix Multiplication of the input with the weights\n",
    "model.layers[2].output.shape  # (batch_size, block_size) @ (block_size, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4th layer: Output of BatchNorm layer\n",
    "# Normalize the output of the previous layer\n",
    "model.layers[3].output.shape  # (batch_size, block_size) @ (block_size, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The current implementation of the Linear Layer\n",
    "# (4, 8, 10) is flattened to (4, 80)\n",
    "# (4, 80) @ (80, 300) + (300,) => (4, 300)\n",
    "(\n",
    "    torch.randn((4, block_size * emb_dim))  # (4, 80)\n",
    "    @ torch.randn((block_size * emb_dim, n_nodes))  # (80, 300)\n",
    "    + torch.randn(n_nodes)  # (300,)\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_1.shape = torch.Size([4, 4, 20])\n",
      "res_2.shape = torch.Size([4, 4, 20])\n"
     ]
    }
   ],
   "source": [
    "# Implement Wavenet\n",
    "#   1       2       3       4     i.e.  n_combined_input = 4 groups\n",
    "# (1 2)   (3 4)   (5 6)   (7 8)\n",
    "# i.e. we want: (batch_size, n_combined_input, -1)\n",
    "# i.e. from (4, 8, 10) to (4, 4, 20) instead of (4, 80)\n",
    "\n",
    "res_1: Tensor = torch.randn((4, block_size * emb_dim)).view(\n",
    "    4, -1, (block_size * emb_dim) // 4\n",
    ")\n",
    "# OR\n",
    "res_2: Tensor = torch.randn((4, block_size * emb_dim)).view(\n",
    "    4, block_size // 2, (emb_dim * 2)\n",
    ")\n",
    "print(f\"{res_1.shape = }\")\n",
    "print(f\"{res_2.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenConsecutive(CustomModule):\n",
    "    \"\"\"A custom module that flattens consecutive elements in the input tensor along\n",
    "    the second dimension.\"\"\"\n",
    "\n",
    "    def __init__(self, n_c_elements: int) -> None:\n",
    "        \"\"\"\n",
    "        Note:\n",
    "            n_c_elements: the number of consecutive elements to concatenate.\n",
    "        \"\"\"\n",
    "        self.n_c_elements = n_c_elements\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{__class__.__name__}({self.n_c_elements})\"\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        # B: batch size, L: sequence length, C: number of channels\n",
    "        B, L, C = x.shape\n",
    "        assert (\n",
    "            L % self.n_c_elements == 0\n",
    "        ), f\"The length of the input tensor must be a multiple of {self.n_c_elements}.\"\n",
    "\n",
    "        x = x.view(B, L // self.n_c_elements, C * self.n_c_elements)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "\n",
    "        self.output = x\n",
    "        return self.output\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Get all the parameters.\"\"\"\n",
    "        return []\n",
    "\n",
    "\n",
    "def calculate_loss_upd(X: Tensor, y: Tensor, training: True) -> Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the loss for the given input tensors `X` and `y`.\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): The input tensor.\n",
    "        y (torch.Tensor): The target tensor.\n",
    "        training (bool): Indicates whether the model is in training mode or not.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The calculated loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the training mode to False\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, \"training\"):\n",
    "            layer.training = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        logits: Tensor = model(X)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss: Tensor = F.cross_entropy(logits, y)\n",
    "        result: str = (\n",
    "            f\"Training loss: {loss:.4f}\" if training else f\"Validation loss: {loss:.4f}\"\n",
    "        )\n",
    "        print(result)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_1.shape = torch.Size([4, 8, 10])\n",
      "fl(res_1).shape = torch.Size([4, 4, 20])\n"
     ]
    }
   ],
   "source": [
    "res_1: Tensor = torch.randn(4, block_size, emb_dim)\n",
    "fl = FlattenConsecutive(n_c_elements=2)\n",
    "# Concatenate 2 consecutive elements. i.e. (1 2), (3 4), (5 6), (7 8)\n",
    "print(f\"{res_1.shape = }\")\n",
    "print(f\"{fl(res_1).shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_2.shape = torch.Size([4, 8, 10])\n",
      "fl(res_2).shape = torch.Size([4, 2, 40])\n"
     ]
    }
   ],
   "source": [
    "res_2: Tensor = torch.randn(4, block_size, emb_dim)\n",
    "fl = FlattenConsecutive(n_c_elements=4)\n",
    "# Concatenate 4 consecutive elements. i.e. (1 2 3 4), (5 6 7 8) etc\n",
    "print(f\"{res_2.shape = }\")\n",
    "print(f\"{fl(res_2).shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 20,073\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "g = torch.Generator().manual_seed(5)\n",
    "\n",
    "emb_dim: int = 10  # embedding dimension\n",
    "block_size: int = 8  # size of the context window for each input sequence\n",
    "M: int = emb_dim * block_size  # number of inputs\n",
    "n_nodes: int = 64  # number of hidden nodes\n",
    "learning_rate: float = 0.1  # learning rate\n",
    "batch_size: int = 32  # batch size\n",
    "epochs: int = 140_000  # number of epochs\n",
    "\n",
    "# NEW!\n",
    "n_c_elements: int = 2\n",
    "model: Sequential = Sequential(\n",
    "    layers=[\n",
    "        Embedding(vocab_size=n_chars, embedding_dim=emb_dim, seed=42),\n",
    "        # ===\n",
    "        FlattenConsecutive(n_c_elements=n_c_elements),\n",
    "        Linear(in_features=emb_dim * n_c_elements, out_features=n_nodes, bias=False),\n",
    "        BatchNorm1d(dim=n_nodes),\n",
    "        Tanh(),\n",
    "        # === layer 1\n",
    "        FlattenConsecutive(n_c_elements=n_c_elements),\n",
    "        Linear(in_features=n_nodes * n_c_elements, out_features=n_nodes, bias=False),\n",
    "        BatchNorm1d(dim=n_nodes),\n",
    "        Tanh(),\n",
    "        # === layer 2\n",
    "        FlattenConsecutive(n_c_elements=n_c_elements),\n",
    "        Linear(in_features=n_nodes * n_c_elements, out_features=n_nodes, bias=False),\n",
    "        BatchNorm1d(dim=n_nodes),\n",
    "        Tanh(),\n",
    "        # === layer 3\n",
    "        Linear(in_features=n_nodes, out_features=n_chars),\n",
    "    ]\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Make last layer less confident\n",
    "    model.layers[-1].weight *= 0.1  # Default: w/o BatchNorm\n",
    "\n",
    "# Parameters Collection\n",
    "parameters: list[Tensor] = model.parameters()  # NEW!\n",
    "print(f\"Total params: {sum(p.numel() for p in parameters):,}\")\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X.shape=torch.Size([228152, 8]), Y.shape=torch.Size([228152])\n",
      "X_train.shape=torch.Size([195069, 8]); X_dev.shape=torch.Size([21675, 8]); X_test.shape=torch.Size([11408, 8])\n",
      "\n",
      "X_s.shape = torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  5, 12,  9, 19],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0, 15, 12],\n",
       "        [ 0,  0,  1,  4,  4, 25, 12,  9]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = build_dataset(names=names, block_size=block_size, print_info=False)\n",
    "data: Dataset = MyDataset(X, y)\n",
    "\n",
    "X_train, X_dev, X_test, y_train, y_dev, y_test = split_data_into_train_dev_test(\n",
    "    data=data\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "batch_size: int = 4\n",
    "idx: Tensor = torch.randint(0, X_train.shape[0], (batch_size,))\n",
    "X_s, y_s = X_train[idx], y_train[idx]\n",
    "logits: Tensor = model(X_s)\n",
    "print(f\"{X_s.shape = }\")\n",
    "\n",
    "# 4 samples each containing a block size of `block_size`\n",
    "X_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(27, 10):       (4, 8, 10)\n",
      "FlattenConsecutive(2):   (4, 4, 20)\n",
      "Linear(20, 64):          (4, 4, 64)\n",
      "BatchNorm1d():           (4, 4, 64)\n",
      "Tanh():                  (4, 4, 64)\n",
      "FlattenConsecutive(2):   (4, 2, 128)\n",
      "Linear(128, 64):         (4, 2, 64)\n",
      "BatchNorm1d():           (4, 2, 64)\n",
      "Tanh():                  (4, 2, 64)\n",
      "FlattenConsecutive(2):   (4, 128)\n",
      "Linear(128, 64):         (4, 64)\n",
      "BatchNorm1d():           (4, 64)\n",
      "Tanh():                  (4, 64)\n",
      "Linear(64, 27):          (4, 27)\n"
     ]
    }
   ],
   "source": [
    "# Define a constant for the padding width\n",
    "PADDING_WIDTH: int = 25\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer_str: str = f\"{layer}:\"\n",
    "    shape_str: str = f\"{tuple(layer.output.shape)}\"\n",
    "    print(layer_str.ljust(PADDING_WIDTH) + shape_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X.shape=torch.Size([228152, 8]), Y.shape=torch.Size([228152])\n",
      "X_train.shape=torch.Size([195069, 8]); X_dev.shape=torch.Size([21675, 8]); X_test.shape=torch.Size([11408, 8])\n"
     ]
    }
   ],
   "source": [
    "X, y = build_dataset(names=names, block_size=block_size, print_info=False)\n",
    "data: Dataset = MyDataset(X, y)\n",
    "\n",
    "X_train, X_dev, X_test, y_train, y_dev, y_test = split_data_into_train_dev_test(\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 283,555\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "g = torch.Generator().manual_seed(5)\n",
    "\n",
    "emb_dim: int = 24  # embedding dimension\n",
    "block_size: int = 8  # size of the context window for each input sequence\n",
    "M: int = emb_dim * block_size  # number of inputs\n",
    "n_nodes: int = 256  # number of hidden nodes\n",
    "learning_rate: float = 0.1  # learning rate\n",
    "batch_size: int = 32  # batch size\n",
    "epochs: int = 140_000  # number of epochs\n",
    "\n",
    "# NEW!\n",
    "n_c_elements: int = 2\n",
    "model: Sequential = Sequential(\n",
    "    layers=[\n",
    "        Embedding(vocab_size=n_chars, embedding_dim=emb_dim, seed=42),\n",
    "        # === Input Layer\n",
    "        FlattenConsecutive(n_c_elements=n_c_elements),\n",
    "        Linear(in_features=emb_dim * n_c_elements, out_features=n_nodes, bias=False),\n",
    "        BatchNorm1d(dim=n_nodes),\n",
    "        Tanh(),\n",
    "        # === Layer 1\n",
    "        FlattenConsecutive(n_c_elements=n_c_elements),\n",
    "        Linear(in_features=n_nodes * n_c_elements, out_features=n_nodes, bias=False),\n",
    "        BatchNorm1d(dim=n_nodes),\n",
    "        Tanh(),\n",
    "        # === Layer 2\n",
    "        FlattenConsecutive(n_c_elements=n_c_elements),\n",
    "        Linear(in_features=n_nodes * n_c_elements, out_features=n_nodes, bias=False),\n",
    "        BatchNorm1d(dim=n_nodes),\n",
    "        Tanh(),\n",
    "        # === Layer 3\n",
    "        Linear(in_features=n_nodes, out_features=n_chars),\n",
    "    ]\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Make last layer less confident\n",
    "    model.layers[-1].weight *= 0.1  # Default: w/o BatchNorm\n",
    "\n",
    "# Parameters Collection\n",
    "parameters: list[Tensor] = model.parameters()  # NEW!\n",
    "print(f\"Total params: {sum(p.numel() for p in parameters):,}\")\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/140000 | Loss: 3.6260\n",
      "Epoch: 10000/140000 | Loss: 1.9061\n",
      "Epoch: 20000/140000 | Loss: 2.0331\n",
      "Epoch: 30000/140000 | Loss: 1.9165\n",
      "Epoch: 40000/140000 | Loss: 1.7180\n",
      "Epoch: 50000/140000 | Loss: 2.1953\n",
      "Epoch: 60000/140000 | Loss: 1.8998\n",
      "Epoch: 70000/140000 | Loss: 1.2714\n",
      "Epoch: 80000/140000 | Loss: 1.9364\n",
      "Epoch: 90000/140000 | Loss: 1.9078\n",
      "Epoch: 100000/140000 | Loss: 1.9687\n",
      "Epoch: 110000/140000 | Loss: 1.9149\n",
      "Epoch: 120000/140000 | Loss: 1.5031\n",
      "Epoch: 130000/140000 | Loss: 1.9494\n"
     ]
    }
   ],
   "source": [
    "# ==== Trainning Loop ====\n",
    "losses_all: list[float] = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Add mini-batches\n",
    "    idx: Tensor = torch.randint(0, X_train.shape[0], size=(batch_size,))\n",
    "    # X, y batch\n",
    "    Xb, yb = X_train[idx], y_train[idx]\n",
    "\n",
    "    # Forward pass\n",
    "    logits: Tensor = model(Xb)\n",
    "    loss: Tensor = F.cross_entropy(logits, yb)\n",
    "\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        # Reset gradients\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # learning rate decay\n",
    "    learning_rate: float = (\n",
    "        0.1 if epoch < 70_000 else (0.01 if epoch < 90_000 else 0.001)\n",
    "    )\n",
    "\n",
    "    # Update the parameters\n",
    "    for p in parameters:\n",
    "        p.data -= learning_rate * p.grad\n",
    "\n",
    "    # Record the loss\n",
    "    losses_all.append(loss.item())\n",
    "\n",
    "    if (epoch) % 10_000 == 0:\n",
    "        print(f\"Epoch: {epoch}/{epochs} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # if epoch > 100:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.7748\n",
      "Validation loss: 1.9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.9630)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss_upd(X=X_train, y=y_train, training=True)\n",
    "calculate_loss_upd(X=X_dev, y=y_dev, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_loss: Tensor = (\n",
    "    torch.tensor(losses_all, dtype=torch.float32).view(-1, 1_000).mean(dim=1)\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  # Create figure and axes\n",
    "ax.plot(avg_loss)  # Plot the data\n",
    "ax.set(xlabel=\"Epoch\", ylabel=\"Loss\", title=\"Loss vs Epoch\")  # Add labels\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karyia.\n",
      "kamarie.\n",
      "margavious.\n",
      "shrithy.\n",
      "chafp.\n",
      "alaikn.\n",
      "mikena.\n",
      "medalyn.\n",
      "cinda.\n",
      "jeden.\n",
      "kodi.\n",
      "terrale.\n",
      "noama.\n",
      "odecia.\n",
      "zahaay.\n",
      "talil.\n",
      "sidney.\n",
      "gily.\n",
      "orgin.\n",
      "stefane.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the model\n",
    "g = torch.Generator().manual_seed(5)\n",
    "n_names: int = 20\n",
    "\n",
    "# Set the training mode to False\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, \"training\"):\n",
    "        layer.training = False\n",
    "\n",
    "\n",
    "for _ in range(n_names):\n",
    "\n",
    "    out: list[str] = []\n",
    "    context: list[int] = [0] * block_size  # initialize with all ...\n",
    "    while True:\n",
    "        # forward pass the neural net\n",
    "        x: Tensor = torch.tensor([context])\n",
    "\n",
    "        logits: Tensor = model(x)\n",
    "        probs: Tensor = F.softmax(logits, dim=1)\n",
    "        # sample from the distribution\n",
    "        idx: int = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        # Shift the context window and track the samples\n",
    "        context = context[1:] + [idx]\n",
    "        out.append(idx)\n",
    "        # If we sample the special '.' token, break\n",
    "        if idx == 0:\n",
    "            break\n",
    "\n",
    "    # Decode and print the generated word\n",
    "    print(\"\".join(num_to_text.get(i) for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
