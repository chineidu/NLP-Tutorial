{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Uniform Manifold Approximation and Projection (UMAP)](https://towardsdatascience.com/dimensionality-reduction-for-data-visualization-pca-vs-tsne-vs-umap-be4aa7b1cb29)\n",
    "  \n",
    "- UMAP is a dimension reduction technique for embedding high-dimensional data into a lower-dimensional space while preserving the data's intrinsic structure. \n",
    "\n",
    "- It is particularly well-suited for visualizing high-dimensional data sets, as it can effectively preserve the `global` and `local` structure of the data while being `computationally efficient`.\n",
    "-  It is a manifold learning technique, which means that it assumes that the data lies on a lower-dimensional manifold embedded in a higher-dimensional space. \n",
    "\n",
    "\n",
    "## Advantages of UMAP\n",
    "\n",
    "- **Preservation of Global Structure:** UMAP effectively preserves the global structure of the data, meaning that the relative positions of data points in the low-dimensional embedding are consistent with their relative positions in the original high-dimensional space. This is important for tasks such as `visualization` and `anomaly detection`.\n",
    "\n",
    "- **Preservation of Local Structure:** UMAP also preserves the local structure of the data, meaning that the distances and densities of neighboring data points are well-represented in the low-dimensional embedding. This is important for tasks such as clustering and classification.\n",
    "\n",
    "- **Computational Efficiency:** UMAP is computationally efficient, making it scalable to large datasets. The algorithm utilizes a stochastic approach that scales linearly with the number of data points, allowing it to handle large datasets without requiring excessive computational resources.\n",
    "\n",
    "- **Visualization Quality:** UMAP produces high-quality visualizations of high-dimensional data, making it a valuable tool for exploring and understanding complex datasets. The embeddings generated by UMAP often reveal patterns and relationships that are difficult to discern in the original high-dimensional space.\n",
    "\n",
    "## Applications\n",
    "\n",
    "- **Data Visualization:** UMAP is particularly well-suited for visualizing high-dimensional data, as it can effectively preserve the global and local structure of the data while producing clear and informative visualizations.\n",
    "\n",
    "- **Exploratory Data Analysis:** UMAP can be used to explore and analyze high-dimensional data to identify patterns, trends, and anomalies. By embedding the data into a lower-dimensional space, UMAP can reveal hidden relationships and structures that may not be apparent in the original high-dimensional representation.\n",
    "\n",
    "- **Dimensionality Reduction for Machine Learning:** UMAP can be used as a dimensionality reduction technique to prepare high-dimensional data for machine learning algorithms. By reducing the dimensionality of the data, UMAP can improve the performance and efficiency of machine learning models without compromising their accuracy.\n",
    "\n",
    "- **Clustering and Segmentation:** UMAP can be used for clustering and segmentation tasks, where the goal is to group data points into meaningful clusters based on their similarities. The low-dimensional embedding produced by UMAP can facilitate the identification of clusters and the separation of different data groups.\n",
    "\n",
    "- **Anomaly Detection:** UMAP can be used to detect anomalies in high-dimensional data. By analyzing the distribution of data points in the low-dimensional embedding, UMAP can identify outliers and data points that deviate from the expected structure of the data.\n",
    "\n",
    "- **Natural Language Processing (NLP):** UMAP is increasingly being used in NLP tasks, such as topic modeling and document embedding. It can help to identify and represent the latent topics in text corpora and create semantic representations of documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, TypeAlias, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich import print\n",
    "import torch\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 60000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "path: str = \"mnist\"\n",
    "mnist: Dataset = load_dataset(path=path)\n",
    "\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       " 'label': 5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.get(\"train\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "mnist.get(\"train\")[0].get(\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the data\n",
    "np.array(mnist.get(\"train\")[0].get(\"image\")).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9398f5bf0a2406a8594b4fd5da08d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd642640c8640d8924c767268b522ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label', 'array'],\n",
       "        num_rows: 60000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label', 'array'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist: Dataset = mnist.map(lambda x: {\"array\": np.array(x.get(\"image\")).reshape(-1)})\n",
    "\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.get(\"train\")[0].get(\"array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min and max\n",
    "min(mnist.get(\"train\")[0].get(\"array\")), max(mnist.get(\"train\")[0].get(\"array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e60183124247a7b6daa343d80cb576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d4d314af7d4376b5c3441d5181f894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize the data\n",
    "mnist: Dataset = mnist.map(lambda x: {\"array\": np.array(x.get(\"array\")) / 255.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min and max\n",
    "min(mnist.get(\"train\")[0].get(\"array\")), max(mnist.get(\"train\")[0].get(\"array\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP Dimensionality Reduction\n",
    "\n",
    "```sh\n",
    "pip install umap-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
