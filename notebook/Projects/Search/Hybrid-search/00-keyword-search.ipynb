{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, TypeAlias, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich import print\n",
    "import torch\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'there', 'good', 'man!'],\n",
       " ['It', 'is', 'quite', 'windy', 'in', 'London'],\n",
       " ['How', 'is', 'the', 'weather', 'today?']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi, BM25L\n",
    "\n",
    "\n",
    "corpus: list[str] = [\n",
    "    \"Hello there good man!\",\n",
    "    \"It is quite windy in London\",\n",
    "    \"How is the weather today?\",\n",
    "]\n",
    "\n",
    "tokenized_corpus: list[list[Any]] = [doc.split(\" \") for doc in corpus]\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rank_bm25.BM25Okapi at 0x7f8a3a42f220>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "- It's important to note that we also need to tokenize our query, and apply the same preprocessing steps we did to the documents in order to have an apples-to-apples comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.93729472, 0.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query: str = \"windy London\"\n",
    "tokenized_query = query.split(\" \")\n",
    "\n",
    "doc_scores: npt.NDArray[np.float_] = bm25.get_scores(tokenized_query)\n",
    "doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is quite windy in London']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of getting the document scores, you can also just retrieve the best documents with\n",
    "bm25.get_top_n(query=tokenized_query, documents=corpus, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "## Using SpaCy And Another Variant of BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 04:33:18.320321: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'This'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'is'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sentence'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'This'\u001b[0m, \u001b[32m'is'\u001b[0m, \u001b[32m'a'\u001b[0m, \u001b[32m'sentence'\u001b[0m, \u001b[32m'.'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.lang.en import English\n",
    "\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp: English = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    disable=[\"tagger\", \"lemmatizer\", \"parser\", \"ner\", \"attribute_ruler\"],\n",
    ")\n",
    "\n",
    "# Process a text\n",
    "text: str = \"This is a sentence.\"\n",
    "doc: Doc = nlp.tokenizer(text)\n",
    "\n",
    "# Only the tokenizer is applied\n",
    "print([x.text for x in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'there', 'good', 'man', '!'],\n",
       " ['It', 'is', 'quite', 'windy', 'in', 'London'],\n",
       " ['How', 'is', 'the', 'weather', 'today', '?']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus: list[list[Any]] = [\n",
    "    [token.text for token in nlp.tokenizer(text)] for text in corpus\n",
    "]\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, corpus: list[str]) -> None:\n",
    "        self.corpus = corpus\n",
    "        # self._tok_corpus = None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(num_corpus={len(self.corpus)})\"\n",
    "\n",
    "    def tokenize_corpus(self) -> list[list[Any]]:\n",
    "        \"\"\"This is used to tokenize the entire corpus.\"\"\"\n",
    "        tok_corpus: list[list[Any]] = [\n",
    "            self._tokenized_document(document=text) for text in self.corpus\n",
    "        ]\n",
    "        return tok_corpus\n",
    "\n",
    "    def tokenized_doc(self, document: str) -> list[str]:\n",
    "        \"\"\"This is used to tokenize a single document/query.\"\"\"\n",
    "        tok_doc: list[str] = self._tokenized_document(document=document)\n",
    "        return tok_doc\n",
    "\n",
    "    @staticmethod\n",
    "    def _tokenized_document(document: str) -> list[str]:\n",
    "        \"\"\"This is a helper function used to tokenize a single document.\"\"\"\n",
    "        tok_doc: list[str] = [token.text.lower() for token in nlp.tokenizer(document)]\n",
    "        return tok_doc\n",
    "\n",
    "    @property\n",
    "    def tok_corpus(self) -> list[list[Any]]:\n",
    "        tok_corpus = self.tokenize_corpus()\n",
    "        return tok_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(num_corpus=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer: Tokenizer = Tokenizer(corpus=corpus)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', 'there', 'good', 'man', '!'],\n",
       " ['it', 'is', 'quite', 'windy', 'in', 'london'],\n",
       " ['how', 'is', 'the', 'weather', 'today', '?']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus: list[list[str]] = tokenizer.tokenize_corpus()\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['windy', 'london']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25l = BM25L(tokenized_corpus)\n",
    "\n",
    "\n",
    "query: str = \"windy London\"\n",
    "tokenized_query: list[str] = tokenizer.tokenized_doc(document=query)\n",
    "\n",
    "tokenized_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 2.41704352, 0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_scores: npt.NDArray[np.float_] = bm25l.get_scores(query=tokenized_query)\n",
    "doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is quite windy in London']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25l.get_top_n(query=tokenized_query, documents=corpus, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus: list[str] = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"The enigmatic sphinx posed an unanswerable riddle to the trembling travelers.\",\n",
    "    \"The bustling city lights glimmered through the rain-streaked windowpane.\",\n",
    "    \"The concert was a resounding success, leaving the audience cheering for more.\",  # A\n",
    "    \"The enigmatic symbols on the ancient scroll remained indecipherable for centuries.\",\n",
    "    \"The music show was a smashing hit, leaving the crowd ecstatic and clamoring for an encore.\",  # similar to A\n",
    "    \"The chirping of crickets and the gentle rustling of leaves filled the night air.\",\n",
    "    \"With a heavy heart, he bid farewell to his beloved companion.\",\n",
    "    \"The intricate clockwork mechanism whirred and buzzed, a marvel of human ingenuity.\",\n",
    "    \"A wave of cheers and enthusiastic shouts erupted from the captivated crowd, urging the artists to return.\",  # similar to A\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'intricate'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'clockwork'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'mechanism'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'whirred'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'buzzed'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'marvel'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'of'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'ingenuity'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'wave'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'of'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'cheers'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enthusiastic'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'shouts'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'erupted'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'from'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'captivated'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'crowd'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'urging'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'artists'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'to'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'return'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'intricate'\u001b[0m,\n",
       "        \u001b[32m'clockwork'\u001b[0m,\n",
       "        \u001b[32m'mechanism'\u001b[0m,\n",
       "        \u001b[32m'whirred'\u001b[0m,\n",
       "        \u001b[32m'and'\u001b[0m,\n",
       "        \u001b[32m'buzzed'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'marvel'\u001b[0m,\n",
       "        \u001b[32m'of'\u001b[0m,\n",
       "        \u001b[32m'human'\u001b[0m,\n",
       "        \u001b[32m'ingenuity'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'wave'\u001b[0m,\n",
       "        \u001b[32m'of'\u001b[0m,\n",
       "        \u001b[32m'cheers'\u001b[0m,\n",
       "        \u001b[32m'and'\u001b[0m,\n",
       "        \u001b[32m'enthusiastic'\u001b[0m,\n",
       "        \u001b[32m'shouts'\u001b[0m,\n",
       "        \u001b[32m'erupted'\u001b[0m,\n",
       "        \u001b[32m'from'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'captivated'\u001b[0m,\n",
       "        \u001b[32m'crowd'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'urging'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'artists'\u001b[0m,\n",
       "        \u001b[32m'to'\u001b[0m,\n",
       "        \u001b[32m'return'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer: Tokenizer = Tokenizer(corpus=corpus)\n",
    "tokenized_corpus: list[list[str]] = tokenizer.tokenize_corpus()\n",
    "print(tokenized_corpus[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing', 'concert']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = BM25Okapi(corpus=tokenized_corpus)\n",
    "\n",
    "\n",
    "query: str = \"Amazing concert\"\n",
    "tokenized_query: list[str] = tokenizer.tokenized_doc(document=query)\n",
    "\n",
    "tokenized_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'concert'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'was'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'resounding'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'leaving'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'audience'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'cheering'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'for'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'more'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'wave'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'of'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'cheers'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enthusiastic'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'shouts'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'erupted'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'from'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'captivated'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'crowd'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'urging'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'artists'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'to'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'return'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'intricate'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'clockwork'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'mechanism'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'whirred'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'buzzed'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'marvel'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'of'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'ingenuity'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'concert'\u001b[0m,\n",
       "        \u001b[32m'was'\u001b[0m,\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'resounding'\u001b[0m,\n",
       "        \u001b[32m'success'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'leaving'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'audience'\u001b[0m,\n",
       "        \u001b[32m'cheering'\u001b[0m,\n",
       "        \u001b[32m'for'\u001b[0m,\n",
       "        \u001b[32m'more'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'wave'\u001b[0m,\n",
       "        \u001b[32m'of'\u001b[0m,\n",
       "        \u001b[32m'cheers'\u001b[0m,\n",
       "        \u001b[32m'and'\u001b[0m,\n",
       "        \u001b[32m'enthusiastic'\u001b[0m,\n",
       "        \u001b[32m'shouts'\u001b[0m,\n",
       "        \u001b[32m'erupted'\u001b[0m,\n",
       "        \u001b[32m'from'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'captivated'\u001b[0m,\n",
       "        \u001b[32m'crowd'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'urging'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'artists'\u001b[0m,\n",
       "        \u001b[32m'to'\u001b[0m,\n",
       "        \u001b[32m'return'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'intricate'\u001b[0m,\n",
       "        \u001b[32m'clockwork'\u001b[0m,\n",
       "        \u001b[32m'mechanism'\u001b[0m,\n",
       "        \u001b[32m'whirred'\u001b[0m,\n",
       "        \u001b[32m'and'\u001b[0m,\n",
       "        \u001b[32m'buzzed'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'marvel'\u001b[0m,\n",
       "        \u001b[32m'of'\u001b[0m,\n",
       "        \u001b[32m'human'\u001b[0m,\n",
       "        \u001b[32m'ingenuity'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It only accurately matches 2 out of the 3 correct documents\n",
    "results: list[list[str]] = bm25.get_top_n(\n",
    "    query=tokenized_query, documents=tokenized_corpus, n=3\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
