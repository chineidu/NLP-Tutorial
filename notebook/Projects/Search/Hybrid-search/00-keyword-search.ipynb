{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Search\n",
    "\n",
    "- `BM25` (Best Matching 25) is a `ranking function` used in information retrieval systems, particularly search engines, to estimate the relevance of documents to a given search query. \n",
    "\n",
    "- It is a `bag-of-words model`, meaning it considers the `occurrence of individual terms` in documents without regard to their order or proximity.\n",
    "\n",
    "## Advantages of BM25\n",
    "\n",
    "- **High accuracy**: BM25 consistently ranks relevant documents higher than non-relevant ones, resulting in more accurate search results.\n",
    "\n",
    "- **Simple and efficient**: The algorithm is relatively simple to implement and computationally efficient, making it suitable for large-scale information retrieval tasks.\n",
    "\n",
    "- **Effective for short queries**: BM25 works well with short queries, which are common in web search.\n",
    "\n",
    "### Breakdown of Some Apecific Advantages:\n",
    "\n",
    "- **Term frequency**: BM25 gives more weight to documents containing the query terms more frequently, reflecting their potential relevance.\n",
    "\n",
    "- **Document length normalization**: BM25 prevents long documents from dominating the results by adjusting the term frequency based on document length.\n",
    "\n",
    "- **Inverse document frequency**: BM25 assigns higher weights to terms that occur less frequently across the entire document collection, highlighting their potential significance.\n",
    "\n",
    "- **Widely implemented**: BM25 is used by many popular search engines and information retrieval systems, making it a standard in the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, TypeAlias, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich import print\n",
    "import torch\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install rank_bm25              \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'there', 'good', 'man!'],\n",
       " ['It', 'is', 'quite', 'windy', 'in', 'London'],\n",
       " ['How', 'is', 'the', 'weather', 'today?']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi, BM25L\n",
    "\n",
    "\n",
    "corpus: list[str] = [\n",
    "    \"Hello there good man!\",\n",
    "    \"It is quite windy in London\",\n",
    "    \"How is the weather today?\",\n",
    "]\n",
    "\n",
    "tokenized_corpus: list[list[Any]] = [doc.split(\" \") for doc in corpus]\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rank_bm25.BM25Okapi at 0x7fe25c21fc70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "- It's important to note that we also need to tokenize our query, and apply the same preprocessing steps we did to the documents in order to have an apples-to-apples comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.93729472, 0.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query: str = \"windy London\"\n",
    "tokenized_query = query.split(\" \")\n",
    "\n",
    "doc_scores: npt.NDArray[np.float_] = bm25.get_scores(tokenized_query)\n",
    "doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is quite windy in London']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of getting the document scores, you can also just retrieve the best documents with\n",
    "bm25.get_top_n(query=tokenized_query, documents=corpus, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "## Using SpaCy And Another Variant of BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 17:32:02.755492: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'This'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'is'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sentence'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'This'\u001b[0m, \u001b[32m'is'\u001b[0m, \u001b[32m'a'\u001b[0m, \u001b[32m'sentence'\u001b[0m, \u001b[32m'.'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.lang.en import English\n",
    "\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp: English = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    disable=[\"tagger\", \"lemmatizer\", \"parser\", \"ner\", \"attribute_ruler\"],\n",
    ")\n",
    "\n",
    "# Process a text\n",
    "text: str = \"This is a sentence.\"\n",
    "doc: Doc = nlp.tokenizer(text)\n",
    "\n",
    "# Only the tokenizer is applied\n",
    "print([x.text for x in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'there', 'good', 'man', '!'],\n",
       " ['It', 'is', 'quite', 'windy', 'in', 'London'],\n",
       " ['How', 'is', 'the', 'weather', 'today', '?']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus: list[list[Any]] = [\n",
    "    [token.text for token in nlp.tokenizer(text)] for text in corpus\n",
    "]\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, corpus: list[str]) -> None:\n",
    "        self.corpus = corpus\n",
    "        # self._tok_corpus = None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(num_corpus={len(self.corpus)})\"\n",
    "\n",
    "    def tokenize_corpus(self) -> list[list[Any]]:\n",
    "        \"\"\"This is used to tokenize the entire corpus.\"\"\"\n",
    "        tok_corpus: list[list[Any]] = [\n",
    "            self._tokenized_document(document=text) for text in self.corpus\n",
    "        ]\n",
    "        return tok_corpus\n",
    "\n",
    "    def tokenized_doc(self, document: str) -> list[str]:\n",
    "        \"\"\"This is used to tokenize a single document/query.\"\"\"\n",
    "        tok_doc: list[str] = self._tokenized_document(document=document)\n",
    "        return tok_doc\n",
    "\n",
    "    @staticmethod\n",
    "    def _tokenized_document(document: str) -> list[str]:\n",
    "        \"\"\"This is a helper function used to tokenize a single document.\"\"\"\n",
    "        tok_doc: list[str] = [token.text.lower() for token in nlp.tokenizer(document)]\n",
    "        return tok_doc\n",
    "\n",
    "    @property\n",
    "    def tok_corpus(self) -> list[list[Any]]:\n",
    "        tok_corpus = self.tokenize_corpus()\n",
    "        return tok_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(num_corpus=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer: Tokenizer = Tokenizer(corpus=corpus)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', 'there', 'good', 'man', '!'],\n",
       " ['it', 'is', 'quite', 'windy', 'in', 'london'],\n",
       " ['how', 'is', 'the', 'weather', 'today', '?']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus: list[list[str]] = tokenizer.tokenize_corpus()\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['windy', 'london']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25l = BM25L(tokenized_corpus)\n",
    "\n",
    "\n",
    "query: str = \"windy London\"\n",
    "tokenized_query: list[str] = tokenizer.tokenized_doc(document=query)\n",
    "\n",
    "tokenized_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 2.41704352, 0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_scores: npt.NDArray[np.float_] = bm25l.get_scores(query=tokenized_query)\n",
    "doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is quite windy in London']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25l.get_top_n(query=tokenized_query, documents=corpus, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus: list[str] = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"The enigmatic sphinx posed an unanswerable riddle to the trembling travelers.\",\n",
    "    \"The bustling city lights glimmered through the rain-streaked windowpane.\",\n",
    "    \"The concert was a resounding success, leaving the audience cheering for more.\",  # A\n",
    "    \"The enigmatic symbols on the ancient scroll remained indecipherable for centuries.\",\n",
    "    \"The music show was a smashing hit, leaving the crowd ecstatic and clamoring for an encore.\",  # similar to A\n",
    "    \"The chirping of crickets and the gentle rustling of leaves filled the night air.\",\n",
    "    \"With a heavy heart, he bid farewell to his beloved companion.\",\n",
    "    \"The intricate clockwork mechanism whirred and buzzed, a marvel of human ingenuity.\",\n",
    "    \"A wave of cheers and enthusiastic shouts erupted from the captivated crowd, urging the artists to return.\",  # similar to A\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'intricate'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'clockwork'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'mechanism'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'whirred'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'buzzed'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'marvel'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'of'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'ingenuity'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'wave'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'of'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'cheers'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enthusiastic'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'shouts'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'erupted'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'from'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'captivated'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'crowd'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'urging'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'artists'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'to'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'return'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'intricate'\u001b[0m,\n",
       "        \u001b[32m'clockwork'\u001b[0m,\n",
       "        \u001b[32m'mechanism'\u001b[0m,\n",
       "        \u001b[32m'whirred'\u001b[0m,\n",
       "        \u001b[32m'and'\u001b[0m,\n",
       "        \u001b[32m'buzzed'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'marvel'\u001b[0m,\n",
       "        \u001b[32m'of'\u001b[0m,\n",
       "        \u001b[32m'human'\u001b[0m,\n",
       "        \u001b[32m'ingenuity'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'wave'\u001b[0m,\n",
       "        \u001b[32m'of'\u001b[0m,\n",
       "        \u001b[32m'cheers'\u001b[0m,\n",
       "        \u001b[32m'and'\u001b[0m,\n",
       "        \u001b[32m'enthusiastic'\u001b[0m,\n",
       "        \u001b[32m'shouts'\u001b[0m,\n",
       "        \u001b[32m'erupted'\u001b[0m,\n",
       "        \u001b[32m'from'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'captivated'\u001b[0m,\n",
       "        \u001b[32m'crowd'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'urging'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'artists'\u001b[0m,\n",
       "        \u001b[32m'to'\u001b[0m,\n",
       "        \u001b[32m'return'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer: Tokenizer = Tokenizer(corpus=corpus)\n",
    "tokenized_corpus: list[list[str]] = tokenizer.tokenize_corpus()\n",
    "print(tokenized_corpus[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing', 'concert']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = BM25Okapi(corpus=tokenized_corpus)\n",
    "\n",
    "\n",
    "query: str = \"Amazing concert\"\n",
    "tokenized_query: list[str] = tokenizer.tokenized_doc(document=query)\n",
    "\n",
    "tokenized_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'concert'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'was'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'resounding'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'leaving'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'audience'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'cheering'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'for'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'more'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'wave'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'of'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'cheers'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enthusiastic'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'shouts'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'erupted'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'from'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'captivated'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'crowd'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'urging'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'artists'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'to'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'return'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'intricate'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'clockwork'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'mechanism'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'whirred'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'buzzed'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'marvel'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'of'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'ingenuity'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'concert'\u001b[0m,\n",
       "        \u001b[32m'was'\u001b[0m,\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'resounding'\u001b[0m,\n",
       "        \u001b[32m'success'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'leaving'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'audience'\u001b[0m,\n",
       "        \u001b[32m'cheering'\u001b[0m,\n",
       "        \u001b[32m'for'\u001b[0m,\n",
       "        \u001b[32m'more'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'wave'\u001b[0m,\n",
       "        \u001b[32m'of'\u001b[0m,\n",
       "        \u001b[32m'cheers'\u001b[0m,\n",
       "        \u001b[32m'and'\u001b[0m,\n",
       "        \u001b[32m'enthusiastic'\u001b[0m,\n",
       "        \u001b[32m'shouts'\u001b[0m,\n",
       "        \u001b[32m'erupted'\u001b[0m,\n",
       "        \u001b[32m'from'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'captivated'\u001b[0m,\n",
       "        \u001b[32m'crowd'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'urging'\u001b[0m,\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'artists'\u001b[0m,\n",
       "        \u001b[32m'to'\u001b[0m,\n",
       "        \u001b[32m'return'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'the'\u001b[0m,\n",
       "        \u001b[32m'intricate'\u001b[0m,\n",
       "        \u001b[32m'clockwork'\u001b[0m,\n",
       "        \u001b[32m'mechanism'\u001b[0m,\n",
       "        \u001b[32m'whirred'\u001b[0m,\n",
       "        \u001b[32m'and'\u001b[0m,\n",
       "        \u001b[32m'buzzed'\u001b[0m,\n",
       "        \u001b[32m','\u001b[0m,\n",
       "        \u001b[32m'a'\u001b[0m,\n",
       "        \u001b[32m'marvel'\u001b[0m,\n",
       "        \u001b[32m'of'\u001b[0m,\n",
       "        \u001b[32m'human'\u001b[0m,\n",
       "        \u001b[32m'ingenuity'\u001b[0m,\n",
       "        \u001b[32m'.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It only accurately matches 2 out of the 3 correct documents\n",
    "results: list[list[str]] = bm25.get_top_n(\n",
    "    query=tokenized_query, documents=tokenized_corpus, n=3\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone's BM25 Implementation\n",
    "\n",
    "```sh\n",
    "pip install \"pinecone-text[splade]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c7927658214982959cd544d5a9a724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pinecone_text.sparse.bm25_encoder.BM25Encoder at 0x7fe265f874f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_text.sparse import BM25Encoder\n",
    "\n",
    "\n",
    "corpus: list[str] = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"The lazy dog is brown\",\n",
    "    \"The fox is brown\",\n",
    "]\n",
    "\n",
    "# Initialize BM25 and fit the corpus\n",
    "bm25 = BM25Encoder()\n",
    "bm25.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "print(\"over\" in stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgdl': 3.6666666666666665,\n",
       " 'n_docs': 3,\n",
       " 'doc_freq': {'indices': [771291085,\n",
       "   741580288,\n",
       "   2673099881,\n",
       "   2381777354,\n",
       "   226376294,\n",
       "   2982218203],\n",
       "  'values': [1.0, 3.0, 2.0, 1.0, 2.0, 2.0]},\n",
       " 'b': 0.75,\n",
       " 'k1': 1.2,\n",
       " 'lower_case': True,\n",
       " 'remove_punctuation': True,\n",
       " 'remove_stopwords': True,\n",
       " 'stem': True,\n",
       " 'language': 'english'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick, brown, fox, jumps, lazy, dog\n",
    "#    1,     3,    2,   1,     2,   2\n",
    "\n",
    "bm25.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{771291085: 1,\n",
       " 741580288: 3,\n",
       " 2673099881: 2,\n",
       " 2381777354: 1,\n",
       " 226376294: 2,\n",
       " 2982218203: 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25.doc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indices': [2673099881, 741580288],\n",
       " 'values': [0.7787512111381205, 0.2212487888618795]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode a query (for search in Pinecone index)\n",
    "query_sparse_vector: dict[str, Any] = bm25.encode_queries(\"Which fox is brown?\")\n",
    "query_sparse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
