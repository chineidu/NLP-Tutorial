{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Introduction To LangChain](https://docs.langchain.com/docs/)\n",
    "\n",
    "<br>\n",
    "\n",
    "- LangChain is a framework for developing applications powered by language models.\n",
    "\n",
    "## Topics Covered\n",
    "\n",
    "1. Document Loading\n",
    "2. Document Splitting\n",
    "3. Using LangChain to create output parsers.\n",
    "4. Using LangChain to create memory.\n",
    "5. Using LangChain to create chains.\n",
    "\n",
    "## Installation\n",
    "\n",
    "```sh\n",
    "pip install langchain\n",
    "\n",
    "# OR\n",
    "pip install 'langchain[all]'\n",
    "\n",
    "# Other dependencies\n",
    "pip install python-dotenv\n",
    "pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document Loading\n",
    "\n",
    "### Retrieval augmented generation\n",
    "\n",
    "```text\n",
    "- In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution.\n",
    "- This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc).\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "[![image.png](https://i.postimg.cc/bJpQfq5y/image.png)](https://postimg.cc/nsSsvfZg)\n",
    "\n",
    "```sh\n",
    "# Install dependency\n",
    "pip install pypdf\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "fp = \"../../data/cs229-data/MachineLearning-Lecture01.pdf\"\n",
    "loader = PyPDFLoader(file_path=fp)\n",
    "pages = loader.load()\n",
    "\n",
    "# Each page is a Document.\n",
    "# A Document contains text (page_content) and metadata.\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MachineLearning-Lecture01  \\n'\n",
      " 'Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\n'\n",
      " 'learning class. So what I wanna do today is ju st spend a little time going '\n",
      " 'over the logistics \\n'\n",
      " \"of the class, and then we'll start to  talk a bit about machine learning.  \\n\"\n",
      " \"By way of introduction, my name's  Andrew Ng and I'll be instru ctor for \"\n",
      " 'this class. And so \\n'\n",
      " \"I personally work in machine learning, and I' ve worked on it for about 15 \"\n",
      " 'years now, and \\n'\n",
      " 'I actually think that machine learning i')\n"
     ]
    }
   ],
   "source": [
    "first_page = pages[0]\n",
    "\n",
    "# 1st 500 charcaters\n",
    "pprint(first_page.page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_page.page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YoutTube\n",
    "\n",
    "```sh\n",
    "pip install yt_dlp\n",
    "pip install pydub\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andrew NG Standford lecture\n",
    "URL = \"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "SAVE_DIR = \"../../data/docs/youtube/\"\n",
    "loader = GenericLoader(YoutubeAudioLoader([URL], SAVE_DIR), OpenAIWhisperParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
      "[youtube] jGwO_UgTS7I: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Unable to download webpage: IncompleteRead(109644 bytes read)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] jGwO_UgTS7I: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] The read operation timed out. Retrying (1/3)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] jGwO_UgTS7I: Downloading ios player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading android player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading iframe API JS\n",
      "[youtube] jGwO_UgTS7I: Downloading player 0e6aaa83\n",
      "[youtube] jGwO_UgTS7I: Downloading web player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading m3u8 information\n",
      "[youtube] jGwO_UgTS7I: Downloading initial data API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Remote end closed connection without response. Retrying (1/3)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] jGwO_UgTS7I: Downloading initial data API JSON\n",
      "[info] jGwO_UgTS7I: Downloading 1 format(s): 140\n",
      "[download] ../../data/docs/youtube//Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a has already been downloaded\n",
      "[download] 100% of   69.76MiB\n",
      "[ExtractAudio] Not converting audio ../../data/docs/youtube//Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a; file is already in target format m4a\n",
      "Transcribing part 1!\n",
      "Transcribing part 2!\n",
      "Transcribing part 3!\n",
      "Transcribing part 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Welcome to CS229 Machine Learning. Uh, some of you know that this is a class that's taught at Stanford for a long time. And this is often the class that, um, I most look forward to teaching each year because this is where we've helped, I think, several generations of Stanford students become experts in machine learning, got- built many of their products and services and startups that I'm sure, many of you or probably all of you are using, uh, uh, today. Um, so what I want to do today was spend s\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes a while to complete!\n",
    "docs = loader.load()\n",
    "docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "handbook/37signals-is-you.md at master · basecamp/handbook · GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Sign up\n",
      "          \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Product\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actions\n",
      "        Automate any workflow\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Packages\n",
      "        Host and manage packages\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Security\n",
      "        Find and fix vulnerabilities\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Codes\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "URL = \"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\"\n",
    "loader = WebBaseLoader(URL)\n",
    "docs = loader.load()\n",
    "\n",
    "# Print the contents of the doc\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    ")\n",
    "\n",
    "\n",
    "chunk_size = 26\n",
    "chunk_overlap = 4\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"abcdefghijklmnopqrstuvwxyz\"  # 26 chars\n",
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = \"abcdefghijklmnopqrstuvwxyzabcdefg\"  # 34 chars\n",
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperator:\"\\n\\n\"\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap, separator=\" \"\n",
    ")\n",
    "\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n"
     ]
    }
   ],
   "source": [
    "# Recursive splitting details\n",
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "print(len(some_text))\n",
    "\n",
    "c_splitter = CharacterTextSplitter(chunk_size=450, chunk_overlap=0, separator=\" \")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When writing documents, writers will use document structure to group '\n",
      " \"content. This can convey to the reader, which idea's are related. For \"\n",
      " 'example, closely related ideas are in sentances. Similar ideas are in '\n",
      " 'paragraphs. Paragraphs form a document. \\n'\n",
      " '\\n'\n",
      " ' Paragraphs are often delimited with a carriage return or two carriage '\n",
      " 'returns. Carriage returns are the \"backslash n\" you see embedded in this '\n",
      " 'string. Sentences have a period at the end, but also,',\n",
      " 'have a space.and words are separated by space.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = c_splitter.split_text(some_text)\n",
    "pprint(result)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_1: When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \n",
      "\n",
      " Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,\n",
      "\n",
      "Split_2: have a space.and words are separated by space.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Split_1: {result[0]}\\n\\nSplit_2: {result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When writing documents, writers will use document structure to group '\n",
      " \"content. This can convey to the reader, which idea's are related. For \"\n",
      " 'example, closely related ideas are in sentances. Similar ideas are in '\n",
      " 'paragraphs. Paragraphs form a document.',\n",
      " 'Paragraphs are often delimited with a carriage return or two carriage '\n",
      " 'returns. Carriage returns are the \"backslash n\" you see embedded in this '\n",
      " 'string. Sentences have a period at the end, but also, have a space.and words '\n",
      " 'are separated by space.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = r_splitter.split_text(some_text)\n",
    "pprint(result)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_1: When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\n",
      "\n",
      "Split_2: Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Split_1: {result[0]}\\n\\nSplit_2: {result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When writing documents, writers will use document structure to group '\n",
      " \"content. This can convey to the reader, which idea's are related\",\n",
      " '. For example, closely related ideas are in sentances. Similar ideas are in '\n",
      " 'paragraphs. Paragraphs form a document.',\n",
      " 'Paragraphs are often delimited with a carriage return or two carriage '\n",
      " 'returns',\n",
      " '. Carriage returns are the \"backslash n\" you see embedded in this string',\n",
      " '. Sentences have a period at the end, but also, have a space.and words are '\n",
      " 'separated by space.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's reduce the chunk size a bit and add a period to our separators:\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"],\n",
    ")\n",
    "\n",
    "result = r_splitter.split_text(some_text)\n",
    "pprint(result)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split_1: When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related\n",
      "\n",
      "Split_2: . For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\n",
      "\n",
      "Split_3: Paragraphs are often delimited with a carriage return or two carriage returns\n",
      "\n",
      "Split_4: . Carriage returns are the \"backslash n\" you see embedded in this string\n",
      "\n",
      "Split_5: . Sentences have a period at the end, but also, have a space.and words are separated by space.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\\nSplit_1: {result[0]}\\n\\nSplit_2: {result[1]}\\n\\nSplit_3: {result[2]}\"\n",
    "    f\"\\n\\nSplit_4: {result[3]}\\n\\nSplit_5: {result[4]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "\n",
      "Split_1: When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related.\n",
      "\n",
      "Split_2: For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\n",
      "\n",
      "Split_3: Paragraphs are often delimited with a carriage return or two carriage returns.\n",
      "\n",
      "Split_4: Carriage returns are the \"backslash n\" you see embedded in this string.\n",
      "\n",
      "Split_5: Sentences have a period at the end, but also, have a space.and words are separated by space.\n"
     ]
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150, chunk_overlap=0, separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "result = r_splitter.split_text(some_text)\n",
    "print(len(result))\n",
    "\n",
    "print(\n",
    "    f\"\\nSplit_1: {result[0]}\\n\\nSplit_2: {result[1]}\\n\\nSplit_3: {result[2]}\"\n",
    "    f\"\\n\\nSplit_4: {result[3]}\\n\\nSplit_5: {result[4]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of split docs: 77\n",
      "Length of original docs: 22\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Load the PDF\n",
    "fp = \"../../data/cs229-data/MachineLearning-Lecture01.pdf\"\n",
    "loader = PyPDFLoader(file_path=fp)\n",
    "pages = loader.load()\n",
    "\n",
    "# Split the document\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", chunk_size=1000, chunk_overlap=150, length_function=len\n",
    ")\n",
    "docs = text_splitter.split_documents(pages)\n",
    "print(f\"Length of split docs: {len(docs)}\\nLength of original docs: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Notion Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "\n",
    "fp = \"../../data/Notion_DB\"\n",
    "loader = NotionDirectoryLoader(path=fp)\n",
    "notion_db = loader.load()\n",
    "docs = text_splitter.split_documents(notion_db)\n",
    "len(notion_db)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "```text\n",
    "Token splitting\n",
    "- We can also split on token count explicity, if we want.\n",
    "- This can be useful because LLMs often have context windows designated in tokens.\n",
    "- Tokens are often ~4 characters.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(page_content='MachineLearning-Lecture01  \\n', metadata={'source': '../../data/cs229-data/MachineLearning-Lecture01.pdf', 'page': 0})\n",
      "\n",
      "{'page': 0, 'source': '../../data/cs229-data/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)\n",
    "text1 = \"foo bar bazzyfoo\"\n",
    "text_splitter.split_text(text1)\n",
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "pprint(docs[0])\n",
    "print()\n",
    "# Metadata of the docs\n",
    "pprint(pages[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "```text\n",
    "Context aware splitting\n",
    "- Chunking aims to keep text with common context together.\n",
    "- A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "- `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "pprint(md_header_splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on a real Markdown file, like a Notion database.\n",
    "fp = \"../../data/Notion_DB\"\n",
    "loader = NotionDirectoryLoader(path=fp)\n",
    "docs = loader.load()\n",
    "txt = \" \".join([d.page_content for d in docs])\n",
    "md_header_splits = markdown_splitter.split_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"This is a living document with everything we've learned working with people while running a startup. And, of course, we continue to learn. Therefore it's a document that will continue to change.  \\n**Everything related to working at Blendle and the people of Blendle, made public.**  \\nThese are the lessons from three years of working with the people of Blendle. It contains everything from [how our leaders lead](https://www.notion.so/ecfb7e647136468a9a0a32f1771a8f52?pvs=21) to [how we increase salaries](https://www.notion.so/Salary-Review-e11b6161c6d34f5c9568bb3e83ed96b6?pvs=21), from [how we hire](https://www.notion.so/Hiring-451bbcfe8d9b49438c0633326bb7af0a?pvs=21) and [fire](https://www.notion.so/Firing-5567687a2000496b8412e53cd58eed9d?pvs=21) to [how we think people should give each other feedback](https://www.notion.so/Our-Feedback-Process-eb64f1de796b4350aeab3bc068e3801f?pvs=21) — and much more.  \\nWe've made this document public because we want to learn from you. We're very much interested in your feedback (including weeding out typo's and Dunglish ;)). Email us at hr@blendle.com. If you're starting your own company or if you're curious as to how we do things at Blendle, we hope that our employee handbook inspires you.  \\nIf you want to work at Blendle you can check our [job ads here](https://blendle.homerun.co/). If you want to be kept in the loop about Blendle, you can sign up for [our behind the scenes newsletter](https://blendle.homerun.co/yes-keep-me-posted/tr/apply?token=8092d4128c306003d97dd3821bad06f2).\", metadata={'Header 1': \"Blendle's Employee Handbook\"}),\n",
       " Document(page_content=\"*Information gap closing in 3... 2... 1...*  \\n---  \\n[To Do/Read in your first week](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/To%20Do%20Read%20in%20your%20first%20week%2017fbb01dc37b4118943b1db905cd57f2.md)  \\n[History](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/History%20ac6441b1b7f7412796b072168db92fd2.md)  \\n[DNA & culture](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/DNA%20&%20culture%20b5db7bb937384f809a81e84059050b3f.md)  \\n[General & practical ](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/General%20&%20practical%20b8d9412f67c34a3e996bf4d3f390de5e.md)\", metadata={'Header 1': \"Blendle's Employee Handbook\", 'Header 2': 'Blendle general'}),\n",
       " Document(page_content=\"*You can tell a company's DNA by looking at how they deal with the practical stuff.*  \\n---  \\n[Office](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Office%204e7a0f0ad8e34c50bba69cfd9f779038.md)  \\n[Time off: holidays and national holidays](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Time%20off%20holidays%20and%20national%20holidays%20b1b4abd60ae547e8b4088818da9e92e7.md)  \\n[Calling in sick/better](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Calling%20in%20sick%20better%204337662f835a4a00933b76b254758bc4.md)  \\n[Perks and benefits](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Perks%20and%20benefits%206b81f8a3deb5408a8385472cd797a3f7.md)  \\n[Travel costs and reimbursements](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Travel%20costs%20and%20reimbursements%204df295267aa74fe1a7fa1361571b6fbc.md)  \\n[Parenthood](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Parenthood%208cd588eff0984cdd983a9eea420c9e76.md)\", metadata={'Header 1': \"Blendle's Employee Handbook\", 'Header 2': 'People operations'}),\n",
       " Document(page_content=\"*Themes we care about.*  \\n---  \\n[Blendle Social Code](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Blendle%20Social%20Code%20d10a41a7746c4bd2ab4c3fe6db803f69.md)  \\n[Diversity and inclusion](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Diversity%20and%20inclusion%20dbd07fc1bf0849019f3f3ed242190055.md)  \\n[#letstalkaboutstress](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/#letstalkaboutstress%20b814c542d1744bbb83bf7e1d63e4bdda.md)\", metadata={'Header 1': \"Blendle's Employee Handbook\", 'Header 2': 'People topics'}),\n",
       " Document(page_content=\"*The number 1 reason for people to work at Blendle is growth and learning from smart people.*  \\n---  \\n[Your 1st month ](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Your%201st%20month%20c6f4af5517c84d4087e635587961fb0e.md)  \\n[Goals](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Goals%207258fc51173d42a79621ef9b3851e719.md)  \\n[Feedback cycle](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Feedback%20cycle%20e838f6e605064170bb0611f538915cb7.md)  \\n[The Matrix™ (job profiles)](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/The%20Matrix%E2%84%A2%20(job%20profiles)%20df18f2beab014a7e89f442d0e459ad73.md)  \\n[Blendle library](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Blendle%20library%2064396b41895842d680d118f4ec17d346.md)\", metadata={'Header 1': \"Blendle's Employee Handbook\", 'Header 2': 'Feedback and development'}),\n",
       " Document(page_content=\"*The coolest and most impactful thing when done right.*  \\n---  \\n[Rating systems](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Rating%20systems%20036cb477bab342349ff0ceb54ab21478.md)  \\n[Getting people in (branding&sourcing)](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Getting%20people%20in%20(branding&sourcing)%20e050e6613efe4305b98d6b7b8c8916a3.md)  \\n[Highly Skilled Migrants and relocation](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Highly%20Skilled%20Migrants%20and%20relocation%204c00141c18fd472fb5770891381b65e2.md)\", metadata={'Header 1': \"Blendle's Employee Handbook\", 'Header 2': '**Hiring**'}),\n",
       " Document(page_content=\"*Here are some tips and tools to help you become a great leader.*  \\n---  \\n[How to lead at Blendle ](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/How%20to%20lead%20at%20Blendle%20404698936d274095856523c94c396a62.md)  \\n[Your check-list](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Your%20check-list%2007455ff3b1364229bfc1ae3462e58030.md)  \\n[Leading Feedback ](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Leading%20Feedback%209ad2513f7ea14b7a8d2762db7c0b70c0.md)  \\n[Salary talks](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Salary%20talks%203c0befca9272403a8a045cace8686d8d.md)  \\n[Hiring ](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Hiring%208c7049f20ed74df982f8e05bc3dca30b.md)  \\n[Firing](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Firing%200a07fff173404adebf98ea7ef3a8eb7d.md)  \\n[Party and study budget](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Party%20and%20study%20budget%2049f8b0f9dfbf45ea8ed15dd11c99e28d.md)  \\n[Holidays](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Holidays%20629b666201b9416684d1d36ce6c63713.md)  \\n[Sickness absence](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Sickness%20absence%2075f3765b7698473aa45171b909ff1e65.md)  \\n[Personal User Guide](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Personal%20User%20Guide%2097a8516bc2cd44b7a565798e954a68a3.md)  \\n[Soft shizzle](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/Soft%20shizzle%207c03996eeb634b12ad9093839cd11bde.md)\", metadata={'Header 1': \"Blendle's Employee Handbook\", 'Header 2': 'How to lead at Blendle'}),\n",
       " Document(page_content=\"---  \\n*Lessons from three years of HR*  \\n[About this document and the author](Blendle's%20Employee%20Handbook%20e367aa77e225482c849111687e114a56/About%20this%20document%20and%20the%20author%208c7a88f91b1d479ea729a6f47ef56d0c.md)\", metadata={'Header 1': \"Blendle's Employee Handbook\", 'Header 2': 'About this document'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"This is a living document with everything we've learned working with people while running a startup. And, of course, we continue to learn. Therefore it's a document that will continue to change.  \\n**Everything related to working at Blendle and the people of Blendle, made public.**  \\nThese are the lessons from three years of working with the people of Blendle. It contains everything from [how our leaders lead](https://www.notion.so/ecfb7e647136468a9a0a32f1771a8f52?pvs=21) to [how we increase salaries](https://www.notion.so/Salary-Review-e11b6161c6d34f5c9568bb3e83ed96b6?pvs=21), from [how we hire](https://www.notion.so/Hiring-451bbcfe8d9b49438c0633326bb7af0a?pvs=21) and [fire](https://www.notion.so/Firing-5567687a2000496b8412e53cd58eed9d?pvs=21) to [how we think people should give each other feedback](https://www.notion.so/Our-Feedback-Process-eb64f1de796b4350aeab3bc068e3801f?pvs=21) — and much more.  \\nWe've made this document public because we want to learn from you. We're very much interested in your feedback (including weeding out typo's and Dunglish ;)). Email us at hr@blendle.com. If you're starting your own company or if you're curious as to how we do things at Blendle, we hope that our employee handbook inspires you.  \\nIf you want to work at Blendle you can check our [job ads here](https://blendle.homerun.co/). If you want to be kept in the loop about Blendle, you can sign up for [our behind the scenes newsletter](https://blendle.homerun.co/yes-keep-me-posted/tr/apply?token=8092d4128c306003d97dd3821bad06f2).\", metadata={'Header 1': \"Blendle's Employee Handbook\"})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
