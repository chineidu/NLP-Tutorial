{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF (from scratch) And Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Feature engine\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "# Custom imports\n",
    "\n",
    "# Built-in library\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "from typing import Union, Optional, Any\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure warnings and pther settings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set()\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def load_data(*, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"This is used to load the data.\n",
    "\n",
    "    Params;\n",
    "        filename (str): The filepath.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): The loaded dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    print(f\"Shape of df: {df.shape}\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (2225, 2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet bus...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\\n\\nAnd Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet bus...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\\n\\nAnd Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of th...   \n",
       "\n",
       "     labels  \n",
       "0  business  \n",
       "1  business  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"../../data/bbc_text_cls.csv\"\n",
    "data = load_data(filename=filename)\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \"\"\"This is used to tokenize documents\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def __call__(self, doc: str, *args: Any, **kwargs: Any) -> list[str]:\n",
    "        # Tokenize\n",
    "        doc = nlp(doc)\n",
    "        tokenized_doc = [word.text.lower() for word in doc]\n",
    "        return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you for being an awesome father</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have an awesome God. I just wanna say thank you</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels\n",
       "0              Thank you for being an awesome father      a\n",
       "1  I have an awesome God. I just wanna say thank you      b"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    \"text\": [\n",
    "        \"Thank you for being an awesome father\",\n",
    "        \"I have an awesome God. I just wanna say thank you\",\n",
    "    ],\n",
    "    \"labels\": [\"a\", \"b\"],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsCalculator:\n",
    "    \"\"\"This tokenizes all the documents and calculates the bag of words.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.tokenizer = Tokenizer()\n",
    "\n",
    "    def __call__(\n",
    "        self, data: pd.DataFrame, *args: Any, **kwargs: Any\n",
    "    ) -> tuple[list, dict]:\n",
    "        \"\"\"This calculates the bag of words.\"\"\"\n",
    "        count = 0\n",
    "        bag_of_words = {}\n",
    "        tokenized_docs = []\n",
    "\n",
    "        for doc in data:\n",
    "            # Tokenize docs\n",
    "            tokenized_doc = self.tokenizer(doc=doc)\n",
    "            doc_as_num = []\n",
    "\n",
    "            for word in tokenized_doc:\n",
    "                # Store the unique words as numbers in the dict\n",
    "                if word not in bag_of_words:\n",
    "                    bag_of_words[word] = count\n",
    "                    count += 1\n",
    "                # Save the word as a number\n",
    "                doc_as_num.append(bag_of_words.get(word))\n",
    "            # Store the tokenized docs (converted to numbers) in a list\n",
    "            tokenized_docs.append(doc_as_num)\n",
    "        return (tokenized_docs, bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow_calculator = BagOfWordsCalculator()\n",
    "# tokenized_docs, bag_of_words = bow_calculator(data=data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_o_words_cal = BagOfWordsCalculator()\n",
    "t_docs, b_o_words = b_o_words_cal(data=df[\"text\"])\n",
    "\n",
    "# number of docs and number of words\n",
    "N, V = df.shape[0], len(b_o_words)\n",
    "tf = np.zeros((N, V))\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 1., 1., 0., 2., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for each word in the doc and increment the count\n",
    "# of the word wherever it occurs\n",
    "for doc_idx, doc_as_num in enumerate(t_docs):\n",
    "    for words_idx in doc_as_num:\n",
    "        tf[doc_idx, words_idx] += 1\n",
    "\n",
    "tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCountVectorizer:\n",
    "    \"\"\"This is used to count the terms in a given document.\"\"\"\n",
    "\n",
    "    def __init__(self, data: pd.Series) -> None:\n",
    "        self.data = data\n",
    "        self.bag_of_words = {}\n",
    "        self.tokenized_docs = []\n",
    "        self.tokenizer = Tokenizer()\n",
    "\n",
    "    def tokenize_docs_n_cal_bag_of_words(self) -> tuple[list, dict]:\n",
    "        \"\"\"This tokenizes the documents abd calculates the bag of words.\"\"\"\n",
    "        count = 0\n",
    "\n",
    "        for doc in self.data:\n",
    "            # Tokenize docs\n",
    "            tokenized_doc = self.tokenizer(doc=doc)\n",
    "            doc_as_num = []\n",
    "\n",
    "            for word in tokenized_doc:\n",
    "                # Store the unique words as numbers in the dict\n",
    "                if word not in self.bag_of_words:\n",
    "                    self.bag_of_words[word] = count\n",
    "                    count += 1\n",
    "                # Save the word as a number\n",
    "                doc_as_num.append(self.bag_of_words.get(word))\n",
    "            # Store the tokenized docs (converted to numbers) in a list\n",
    "            self.tokenized_docs.append(doc_as_num)\n",
    "        return (self.tokenized_docs, self.bag_of_words)\n",
    "\n",
    "    def calculate_term_frequency(self, *args: Any, **kwargs: Any) -> np.ndarray:\n",
    "        \"\"\"Count the terms in the document. i.e term frequency\"\"\"\n",
    "        self.tokenized_docs, self.bag_of_words = self.tokenize_docs_n_cal_bag_of_words()\n",
    "        # Number of docs and number of words\n",
    "        N, W = self.data.shape[0], len(self.bag_of_words)\n",
    "        tf = np.zeros((N, W))  # Instantiate tf\n",
    "\n",
    "        # Check each word in the doc and increment the count\n",
    "        # of the word wherever it occurs\n",
    "        for doc_idx, doc_as_num in enumerate(self.tokenized_docs):\n",
    "            for words_idx in doc_as_num:\n",
    "                tf[doc_idx, words_idx] += 1\n",
    "        return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you for being an awesome father</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have an awesome God. I just wanna say thank you</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels\n",
       "0              Thank you for being an awesome father      a\n",
       "1  I have an awesome God. I just wanna say thank you      b"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 1., 1., 0., 2., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CustomCountVectorizer(data=df[\"text\"])\n",
    "tf = count_vectorizer.calculate_term_frequency()\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.69314718, 0.69314718, 0.        ,\n",
       "       0.        , 0.69314718, 0.69314718, 0.69314718, 0.69314718,\n",
       "       0.69314718, 0.69314718, 0.69314718, 0.69314718])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute IDF\n",
    "# DF: Document Frequency is the num of documents the term occurs in.\n",
    "# IDF: Number of documents(N) divided by DF. The log is taken to\n",
    "# reduce the impact of extremely large documents.\n",
    "# Therefore, IDF = log(N / DF)\n",
    "N = df.shape[0]\n",
    "document_frequency = (tf > 0).sum(axis=0)  # shape (W,)\n",
    "idf = np.log(N / document_frequency)\n",
    "\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.69314718, 0.69314718, 0.        ,\n",
       "        0.        , 0.69314718, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.38629436, 0.69314718, 0.69314718,\n",
       "        0.69314718, 0.69314718, 0.69314718, 0.69314718]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = tf * idf\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TermFrequencyInverseDocumentFrequency:\n",
    "    \"\"\"This is used to calculate the term frequency\n",
    "    inverse document frequency of a given corpus.\"\"\"\n",
    "\n",
    "    def __init__(self, data: pd.Series) -> None:\n",
    "        self.data = data\n",
    "        self.bag_of_words = {}\n",
    "        self.tokenized_docs = []\n",
    "        self.tokenizer = Tokenizer()\n",
    "\n",
    "    def tokenize_docs_n_cal_bag_of_words(self) -> tuple[list, dict]:\n",
    "        \"\"\"This tokenizes the documents abd calculates the bag of words.\"\"\"\n",
    "        count = 0\n",
    "\n",
    "        for doc in self.data:\n",
    "            # Tokenize docs\n",
    "            tokenized_doc = self.tokenizer(doc=doc)\n",
    "            doc_as_num = []\n",
    "\n",
    "            for word in tokenized_doc:\n",
    "                # Store the unique words as numbers in the dict\n",
    "                if word not in self.bag_of_words:\n",
    "                    self.bag_of_words[word] = count\n",
    "                    count += 1\n",
    "                # Save the word as a number\n",
    "                doc_as_num.append(self.bag_of_words.get(word))\n",
    "            # Store the tokenized docs (converted to numbers) in a list\n",
    "            self.tokenized_docs.append(doc_as_num)\n",
    "        return (self.tokenized_docs, self.bag_of_words)\n",
    "\n",
    "    def convert_numbers_to_words(self) -> dict:\n",
    "        \"\"\"This is used to map numbers to words.\"\"\"\n",
    "        _, self.bag_of_words = self.tokenize_docs_n_cal_bag_of_words()\n",
    "        nums_to_words = {num: word for word, num in self.bag_of_words.items()}\n",
    "        return nums_to_words\n",
    "\n",
    "    def calculate_term_frequency(self, *args: Any, **kwargs: Any) -> np.ndarray:\n",
    "        \"\"\"Count the terms in the document. i.e term frequency\"\"\"\n",
    "        self.tokenized_docs, self.bag_of_words = self.tokenize_docs_n_cal_bag_of_words()\n",
    "        # Number of docs and number of words\n",
    "        N, W = self.data.shape[0], len(self.bag_of_words)\n",
    "        tf = np.zeros((N, W))  # Instantiate tf\n",
    "\n",
    "        # Check each word in the doc and increment the count\n",
    "        # of the word wherever it occurs\n",
    "        for doc_idx, doc_as_num in enumerate(self.tokenized_docs):\n",
    "            for words_idx in doc_as_num:\n",
    "                tf[doc_idx, words_idx] += 1\n",
    "        return tf\n",
    "\n",
    "    def calculate_term_freq_inv_doc_freq(self) -> np.ndarray:\n",
    "        \"\"\"This returns the term frequency inverse document frequency\n",
    "        of a given corpus.\"\"\"\n",
    "        # DF: Document Frequency is the num of documents the term occurs in.\n",
    "        # IDF: Number of documents(N) divided by DF. The log is taken to\n",
    "        # reduce the impact of extremely large documents.\n",
    "        # Therefore, IDF = log(N / DF)\n",
    "        N = self.data.shape[0]\n",
    "        tf = self.calculate_term_frequency()\n",
    "        document_frequency = (tf > 0).sum(axis=0)  # shape (W,)\n",
    "        inverse_doc_freq = np.log(N / document_frequency)\n",
    "        tf_idf = tf * inverse_doc_freq\n",
    "        return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.69314718, 0.69314718, 0.        ,\n",
       "        0.        , 0.69314718, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.38629436, 0.69314718, 0.69314718,\n",
       "        0.69314718, 0.69314718, 0.69314718, 0.69314718]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec = TermFrequencyInverseDocumentFrequency(data=df[\"text\"])\n",
    "tfidf = tfidf_vec.calculate_term_freq_inv_doc_freq()\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: a\n",
      "Text: Thank you for being an awesome father\n",
      "Top 5 terms:\n",
      "for\n",
      "being\n",
      "father\n",
      "thank\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "idx_2_word = tfidf_vec.convert_numbers_to_words()\n",
    "\n",
    "# pick a random document, show the top 5 terms (in terms of tf_idf score)\n",
    "# i = np.random.choice(N)\n",
    "i = 0\n",
    "row = df.iloc[i]\n",
    "print(\"Label:\", row[\"labels\"])\n",
    "print(\"Text:\", row[\"text\"])\n",
    "print(\"Top 5 terms:\")\n",
    "\n",
    "scores = tfidf[i]\n",
    "indices = (-scores).argsort()  # Sort in descending order\n",
    "\n",
    "for idx in indices[:5]:\n",
    "    print(idx_2_word[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet bus...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\\n\\nAnd Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (£479m) loan.\\n\\nState-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets. Rosneft already faces a similar $540m repayment demand from foreign banks. Legal experts said Rosneft's purchase of Yugansk would include such obligations. \"The pledged assets are wit...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet bus...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\\n\\nAnd Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of th...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (£479m) loan.\\n\\nState-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets. Rosneft already faces a similar $540m repayment demand from foreign banks. Legal experts said Rosneft's purchase of Yugansk would include such obligations. \"The pledged assets are wit...   \n",
       "\n",
       "     labels  \n",
       "0  business  \n",
       "1  business  \n",
       "2  business  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TermFrequencyInverseDocumentFrequency(data=data[\"text\"])\n",
    "tfidf = tfidf_vec.calculate_term_freq_inv_doc_freq()\n",
    "idx_2_word = tfidf_vec.convert_numbers_to_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 144\n",
      "Label: business\n",
      "Text: Winn-Dixie files for bankruptcy\n",
      "Top 5 terms:\n",
      "dixie\n",
      "winn\n",
      "bankruptcy\n",
      "stores\n",
      "foods\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document, show the top 5 terms (in terms of tf_idf score)\n",
    "N = data.shape[0]\n",
    "i = np.random.choice(N)\n",
    "row = data.iloc[i]\n",
    "\n",
    "print(f\"i: {i}\")\n",
    "print(\"Label:\", row[\"labels\"])\n",
    "print(\"Text:\", row[\"text\"].split(\"\\n\")[0])\n",
    "print(\"Top 5 terms:\")\n",
    "\n",
    "scores = tfidf[i]\n",
    "indices = (-scores).argsort()  # Sort in descending order\n",
    "\n",
    "for idx in indices[:5]:\n",
    "    print(idx_2_word[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Using SKLearn's TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf_vec = TfidfVectorizer(\n",
    "#     stop_words=\"english\", tokenizer=Tokenizer(), max_features=25_000\n",
    "# )\n",
    "# X = data[\"text\"]\n",
    "# X_tr = tf_idf_vec.fit_transform(X)\n",
    "\n",
    "# dict_ = tf_idf_vec.vocabulary_\n",
    "# idx_2_word_dict = {num: word for word, num in dict_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 144\n",
      "Label: business\n",
      "Text: Winn-Dixie files for bankruptcy\n",
      "Top 5 terms:\n",
      "winn\n",
      "dixie\n",
      "bankruptcy\n",
      "stores\n",
      "foods\n"
     ]
    }
   ],
   "source": [
    "# i = 594\n",
    "row = data.iloc[i]\n",
    "\n",
    "print(f\"i: {i}\")\n",
    "print(\"Label:\", row[\"labels\"])\n",
    "print(\"Text:\", row[\"text\"].split(\"\\n\")[0])\n",
    "print(\"Top 5 terms:\")\n",
    "\n",
    "scores = X_tr[i].toarray().flatten()\n",
    "indices = (-scores).argsort()  # Sort in descending order\n",
    "\n",
    "for idx in indices[:5]:\n",
    "    print(idx_2_word_dict[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Text Summarization\n",
    "\n",
    "### Using TFIDF\n",
    "\n",
    "1. Split the document into sentences.\n",
    "2. Score each sentence (using the average TFIDF of the non zero scores)\n",
    "3. Rank each sentence by the scores.\n",
    "4. Summary is approximately the top N ranked sentences by score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet bus...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet bus...   \n",
       "\n",
       "     labels  \n",
       "0  business  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentencizer:\n",
    "    \"\"\"This is used to convert a document into a list of sentences.\n",
    "    It returns sentences.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def __call__(self, doc: str, *args: Any, **kwargs: Any) -> list[str]:\n",
    "        # Tokenize\n",
    "        doc = nlp(doc)\n",
    "        sentences = list(doc.sents)\n",
    "        tokenized_sentences = [str(sentence) for sentence in sentences]\n",
    "        return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"labels\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Goodrem wins top female MTV prize\\n\\nPop singer Delta Goodrem has scooped one of the top individual prizes at the first Australian MTV Music Awards.\\n\\nThe 21-year-old singer won the award for best female artist, with Australian Idol runner-up Shannon Noll taking the title of best male at the ceremony. Goodrem, known in both Britain and Australia for her role as Nina Tucker in TV soap Neighbours, also performed a duet with boyfriend Brian McFadden. Other winners included Green Day, voted best group, and the Black Eyed Peas. Goodrem, Green Day and the Black Eyed Peas took home two awards ea...\n",
       "1    Tough schedule delays Elliot show\\n\\nPreview performances of the £3m musical Billy Elliot have been delayed to give the child actors a less arduous rehearsal schedule.\\n\\nDirector Stephen Daldry made the decision to re-schedule the previews to protect the young stars. Three boys will rotate the demanding role of ballet dancer Billy, which requires them to sing, dance and act. The show's opening night on 12 May at the Victoria Palace Theatre in London remains unaffected by the changes. Preview performances will now be held on 14, 20 and 27 April. \"This is one of the most ambitious projects ...\n",
       "2    U2's desire to be number one\\n\\nU2, who have won three prestigious Grammy Awards for their hit Vertigo, are stubbornly clinging to their status as one of the biggest bands in the world.\\n\\nThe most popular groups in the history of rock all have several things in common. The music must be inspired and appeal across generations and be distinctive, if not always groundbreaking. But such success is down to more than music. They have to be compelling performers, charismatic and intelligent enough to make good decisions and keep their feet on the ground. They also have to want it. They have to w...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select document\n",
    "sample_data = (\n",
    "    data.loc[data[\"labels\"] == \"entertainment\", \"text\"]\n",
    "    .sample(n=3, random_state=123)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPop singer Delta Goodrem has scooped one of the top individual prizes at the first Australian MTV Music Awards.\\n\\nThe 21-year-old singer won the award for best female artist, with Australian Idol runn'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split ONCE using '\\n' and exclude the title\n",
    "doc = sample_data.iloc[0].split(\"\\n\", 1)[1]\n",
    "doc[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nPop singer Delta Goodrem has scooped one of the top individual prizes at the first Australian MTV Music Awards.\\n\\n',\n",
       " 'The 21-year-old singer won the award for best female artist, with Australian Idol runner-up Shannon Noll taking the title of best male at the ceremony.',\n",
       " 'Goodrem, known in both Britain and Australia for her role as Nina Tucker in TV soap Neighbours, also performed a duet with boyfriend Brian McFadden.',\n",
       " 'Other winners included Green Day, voted best group, and the Black Eyed Peas.',\n",
       " 'Goodrem, Green Day and the Black Eyed Peas took home two awards each.',\n",
       " 'As well as best female, Goodrem also took home the Pepsi Viewers Choice Award, whilst Green Day bagged the prize for best rock video for American Idiot.',\n",
       " \"The Black Eyed Peas won awards for best R 'n' B video and sexiest video, both for Hey Mama.\",\n",
       " 'Local singer and songwriter Missy Higgins took the title of breakthrough artist of the year, with Australian Idol winner Guy Sebastian taking the honours for best pop video.',\n",
       " 'The VH1 First Music Award went to Cher honouring her achievements within the music industry.',\n",
       " 'The ceremony was held at the Luna Park fairground in Sydney Harbour and was hosted by the Osbourne family.',\n",
       " 'Artists including Carmen Electra, Missy Higgins, Kelly Osbourne, Green Day, Ja Rule and Natalie Imbruglia gave live performances at the event.']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = Sentencizer()\n",
    "sentences = sents(doc=doc)\n",
    "print(len(sentences))\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who', 'none', 'keep', 'name', 'thereby']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy stopwords\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "spacy_stopwords = list(spacy_stopwords)\n",
    "spacy_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 102)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the sentences\n",
    "tfidf = TfidfVectorizer(stop_words=spacy_stopwords, norm=\"l1\")\n",
    "X_tr = tfidf.fit_transform(sentences)\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_sentence_score(tfidf_row):\n",
    "    \"\"\"This returns the average value of the non-zero tfidf value\n",
    "    for a given sentence.\"\"\"\n",
    "    x = tfidf_row[tfidf_row != 0]\n",
    "    return x.mean()\n",
    "\n",
    "\n",
    "# Initialize the score\n",
    "scores = np.zeros(len(sentences))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the score for each sentence\n",
    "for i in range(len(sentences)):\n",
    "    score = calculate_sentence_score(X_tr[i, :])\n",
    "    scores[i] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  4,  9,  3,  6,  0,  2,  1,  5, 10,  7])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the scores in descending order\n",
    "sort_idx = np.argsort(-scores)\n",
    "sort_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Another method for calculating the scores\n",
    "# A = X_tr.toarray()\n",
    "\n",
    "# B = pd.DataFrame(A)\n",
    "# scores = B[B != 0].mean(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Goodrem wins top female MTV prize\n",
      "Generated summary:\n",
      "8: 0.125 The VH1 First Music Award went to Cher honouring her achievements within the music industry.\n",
      "4: 0.111 Goodrem, Green Day and the Black Eyed Peas took home two awards each.\n",
      "9: 0.1 The ceremony was held at the Luna Park fairground in Sydney Harbour and was hosted by the Osbourne family.\n",
      "3: 0.1 Other winners included Green Day, voted best group, and the Black Eyed Peas.\n",
      "6: 0.1 The Black Eyed Peas won awards for best R 'n' B video and sexiest video, both for Hey Mama.\n"
     ]
    }
   ],
   "source": [
    "# Many options for how to choose which sentences to include:\n",
    "\n",
    "# 1) top N sentences\n",
    "# 2) top N words or characters.\n",
    "# 3) top X% sentences or top X% words\n",
    "# 4) sentences with scores > average score\n",
    "# 5) sentences with scores > factor * average score\n",
    "\n",
    "# You also don't have to sort. May make more sense in order.\n",
    "\n",
    "# Title\n",
    "title = sample_data.iloc[0].split(\"\\n\", 1)[0]\n",
    "\n",
    "print(f\"Title: {title}\\nGenerated summary:\")\n",
    "for i in sort_idx[:5]:\n",
    "    print(f\"{i}: {round(scores[i], 3)} {sentences[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goodrem wins top female MTV prize'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title\n",
    "sample_data.iloc[0].split(\"\\n\", 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c160606400bd63443fe4361c23f8347e54b6f9986e7c6d27e878f1970943f47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
