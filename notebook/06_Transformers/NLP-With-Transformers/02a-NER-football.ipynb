{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chineidu/NLP-Tutorial/blob/main/notebook/06_Transformers/NLP-With-Transformers/02a-NER-football.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers accelerate datasets \\\n",
        "  seqeval mlxtend watermark rich"
      ],
      "metadata": {
        "id": "MtO1xNAGq3uW",
        "outputId": "d8aed41d-e1a4-4b07-dd9c-89ef3c7e6ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L-sc1OAjq0Xi",
        "outputId": "7d8fd55f-c6ee-49d4-f047-55f7edac860b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.26.4\n",
            "pandas      : 2.1.4\n",
            "polars      : 0.20.2\n",
            "mlxtend     : 0.23.1\n",
            "transformers: 4.42.4\n",
            "\n",
            "conda environment: n/a\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext watermark\n",
        "%watermark -v -p numpy,pandas,polars,mlxtend,transformers --conda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-9GvQlHkq0Xl"
      },
      "outputs": [],
      "source": [
        "# Built-in library\n",
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "from typing import Any, Optional, Union\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "from rich.console import Console\n",
        "from rich.theme import Theme\n",
        "\n",
        "custom_theme = Theme(\n",
        "    {\n",
        "        \"info\": \"#76FF7B\",\n",
        "        \"warning\": \"#FBDDFE\",\n",
        "        \"error\": \"#FF0000\",\n",
        "    }\n",
        ")\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NumPy settings\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "# Pandas settings\n",
        "pd.options.display.max_rows = 1_000\n",
        "pd.options.display.max_columns = 1_000\n",
        "pd.options.display.max_colwidth = 600\n",
        "\n",
        "# Polars settings\n",
        "pl.Config.set_fmt_str_lengths(1_000)\n",
        "pl.Config.set_tbl_cols(n=1_000)\n",
        "pl.Config.set_tbl_rows(n=200)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# # Black code formatter (Optional)\n",
        "# %load_ext lab_black\n",
        "\n",
        "# # auto reload imports\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBSIuXIDq0Xm"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vVYCrzwq0Xn"
      },
      "outputs": [],
      "source": [
        "# fp: str = \"../../../data/ner_data.jsonl\"\n",
        "\n",
        "# with open(fp, \"r\") as f:\n",
        "#     json_data = [json.loads(line) for line in f]\n",
        "\n",
        "# print(len(json_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J54wabjlrftE",
        "outputId": "35355efb-18ab-4c81-c18b-eab51c49f3dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NJH94Ry5q0Xn",
        "outputId": "66fdbc39-6eee-4bcd-f2d2-8b3bea4ce7b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document_id', 'sentences'],\n",
              "        num_rows: 1940\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['document_id', 'sentences'],\n",
              "        num_rows: 222\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document_id', 'sentences'],\n",
              "        num_rows: 222\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk\n",
        "from datasets.features.features import ClassLabel, Sequence\n",
        "\n",
        "# data: DatasetDict = load_dataset(\"ontonotes/conll2012_ontonotesv5\", \"english_v4\")\n",
        "# data.save_to_disk(\"../../../data/conll2012_ontonotesv5\")\n",
        "\n",
        "fp: str = \"../../../data/conll2012_ontonotesv5\"\n",
        "fp: str = \"/content/drive/MyDrive/My doc/Deep Learning/Data/conll2012_ontonotesv5\"\n",
        "ds_dict: DatasetDict = load_from_disk(dataset_path=fp)\n",
        "ds_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8F8vhAvaq0Xo",
        "outputId": "8cdc4bc6-643f-4c1a-a7ec-e5ed5288ee28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'part_id': Value(dtype='int32', id=None),\n",
              " 'words': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'pos_tags': Sequence(feature=ClassLabel(names=['XX', '``', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'ADD', 'AFX', 'CC', 'CD', 'DT', 'EX', 'FW', 'HYPH', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NFP', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None),\n",
              " 'parse_tree': Value(dtype='string', id=None),\n",
              " 'predicate_lemmas': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'predicate_framenet_ids': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'word_senses': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None),\n",
              " 'speaker': Value(dtype='string', id=None),\n",
              " 'named_entities': Sequence(feature=ClassLabel(names=['O', 'B-PERSON', 'I-PERSON', 'B-NORP', 'I-NORP', 'B-FAC', 'I-FAC', 'B-ORG', 'I-ORG', 'B-GPE', 'I-GPE', 'B-LOC', 'I-LOC', 'B-PRODUCT', 'I-PRODUCT', 'B-DATE', 'I-DATE', 'B-TIME', 'I-TIME', 'B-PERCENT', 'I-PERCENT', 'B-MONEY', 'I-MONEY', 'B-QUANTITY', 'I-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'B-CARDINAL', 'I-CARDINAL', 'B-EVENT', 'I-EVENT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'B-LAW', 'I-LAW', 'B-LANGUAGE', 'I-LANGUAGE'], id=None), length=-1, id=None),\n",
              " 'srl_frames': [{'verb': Value(dtype='string', id=None),\n",
              "   'frames': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}],\n",
              " 'coref_spans': Sequence(feature=Sequence(feature=Value(dtype='int32', id=None), length=3, id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "ds_dict[\"train\"].features[\"sentences\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wKdpomnsq0Xp",
        "outputId": "a25a80e0-bae5-40da-91b0-e7f25c0c2f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClassLabel(names=['O', 'B-PERSON', 'I-PERSON', 'B-NORP', 'I-NORP', 'B-FAC', 'I-FAC', 'B-ORG', 'I-ORG', 'B-GPE', 'I-GPE', 'B-LOC', 'I-LOC', 'B-PRODUCT', 'I-PRODUCT', 'B-DATE', 'I-DATE', 'B-TIME', 'I-TIME', 'B-PERCENT', 'I-PERCENT', 'B-MONEY', 'I-MONEY', 'B-QUANTITY', 'I-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'B-CARDINAL', 'I-CARDINAL', 'B-EVENT', 'I-EVENT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'B-LAW', 'I-LAW', 'B-LANGUAGE', 'I-LANGUAGE'], id=None)\n"
          ]
        }
      ],
      "source": [
        "tags: ClassLabel = ds_dict[\"train\"].features[\"sentences\"][0][\"named_entities\"].feature\n",
        "print(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2BjXHOc_q0Xp",
        "outputId": "35816d34-ee1c-4e9d-a09f-a701426615ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'O', 1: 'B-PERSON', 2: 'I-PERSON', 3: 'B-NORP', 4: 'I-NORP', 5: 'B-FAC', 6: 'I-FAC', 7: 'B-ORG', 8: 'I-ORG', 9: 'B-GPE', 10: 'I-GPE', 11: 'B-LOC', 12: 'I-LOC', 13: 'B-PRODUCT', 14: 'I-PRODUCT', 15: 'B-DATE', 16: 'I-DATE', 17: 'B-TIME', 18: 'I-TIME', 19: 'B-PERCENT', 20: 'I-PERCENT', 21: 'B-MONEY', 22: 'I-MONEY', 23: 'B-QUANTITY', 24: 'I-QUANTITY', 25: 'B-ORDINAL', 26: 'I-ORDINAL', 27: 'B-CARDINAL', 28: 'I-CARDINAL', 29: 'B-EVENT', 30: 'I-EVENT', 31: 'B-WORK_OF_ART', 32: 'I-WORK_OF_ART', 33: 'B-LAW', 34: 'I-LAW', 35: 'B-LANGUAGE', 36: 'I-LANGUAGE'}\n"
          ]
        }
      ],
      "source": [
        "index2tag: dict[int, str] = {tags.str2int(tag): tag for tag in tags.names}\n",
        "tag2index: dict[str, int] = {tag: tags.str2int(tag) for tag in tags.names}\n",
        "\n",
        "print(index2tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr1Yd3x0q0Xq"
      },
      "source": [
        "### Comment\n",
        "\n",
        "- Drop irrelevant columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MLp2uSk2q0Xq"
      },
      "outputs": [],
      "source": [
        "def extract_tokens_and_labels(example: dict[str, Any]) -> dict[str, Any]:\n",
        "    tokens = example[\"sentences\"][0][\"words\"]\n",
        "    labels = example[\"sentences\"][0][\"named_entities\"]\n",
        "\n",
        "    return {\"tokens\": tokens, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRCynEZ3q0Xq",
        "outputId": "cda4dd70-e488-41d1-8ce3-f8bbeeec206c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "039a53788fb443a2aa9c6052d9151767",
            "f380aa4801db49f9a1860f21040e2a9f",
            "be21aee55f49472a89022fb8a12c0193",
            "2f7310fe16cf4b53acd0c4ab9ffe28e8",
            "e9a694d8685e483e8480aad0f15e593d",
            "f70b0a3be40a4ada9d87dc57bb99c857",
            "d1d5406df6b34c63a276d901b0ef0b83",
            "b67d35bc643646519d63b1f55a7fafe5",
            "a2e8ee7f4b8c4bb994b4e4aacfa845ce",
            "034e27c5680649feb1610660b9922508",
            "7ba8d112af17429ba9f2cfb0b9977626"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1940 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "039a53788fb443a2aa9c6052d9151767"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ClassLabel object\n",
        "class_label = ClassLabel(num_classes=len(tags.names), names=tags.names)\n",
        "\n",
        "# Create a copy\n",
        "ds_dict: DatasetDict = ds_dict.copy()\n",
        "\n",
        "for split in ds_dict.keys():\n",
        "    ds_dict[split] = ds_dict[split].map(extract_tokens_and_labels)\n",
        "    ds_dict[split] = ds_dict[split].remove_columns([\"sentences\"])\n",
        "    # Update the 'labels' column to use ClassLabel\n",
        "    ds_dict[split] = ds_dict[split].cast_column(\n",
        "        column=\"labels\", feature=Sequence(class_label)\n",
        "    )\n",
        "    ds_dict[split] = ds_dict[split].map(\n",
        "        lambda x: {\"ner_labels\": [index2tag[t] for t in x[\"labels\"]]}\n",
        "    )\n",
        "\n",
        "ds_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g65LSaIq0Xr"
      },
      "outputs": [],
      "source": [
        "ds_dict[\"train\"][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba1UkCykq0Xr"
      },
      "outputs": [],
      "source": [
        "df: pl.DataFrame = ds_dict[\"train\"].to_polars()\n",
        "df = df.with_columns(token_length=pl.col(\"tokens\").map_elements(lambda x: len(x)))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQvTKBfiq0Xr"
      },
      "outputs": [],
      "source": [
        "# Check the distribution of all the tags\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "\n",
        "splits_freq: defaultdict = defaultdict(Counter)\n",
        "\n",
        "for split, ds in ds_dict.items():\n",
        "    for row in ds[\"ner_labels\"]:\n",
        "        for tag in row:\n",
        "            # Focus on the `beginning` tags\n",
        "            if tag.startswith(\"B\"):\n",
        "                tag_type: str = tag.split(\"-\")[1]\n",
        "                splits_freq[split][tag_type] += 1\n",
        "\n",
        "\n",
        "# The tags are roughly equally distributed\n",
        "pl.DataFrame(splits_freq).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coT679D1q0Xs"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "chkpoint: str = \"dslim/distilbert-NER\"  # \"dslim/bert-base-NER\"\n",
        "\n",
        "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(chkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctXHISkiq0Xs"
      },
      "outputs": [],
      "source": [
        "text: str = \" \".join(ds_dict[\"train\"][\"tokens\"][-3])\n",
        "inp_labels: list[int] = ds_dict[\"train\"][\"labels\"][-3]\n",
        "tokens: list[str] = tokenizer(text).tokens()  # tokenizer.tokenize(text)\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQkaXIdWq0Xs"
      },
      "outputs": [],
      "source": [
        "inputs.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHxgzwl1q0Xs",
        "outputId": "eab13616-8627-473e-f9b6-d9900dac9326"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 56, 768])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "\n",
        "bert_model = AutoModel.from_pretrained(chkpoint)\n",
        "bert_model(**inputs)[\"last_hidden_state\"].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3vtPB2Vq0Xt"
      },
      "source": [
        "### Tokenization Pipeline\n",
        "\n",
        "<br>\n",
        "\n",
        "[![image.png](https://i.postimg.cc/zvJ0SrZz/image.png)](https://postimg.cc/dkx2wgVp)\n",
        "\n",
        "<br>\n",
        "\n",
        "- `Normalization`: it involves cleaning raw text by removing whitespace, accents, and standardizing Unicode characters. It also includes lowercasing to reduce vocabulary size. After normalization, our example string becomes \"jack sparrow loves new york!\".\n",
        "\n",
        "- `Pretokenization`: it splits text into words for easier tokenization. For English and similar languages, this is simple. For languages like Chinese, it's more complex and might require language-specific libraries.\n",
        "\n",
        "- `Tokenizer model`: it splits words into subwords to reduce vocabulary size and out-of-vocabulary tokens. This is done using algorithms like BPE, Unigram, and WordPiece. For example, \"jack sparrow\" might become \"[jack, spa, rrow]\".\n",
        "\n",
        "- `Postprocessing`: it's the final step in tokenization, where additional tokens (like [CLS] and [SEP]) are added to the beginning and end of the token sequence to prepare it for input into a model like BERT.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK4YcIjrq0Xt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDNuoMrwq0Xt"
      },
      "source": [
        "### Named Entity Recognition\n",
        "\n",
        "[![image.png](https://i.postimg.cc/26YwrD5Q/image.png)](https://postimg.cc/rdhWN7xs)\n",
        "\n",
        "<br>\n",
        "\n",
        "- In `token classification`, assign the label (e.g., B-PER) to the first subword (\"Chr\") and ignore subsequent subwords (\"##ista\"). This convention follows the BERT paper and maintains the IOB2 format. Postprocessing can propagate the label to all subwords.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Classification Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJF-aC1eq0Xt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from transformers import BertConfig, BertModel\n",
        "from transformers.models.bert.modeling_bert import BertPreTrainedModel\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "\n",
        "\n",
        "class BertForTokenClassification(BertPreTrainedModel):\n",
        "    class_config = BertConfig\n",
        "\n",
        "    def __init__(self, config) -> None:\n",
        "        super().__init__(config)\n",
        "\n",
        "        # Load model body\n",
        "        self.model = BertModel(config)\n",
        "\n",
        "        # Setup classifiaction head\n",
        "        self.num_labels = config.num_labels\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        # Load pretrained weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Tensor | None = None,\n",
        "        attention_mask: Tensor | None = None,\n",
        "        token_type_ids: Tensor | None = None,\n",
        "        labels: Tensor | None = None,\n",
        "        **kwargs\n",
        "    ) -> TokenClassifierOutput:\n",
        "        # Get the encoder representations using the body\n",
        "        outputs: dict = self.model(input_ids, attention_mask, token_type_ids, **kwargs)\n",
        "\n",
        "        # Apply classifier to encoder representation\n",
        "        sequence_output: Tensor = self.dropout(outputs[\"last_hidden_state\"])\n",
        "        logits: Tensor = self.classifier(sequence_output)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss: Tensor | None = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return TokenClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L0_eugSq0Xt",
        "outputId": "2e1afe1a-be6d-4ee0-decf-b255022627b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClassLabel(names=['O', 'B-PERSON', 'I-PERSON', 'B-NORP', 'I-NORP', 'B-FAC', 'I-FAC', 'B-ORG', 'I-ORG', 'B-GPE', 'I-GPE', 'B-LOC', 'I-LOC', 'B-PRODUCT', 'I-PRODUCT', 'B-DATE', 'I-DATE', 'B-TIME', 'I-TIME', 'B-PERCENT', 'I-PERCENT', 'B-MONEY', 'I-MONEY', 'B-QUANTITY', 'I-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'B-CARDINAL', 'I-CARDINAL', 'B-EVENT', 'I-EVENT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'B-LAW', 'I-LAW', 'B-LANGUAGE', 'I-LANGUAGE'], id=None)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_gXZW7Qq0Xu",
        "outputId": "f9a614ae-448c-417b-810f-150d0f345c19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"distilbert-base-cased\",\n",
              "  \"activation\": \"gelu\",\n",
              "  \"architectures\": [\n",
              "    \"DistilBertForTokenClassification\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.1,\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"dim\": 768,\n",
              "  \"dropout\": 0.1,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dim\": 3072,\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"O\",\n",
              "    \"1\": \"B-PERSON\",\n",
              "    \"2\": \"I-PERSON\",\n",
              "    \"3\": \"B-NORP\",\n",
              "    \"4\": \"I-NORP\",\n",
              "    \"5\": \"B-FAC\",\n",
              "    \"6\": \"I-FAC\",\n",
              "    \"7\": \"B-ORG\",\n",
              "    \"8\": \"I-ORG\",\n",
              "    \"9\": \"B-GPE\",\n",
              "    \"10\": \"I-GPE\",\n",
              "    \"11\": \"B-LOC\",\n",
              "    \"12\": \"I-LOC\",\n",
              "    \"13\": \"B-PRODUCT\",\n",
              "    \"14\": \"I-PRODUCT\",\n",
              "    \"15\": \"B-DATE\",\n",
              "    \"16\": \"I-DATE\",\n",
              "    \"17\": \"B-TIME\",\n",
              "    \"18\": \"I-TIME\",\n",
              "    \"19\": \"B-PERCENT\",\n",
              "    \"20\": \"I-PERCENT\",\n",
              "    \"21\": \"B-MONEY\",\n",
              "    \"22\": \"I-MONEY\",\n",
              "    \"23\": \"B-QUANTITY\",\n",
              "    \"24\": \"I-QUANTITY\",\n",
              "    \"25\": \"B-ORDINAL\",\n",
              "    \"26\": \"I-ORDINAL\",\n",
              "    \"27\": \"B-CARDINAL\",\n",
              "    \"28\": \"I-CARDINAL\",\n",
              "    \"29\": \"B-EVENT\",\n",
              "    \"30\": \"I-EVENT\",\n",
              "    \"31\": \"B-WORK_OF_ART\",\n",
              "    \"32\": \"I-WORK_OF_ART\",\n",
              "    \"33\": \"B-LAW\",\n",
              "    \"34\": \"I-LAW\",\n",
              "    \"35\": \"B-LANGUAGE\",\n",
              "    \"36\": \"I-LANGUAGE\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"B-CARDINAL\": 27,\n",
              "    \"B-DATE\": 15,\n",
              "    \"B-EVENT\": 29,\n",
              "    \"B-FAC\": 5,\n",
              "    \"B-GPE\": 9,\n",
              "    \"B-LANGUAGE\": 35,\n",
              "    \"B-LAW\": 33,\n",
              "    \"B-LOC\": 11,\n",
              "    \"B-MONEY\": 21,\n",
              "    \"B-NORP\": 3,\n",
              "    \"B-ORDINAL\": 25,\n",
              "    \"B-ORG\": 7,\n",
              "    \"B-PERCENT\": 19,\n",
              "    \"B-PERSON\": 1,\n",
              "    \"B-PRODUCT\": 13,\n",
              "    \"B-QUANTITY\": 23,\n",
              "    \"B-TIME\": 17,\n",
              "    \"B-WORK_OF_ART\": 31,\n",
              "    \"I-CARDINAL\": 28,\n",
              "    \"I-DATE\": 16,\n",
              "    \"I-EVENT\": 30,\n",
              "    \"I-FAC\": 6,\n",
              "    \"I-GPE\": 10,\n",
              "    \"I-LANGUAGE\": 36,\n",
              "    \"I-LAW\": 34,\n",
              "    \"I-LOC\": 12,\n",
              "    \"I-MONEY\": 22,\n",
              "    \"I-NORP\": 4,\n",
              "    \"I-ORDINAL\": 26,\n",
              "    \"I-ORG\": 8,\n",
              "    \"I-PERCENT\": 20,\n",
              "    \"I-PERSON\": 2,\n",
              "    \"I-PRODUCT\": 14,\n",
              "    \"I-QUANTITY\": 24,\n",
              "    \"I-TIME\": 18,\n",
              "    \"I-WORK_OF_ART\": 32,\n",
              "    \"O\": 0\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"n_heads\": 12,\n",
              "  \"n_layers\": 6,\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"qa_dropout\": 0.1,\n",
              "  \"seq_classif_dropout\": 0.2,\n",
              "  \"sinusoidal_pos_embds\": false,\n",
              "  \"tie_weights_\": true,\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.39.3\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 28996\n",
              "}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = BertConfig.from_pretrained(\n",
        "    chkpoint, num_labels=len(tags.names), id2label=index2tag, label2id=tag2index\n",
        ")\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2YYoPQxq0Xu",
        "outputId": "4ea4a453-5335-498d-9bed-602daf58d838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'[CLS]': 101, 'Note': 5322, ':': 131, 'There': 1247, \"'\": 112, 's': 188, 'a': 170, 'piece': 2727, 'by': 1118, 'George': 1667, 'Pack': 14667, '##er': 1200, 'in': 1107, 'The': 1109, 'New': 1203, 'Yorker': 20998, '-': 118, 'L': 149, '##RB': 22672, 'Bet': 26615, '##ray': 6447, '##ed': 1174, 'the': 1103, 'Iraqi': 8612, '##s': 1116, 'who': 1150, 'trusted': 9373, 'America': 1738, 'most': 1211, 'R': 155, 'about': 1164, 'all': 1155, 'this': 1142, ',': 117, 'but': 1133, 'it': 1122, 'way': 1236, 'too': 1315, 'long': 1263, 'to': 1106, 'blog': 10679, 'here': 1303, '.': 119, '[SEP]': 102}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 44)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>[CLS]</th><th>Note</th><th>:</th><th>There</th><th>&#x27;</th><th>s</th><th>a</th><th>piece</th><th>by</th><th>George</th><th>Pack</th><th>##er</th><th>in</th><th>The</th><th>New</th><th>Yorker</th><th>-</th><th>L</th><th>##RB</th><th>Bet</th><th>##ray</th><th>##ed</th><th>the</th><th>Iraqi</th><th>##s</th><th>who</th><th>trusted</th><th>America</th><th>most</th><th>R</th><th>about</th><th>all</th><th>this</th><th>,</th><th>but</th><th>it</th><th>way</th><th>too</th><th>long</th><th>to</th><th>blog</th><th>here</th><th>.</th><th>[SEP]</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>101</td><td>5322</td><td>131</td><td>1247</td><td>112</td><td>188</td><td>170</td><td>2727</td><td>1118</td><td>1667</td><td>14667</td><td>1200</td><td>1107</td><td>1109</td><td>1203</td><td>20998</td><td>118</td><td>149</td><td>22672</td><td>26615</td><td>6447</td><td>1174</td><td>1103</td><td>8612</td><td>1116</td><td>1150</td><td>9373</td><td>1738</td><td>1211</td><td>155</td><td>1164</td><td>1155</td><td>1142</td><td>117</td><td>1133</td><td>1122</td><td>1236</td><td>1315</td><td>1263</td><td>1106</td><td>10679</td><td>1303</td><td>119</td><td>102</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (1, 44)\n",
              "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
              "│ [CL ┆ Not ┆ :   ┆ The ┆ '   ┆ s   ┆ a   ┆ pie ┆ by  ┆ Geo ┆ Pac ┆ ##e ┆ in  ┆ The ┆ New ┆ Yor ┆ -   ┆ L   ┆ ##R ┆ Bet ┆ ##r ┆ ##e ┆ the ┆ Ira ┆ ##s ┆ who ┆ tru ┆ Ame ┆ mos ┆ R   ┆ abo ┆ all ┆ thi ┆ ,   ┆ but ┆ it  ┆ way ┆ too ┆ lon ┆ to  ┆ blo ┆ her ┆ .   ┆ [SE │\n",
              "│ S]  ┆ e   ┆ --- ┆ re  ┆ --- ┆ --- ┆ --- ┆ ce  ┆ --- ┆ rge ┆ k   ┆ r   ┆ --- ┆ --- ┆ --- ┆ ker ┆ --- ┆ --- ┆ B   ┆ --- ┆ ay  ┆ d   ┆ --- ┆ qi  ┆ --- ┆ --- ┆ ste ┆ ric ┆ t   ┆ --- ┆ ut  ┆ --- ┆ s   ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ g   ┆ --- ┆ g   ┆ e   ┆ --- ┆ P]  │\n",
              "│ --- ┆ --- ┆ i64 ┆ --- ┆ i64 ┆ i64 ┆ i64 ┆ --- ┆ i64 ┆ --- ┆ --- ┆ --- ┆ i64 ┆ i64 ┆ i64 ┆ --- ┆ i64 ┆ i64 ┆ --- ┆ i64 ┆ --- ┆ --- ┆ i64 ┆ --- ┆ i64 ┆ i64 ┆ d   ┆ a   ┆ --- ┆ i64 ┆ --- ┆ i64 ┆ --- ┆ i64 ┆ i64 ┆ i64 ┆ i64 ┆ i64 ┆ --- ┆ i64 ┆ --- ┆ --- ┆ i64 ┆ --- │\n",
              "│ i64 ┆ i64 ┆     ┆ i64 ┆     ┆     ┆     ┆ i64 ┆     ┆ i64 ┆ i64 ┆ i64 ┆     ┆     ┆     ┆ i64 ┆     ┆     ┆ i64 ┆     ┆ i64 ┆ i64 ┆     ┆ i64 ┆     ┆     ┆ --- ┆ --- ┆ i64 ┆     ┆ i64 ┆     ┆ i64 ┆     ┆     ┆     ┆     ┆     ┆ i64 ┆     ┆ i64 ┆ i64 ┆     ┆ i64 │\n",
              "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ i64 ┆ i64 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
              "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
              "│ 101 ┆ 532 ┆ 131 ┆ 124 ┆ 112 ┆ 188 ┆ 170 ┆ 272 ┆ 111 ┆ 166 ┆ 146 ┆ 120 ┆ 110 ┆ 110 ┆ 120 ┆ 209 ┆ 118 ┆ 149 ┆ 226 ┆ 266 ┆ 644 ┆ 117 ┆ 110 ┆ 861 ┆ 111 ┆ 115 ┆ 937 ┆ 173 ┆ 121 ┆ 155 ┆ 116 ┆ 115 ┆ 114 ┆ 117 ┆ 113 ┆ 112 ┆ 123 ┆ 131 ┆ 126 ┆ 110 ┆ 106 ┆ 130 ┆ 119 ┆ 102 │\n",
              "│     ┆ 2   ┆     ┆ 7   ┆     ┆     ┆     ┆ 7   ┆ 8   ┆ 7   ┆ 67  ┆ 0   ┆ 7   ┆ 9   ┆ 3   ┆ 98  ┆     ┆     ┆ 72  ┆ 15  ┆ 7   ┆ 4   ┆ 3   ┆ 2   ┆ 6   ┆ 0   ┆ 3   ┆ 8   ┆ 1   ┆     ┆ 4   ┆ 5   ┆ 2   ┆     ┆ 3   ┆ 2   ┆ 6   ┆ 5   ┆ 3   ┆ 6   ┆ 79  ┆ 3   ┆     ┆     │\n",
              "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = BertForTokenClassification(config=config).to(device)\n",
        "\n",
        "\n",
        "# Check that the tokenizer and model were properly initialized\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "data: dict[str, int] = {\n",
        "    col: int(val) for col, val in zip(tokens, inputs.input_ids.flatten())\n",
        "}\n",
        "print(data)\n",
        "\n",
        "pl.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkjOlt2iq0Xu",
        "outputId": "2751d37f-4f4c-4103-f03e-d1586e2575bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  5322,   131,  1247,   112,   188,   170,  2727,  1118,  1667,\n",
              "          14667,  1200,  1107,  1109,  1203, 20998,   118,   149, 22672,   118,\n",
              "            112,   112, 26615,  6447,  1174,   131,  1103,  8612,  1116,  1150,\n",
              "           9373,  1738,  1103,  1211,   112,   112,   118,   155, 22672,   118,\n",
              "           1164,  1155,  1142,   117,  1133,  1122,   112,   188,  1236,  1315,\n",
              "           1263,  1106, 10679,  1303,   119,   102]]),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs_device: dict[str, Tensor] = {\n",
        "    k: torch.tensor(v).to(device) for k, v in inputs.items()\n",
        "}\n",
        "inputs_device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJfp4Mf5q0Xu",
        "outputId": "c629773f-1c2b-4778-971e-1c289e75bfb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  5322,   131,  1247,   112,   188,   170,  2727,  1118,  1667,\n",
              "          14667,  1200,  1107,  1109,  1203, 20998,   118,   149, 22672,   118,\n",
              "            112,   112, 26615,  6447,  1174,   131,  1103,  8612,  1116,  1150,\n",
              "           9373,  1738,  1103,  1211,   112,   112,   118,   155, 22672,   118,\n",
              "           1164,  1155,  1142,   117,  1133,  1122,   112,   188,  1236,  1315,\n",
              "           1263,  1106, 10679,  1303,   119,   102]]),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs_device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqc06PDbq0Xu",
        "outputId": "15a90d61-2a56-4f44-d81f-b1a69dbf26ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens in sequence: 56\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 44)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>[CLS]</th><th>Note</th><th>:</th><th>There</th><th>&#x27;</th><th>s</th><th>a</th><th>piece</th><th>by</th><th>George</th><th>Pack</th><th>##er</th><th>in</th><th>The</th><th>New</th><th>Yorker</th><th>-</th><th>L</th><th>##RB</th><th>Bet</th><th>##ray</th><th>##ed</th><th>the</th><th>Iraqi</th><th>##s</th><th>who</th><th>trusted</th><th>America</th><th>most</th><th>R</th><th>about</th><th>all</th><th>this</th><th>,</th><th>but</th><th>it</th><th>way</th><th>too</th><th>long</th><th>to</th><th>blog</th><th>here</th><th>.</th><th>[SEP]</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;I-LOC&quot;</td><td>&quot;I-LOC&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;B-MONEY&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;B-GPE&quot;</td><td>&quot;B-GPE&quot;</td><td>&quot;I-ORDINAL&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;B-PRODUCT&quot;</td><td>&quot;B-GPE&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;I-FAC&quot;</td><td>&quot;I-LOC&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;B-GPE&quot;</td><td>&quot;B-LANGUAGE&quot;</td><td>&quot;B-GPE&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;B-LOC&quot;</td><td>&quot;B-PRODUCT&quot;</td><td>&quot;I-ORG&quot;</td><td>&quot;I-GPE&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;I-ORDINAL&quot;</td><td>&quot;I-PERCENT&quot;</td><td>&quot;B-PRODUCT&quot;</td><td>&quot;B-MONEY&quot;</td><td>&quot;B-LANGUAGE&quot;</td><td>&quot;B-MONEY&quot;</td><td>&quot;I-LOC&quot;</td><td>&quot;B-MONEY&quot;</td><td>&quot;B-PERCENT&quot;</td><td>&quot;I-ORG&quot;</td><td>&quot;B-MONEY&quot;</td><td>&quot;B-LANGUAGE&quot;</td><td>&quot;I-MONEY&quot;</td><td>&quot;B-MONEY&quot;</td><td>&quot;B-LANGUAGE&quot;</td><td>&quot;I-LOC&quot;</td><td>&quot;B-PERCENT&quot;</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (1, 44)\n",
              "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
              "│ [CL ┆ Not ┆ :   ┆ The ┆ '   ┆ s   ┆ a   ┆ pie ┆ by  ┆ Geo ┆ Pac ┆ ##e ┆ in  ┆ The ┆ New ┆ Yor ┆ -   ┆ L   ┆ ##R ┆ Bet ┆ ##r ┆ ##e ┆ the ┆ Ira ┆ ##s ┆ who ┆ tru ┆ Ame ┆ mos ┆ R   ┆ abo ┆ all ┆ thi ┆ ,   ┆ but ┆ it  ┆ way ┆ too ┆ lon ┆ to  ┆ blo ┆ her ┆ .   ┆ [SE │\n",
              "│ S]  ┆ e   ┆ --- ┆ re  ┆ --- ┆ --- ┆ --- ┆ ce  ┆ --- ┆ rge ┆ k   ┆ r   ┆ --- ┆ --- ┆ --- ┆ ker ┆ --- ┆ --- ┆ B   ┆ --- ┆ ay  ┆ d   ┆ --- ┆ qi  ┆ --- ┆ --- ┆ ste ┆ ric ┆ t   ┆ --- ┆ ut  ┆ --- ┆ s   ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ g   ┆ --- ┆ g   ┆ e   ┆ --- ┆ P]  │\n",
              "│ --- ┆ --- ┆ str ┆ --- ┆ str ┆ str ┆ str ┆ --- ┆ str ┆ --- ┆ --- ┆ --- ┆ str ┆ str ┆ str ┆ --- ┆ str ┆ str ┆ --- ┆ str ┆ --- ┆ --- ┆ str ┆ --- ┆ str ┆ str ┆ d   ┆ a   ┆ --- ┆ str ┆ --- ┆ str ┆ --- ┆ str ┆ str ┆ str ┆ str ┆ str ┆ --- ┆ str ┆ --- ┆ --- ┆ str ┆ --- │\n",
              "│ str ┆ str ┆     ┆ str ┆     ┆     ┆     ┆ str ┆     ┆ str ┆ str ┆ str ┆     ┆     ┆     ┆ str ┆     ┆     ┆ str ┆     ┆ str ┆ str ┆     ┆ str ┆     ┆     ┆ --- ┆ --- ┆ str ┆     ┆ str ┆     ┆ str ┆     ┆     ┆     ┆     ┆     ┆ str ┆     ┆ str ┆ str ┆     ┆ str │\n",
              "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ str ┆ str ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
              "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
              "│ I-L ┆ I-L ┆ I-M ┆ B-M ┆ I-M ┆ B-G ┆ B-G ┆ I-O ┆ I-M ┆ B-P ┆ B-G ┆ I-M ┆ I-F ┆ I-L ┆ I-M ┆ I-M ┆ B-G ┆ B-L ┆ B-G ┆ I-M ┆ I-M ┆ I-M ┆ B-L ┆ B-P ┆ I-O ┆ I-G ┆ I-M ┆ I-O ┆ I-P ┆ B-P ┆ B-M ┆ B-L ┆ B-M ┆ I-L ┆ B-M ┆ B-P ┆ I-O ┆ B-M ┆ B-L ┆ I-M ┆ B-M ┆ B-L ┆ I-L ┆ B-P │\n",
              "│ OC  ┆ OC  ┆ ONE ┆ ONE ┆ ONE ┆ PE  ┆ PE  ┆ RDI ┆ ONE ┆ ROD ┆ PE  ┆ ONE ┆ AC  ┆ OC  ┆ ONE ┆ ONE ┆ PE  ┆ ANG ┆ PE  ┆ ONE ┆ ONE ┆ ONE ┆ OC  ┆ ROD ┆ RG  ┆ PE  ┆ ONE ┆ RDI ┆ ERC ┆ ROD ┆ ONE ┆ ANG ┆ ONE ┆ OC  ┆ ONE ┆ ERC ┆ RG  ┆ ONE ┆ ANG ┆ ONE ┆ ONE ┆ ANG ┆ OC  ┆ ERC │\n",
              "│     ┆     ┆ Y   ┆ Y   ┆ Y   ┆     ┆     ┆ NAL ┆ Y   ┆ UCT ┆     ┆ Y   ┆     ┆     ┆ Y   ┆ Y   ┆     ┆ UAG ┆     ┆ Y   ┆ Y   ┆ Y   ┆     ┆ UCT ┆     ┆     ┆ Y   ┆ NAL ┆ ENT ┆ UCT ┆ Y   ┆ UAG ┆ Y   ┆     ┆ Y   ┆ ENT ┆     ┆ Y   ┆ UAG ┆ Y   ┆ Y   ┆ UAG ┆     ┆ ENT │\n",
              "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ E   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ E   ┆     ┆     ┆     ┆     ┆     ┆     ┆ E   ┆     ┆     ┆ E   ┆     ┆     │\n",
              "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pass the input to the model and extract the predictions\n",
        "inputs_device: dict[str, Tensor] = {\n",
        "    k: torch.tensor(v).to(device) for k, v in inputs.items()\n",
        "}\n",
        "outputs = model(**inputs_device).logits\n",
        "predictions: Tensor = torch.argmax(outputs, dim=-1)\n",
        "print(f\"Number of tokens in sequence: {len(tokens)}\")\n",
        "\n",
        "data: dict[str, str] = {\n",
        "    col: tags.names[p] for col, p in zip(tokens, predictions.flatten())\n",
        "}\n",
        "\n",
        "pl.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go588DZYq0Xv"
      },
      "outputs": [],
      "source": [
        "# text.split()\n",
        "# pattern: str = r\"[,.:;?!\\s]+\"\n",
        "# tokens: list[str] = re.compile(pattern).split(text)\n",
        "# tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ePE2GuHq0Xv",
        "outputId": "1282fe21-7b0d-4255-bca1-0a22ebec9920"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 5)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample = ds_dict[\"train\"][10]\n",
        "\n",
        "words, inp_labels = sample[\"tokens\"], sample[\"labels\"]\n",
        "\n",
        "len(words), len(inp_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxuaVDxfq0Xv",
        "outputId": "5f7db626-8720-4613-8faa-3329f8988813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]', 'Journalists', 'sources', 'and', 'jail', '/', '.', '[SEP]']"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize each word and specify that the input sequence has already been split into words.\n",
        "tokenized_input = tokenizer(words, is_split_into_words=True)\n",
        "tokens: list[str] = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoM9KZPtq0Xv",
        "outputId": "60433b0c-7583-4f32-f665-2f3f483b5003"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 4, None]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_ids = tokenized_input.word_ids()\n",
        "word_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl302OdTq0Xv",
        "outputId": "4195715f-e402-4c17-dd7f-cf40946a0fa7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>[CLS]</td>\n",
              "      <td>Journalists</td>\n",
              "      <td>sources</td>\n",
              "      <td>and</td>\n",
              "      <td>jail</td>\n",
              "      <td>/</td>\n",
              "      <td>.</td>\n",
              "      <td>[SEP]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word IDs</th>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label IDs</th>\n",
              "      <td>-100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-100</td>\n",
              "      <td>-100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Labels</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0            1        2    3     4     5     6      7\n",
              "Tokens     [CLS]  Journalists  sources  and  jail     /     .  [SEP]\n",
              "Word IDs    None            0        1    2     3     4     4   None\n",
              "label IDs   -100            0        0    0     0     0  -100   -100\n",
              "Labels         0            0        0    0     0  None  None   None"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Align the labels\n",
        "prev_word_idx: int | None = None\n",
        "label_ids: list[int] = []\n",
        "\n",
        "for word_idx in word_ids:\n",
        "    if word_idx is None or word_idx == prev_word_idx:\n",
        "        label_ids.append(-100)\n",
        "    else:\n",
        "        label_ids.append(inp_labels[word_idx])\n",
        "    prev_word_idx = word_idx\n",
        "\n",
        "\n",
        "# Update the labels\n",
        "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
        "index = [\"Tokens\", \"Word IDs\", \"label IDs\", \"Labels\"]\n",
        "\n",
        "pd.DataFrame([tokens, word_ids, label_ids, inp_labels], index=index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRsYW_mtq0Xw"
      },
      "source": [
        "#### Comment\n",
        "\n",
        "- The ID `-100` is used to mask subword representations in PyTorch's cross-entropy loss to ignore them during training, preventing their influence on the model's learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILWJnO8kq0Xw"
      },
      "outputs": [],
      "source": [
        "# Putting it together\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "\n",
        "\n",
        "def tokenize_and_align_labels(examples: dict[str, list]) -> dict[str, list]:\n",
        "    labels: list[list[int]] = []\n",
        "\n",
        "    # Tokenize each word and specify that the input sequence has\n",
        "    # already been split into words.\n",
        "    tokenized_inputs: dict[str, list] = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "        max_length=config.max_position_embeddings,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    for idx, label in enumerate(examples[\"labels\"]):\n",
        "        word_ids: list[int | None] = tokenized_inputs.word_ids(batch_index=idx)\n",
        "        prev_word_idx: int | None = None\n",
        "        label_ids: list[int] = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None or word_idx == prev_word_idx:\n",
        "                label_ids.append(-100)\n",
        "            else:\n",
        "                label_ids.append(label[word_idx])\n",
        "            prev_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    # Add the labels to the inputs\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "def encode_dataset(corpus: DatasetDict) -> DatasetDict:\n",
        "    encoded_corpus = DatasetDict()\n",
        "    for split, dataset in corpus.items():\n",
        "        encoded_corpus[split] = dataset.map(\n",
        "            tokenize_and_align_labels,\n",
        "            batched=True,\n",
        "            remove_columns=[\"tokens\", \"ner_labels\"],\n",
        "            desc=f\"Running tokenizer on {split} split\",\n",
        "        )\n",
        "    return encoded_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjIz7OSPq0Xw",
        "outputId": "82538434-d53c-4f01-82e1-de11ed845301",
        "colab": {
          "referenced_widgets": [
            "87937f1a9f4c4a9aae2a1b298e2a7d5d"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87937f1a9f4c4a9aae2a1b298e2a7d5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on validation split:   0%|          | 0/222 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document_id', 'labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1940\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['document_id', 'labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 222\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document_id', 'labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 222\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_dict_encoded: DatasetDict = encode_dataset(ds_dict)\n",
        "ds_dict_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TgYuGxOq0Xw"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Performance Metrics\n",
        "\n",
        "- Evaluating NER models involves precision, recall, and F1-score.\n",
        "- All words of an entity must be predicted correctly.\n",
        "- The `seqeval` library can compute these metrics using the `classification_report()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46WhnTucq0Xx"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "\n",
        "def align_predictions(\n",
        "    predictions: np.ndarray, label_ids: np.ndarray\n",
        ") -> tuple[list[list[str]], list[list[str]]]:\n",
        "    \"\"\"\n",
        "    Align predictions with label IDs and convert them to tag strings. It's\n",
        "    required to convert the model outputs to the format `seqeval` expects.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    predictions : np.ndarray\n",
        "        The prediction tensor of shape (batch_size, seq_len, num_classes).\n",
        "    label_ids : np.ndarray\n",
        "        The label IDs tensor of shape (batch_size, seq_len).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple[list[list[str]], list[list[str]]]\n",
        "        A tuple containing two lists:\n",
        "        - preds_list: List of lists containing predicted tags for each sequence.\n",
        "        - labels_list: List of lists containing true tags for each sequence.\n",
        "    \"\"\"\n",
        "    preds: np.ndarray = np.argmax(predictions, axis=2)\n",
        "    batch_size, seq_len = preds.shape\n",
        "    labels_list: list[list[str]] = []\n",
        "    preds_list: list[list[str]] = []\n",
        "\n",
        "    for batch_idx in range(batch_size):\n",
        "        example_labels: list[str] = []\n",
        "        example_preds: list[str] = []\n",
        "        for seq_idx in range(seq_len):\n",
        "            # Skip the special tokens (label IDs = -100)\n",
        "            if label_ids[batch_idx, seq_idx] != -100:\n",
        "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
        "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
        "\n",
        "        labels_list.append(example_labels)\n",
        "        preds_list.append(example_preds)\n",
        "\n",
        "    return preds_list, labels_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTrl4cAXq0Xx",
        "outputId": "4cf3358a-5e50-4140-f0fa-9310383c42cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /Users/neidu/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "\n",
        "# Load the .env file\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "\n",
        "# Access an environment variable\n",
        "HF_NOTEBOOK_TOKEN = os.getenv(\"HF_NOTEBOOK_TOKEN\")\n",
        "login(token=HF_NOTEBOOK_TOKEN, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXxhSVwmq0Xy"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "\n",
        "# Define the training arguments\n",
        "num_epochs: int = 3\n",
        "batch_size: int = 24  # (4 because data is small)\n",
        "logging_steps: int = len(ds_dict_encoded[\"train\"]) // batch_size\n",
        "model_name: str = f\"{chkpoint}-finetuned-bert-tiny\"\n",
        "\n",
        "# The model's predictions are evaluated on the validation set after each epoch.\n",
        "# Weight decay is adjusted, and checkpointing is disabled to speed up training.\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name,\n",
        "    log_level=\"error\",\n",
        "    num_train_epochs=num_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_steps=1e6,\n",
        "    weight_decay=0.01,\n",
        "    disable_tqdm=False,\n",
        "    logging_steps=logging_steps,\n",
        "    # push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZectm2qq0Xy"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred: tuple[Any, Any]) -> dict[str, float]:\n",
        "    \"\"\"\n",
        "    Compute F1 score for the predictions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    eval_pred :tuple[Any, Any]\n",
        "        A tuple containing model predictions and true labels.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict[str, float]\n",
        "        A dictionary containing the F1 score.\n",
        "    \"\"\"\n",
        "    y_pred, y_true = align_predictions(*eval_pred)\n",
        "    return {\"f1\": f1_score(y_true, y_pred)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENPDBzrUq0Xy"
      },
      "source": [
        "#### Comment\n",
        "\n",
        "- The labels in sequence classification are padded with `-100` to avoid affecting the loss.\n",
        "- A `model_init()` method is used to load an untrained model for training to avoid creating a new model for each Trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCy-TedOq0Xy"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikF0ZPkYq0Xz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESiHgzICq0Xz"
      },
      "outputs": [],
      "source": [
        "def model_init() -> BertForTokenClassification:\n",
        "    \"\"\"\n",
        "    Initialize and return a BertForTokenClassification model.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    BertForTokenClassification\n",
        "        A pre-trained BERT model for token classification, loaded with the specified\n",
        "        checkpoint and configuration, and moved to the specified device.\n",
        "    \"\"\"\n",
        "    return BertForTokenClassification.from_pretrained(\n",
        "        chkpoint, config=config, ignore_mismatched_sizes=True\n",
        "    ).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_vpzqgiq0Xz"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3outJo9q0Xz",
        "outputId": "c6dd6a2b-cfc5-42c9-9ae1-cb49fe1ab6d2",
        "colab": {
          "referenced_widgets": [
            "c3edf1e2a02a4e5abff09132da073665"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3edf1e2a02a4e5abff09132da073665",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/243 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[75], line 16\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# A model_init() method is used to load an untrained model for\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# training to avoid creating a new model for each Trainer.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      7\u001b[0m     model_init\u001b[38;5;241m=\u001b[39mmodel_init,\n\u001b[1;32m      8\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/torch_p11/lib/python3.11/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/torch_p11/lib/python3.11/site-packages/transformers/trainer.py:2118\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2118\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2121\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2122\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2124\u001b[0m ):\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m~/miniconda3/envs/torch_p11/lib/python3.11/site-packages/transformers/trainer.py:3045\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3043\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3045\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
            "File \u001b[0;32m~/miniconda3/envs/torch_p11/lib/python3.11/site-packages/accelerate/accelerator.py:2159\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2159\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/torch_p11/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/torch_p11/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "\n",
        "# A model_init() method is used to load an untrained model for\n",
        "# training to avoid creating a new model for each Trainer.\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=ds_dict_encoded[\"train\"],\n",
        "    eval_dataset=ds_dict_encoded[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1gGlJ-Lq0Xz"
      },
      "outputs": [],
      "source": [
        "def tag_text(\n",
        "    text: str,\n",
        "    tags: ClassLabel,\n",
        "    model: BertModel,\n",
        "    tokenizer: AutoTokenizer,\n",
        ") -> pl.DataFrame:\n",
        "    # Get tokens with special characters\n",
        "    tokens: list[str] = tokenizer(text).tokens()\n",
        "\n",
        "    # Encode\n",
        "    inputs: Tensor = tokenizer(\n",
        "        text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {k: torch.tensor(v).to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Get predictions\n",
        "    outputs: Tensor = model(**inputs).logits\n",
        "\n",
        "    # Get predictions\n",
        "    predictions: Tensor = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "    data: dict[str, str] = {\n",
        "        col: tags.names[p]\n",
        "        for col, p in zip(tokens, predictions.flatten().cpu().numpy())\n",
        "    }\n",
        "\n",
        "    return pl.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3x4AeaZq0X0"
      },
      "outputs": [],
      "source": [
        "text: str = \"tomorrow\"\n",
        "\n",
        "tag_text(text, tags, trainer.model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgeFPB2Kq0X0"
      },
      "outputs": [],
      "source": [
        "trainer.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YRcFKxHq0X0"
      },
      "outputs": [],
      "source": [
        "ds_dict[\"test\"][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSelOQDVq0X0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "039a53788fb443a2aa9c6052d9151767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f380aa4801db49f9a1860f21040e2a9f",
              "IPY_MODEL_be21aee55f49472a89022fb8a12c0193",
              "IPY_MODEL_2f7310fe16cf4b53acd0c4ab9ffe28e8"
            ],
            "layout": "IPY_MODEL_e9a694d8685e483e8480aad0f15e593d"
          }
        },
        "f380aa4801db49f9a1860f21040e2a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f70b0a3be40a4ada9d87dc57bb99c857",
            "placeholder": "​",
            "style": "IPY_MODEL_d1d5406df6b34c63a276d901b0ef0b83",
            "value": "Map:  78%"
          }
        },
        "be21aee55f49472a89022fb8a12c0193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b67d35bc643646519d63b1f55a7fafe5",
            "max": 1940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2e8ee7f4b8c4bb994b4e4aacfa845ce",
            "value": 1519
          }
        },
        "2f7310fe16cf4b53acd0c4ab9ffe28e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034e27c5680649feb1610660b9922508",
            "placeholder": "​",
            "style": "IPY_MODEL_7ba8d112af17429ba9f2cfb0b9977626",
            "value": " 1519/1940 [00:13&lt;00:02, 161.43 examples/s]"
          }
        },
        "e9a694d8685e483e8480aad0f15e593d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f70b0a3be40a4ada9d87dc57bb99c857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d5406df6b34c63a276d901b0ef0b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b67d35bc643646519d63b1f55a7fafe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e8ee7f4b8c4bb994b4e4aacfa845ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "034e27c5680649feb1610660b9922508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba8d112af17429ba9f2cfb0b9977626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}