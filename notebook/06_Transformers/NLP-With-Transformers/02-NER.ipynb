{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chineidu/NLP-Tutorial/blob/main/notebook/06_Transformers/NLP-With-Transformers/02-NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtGFoeV9TuKy"
      },
      "source": [
        "# Multiingual Name Entity Recognition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U2gZ0AI1TuK0"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate datasets \\\n",
        "  seqeval mlxtend watermark rich"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64oQM8L7TuK1",
        "outputId": "3c84c6db-1609-4bbe-e5ea-60ffb5d1115c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.26.4\n",
            "pandas      : 2.1.4\n",
            "polars      : 0.20.2\n",
            "mlxtend     : 0.23.1\n",
            "transformers: 4.42.4\n",
            "\n",
            "conda environment: n/a\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext watermark\n",
        "%watermark -v -p numpy,pandas,polars,mlxtend,transformers --conda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3_pInrMJTuK2"
      },
      "outputs": [],
      "source": [
        "# Built-in library\n",
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "from typing import Any, Optional, Union\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "from rich.console import Console\n",
        "from rich.theme import Theme\n",
        "\n",
        "custom_theme = Theme(\n",
        "    {\n",
        "        \"info\": \"#76FF7B\",\n",
        "        \"warning\": \"#FBDDFE\",\n",
        "        \"error\": \"#FF0000\",\n",
        "    }\n",
        ")\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NumPy settings\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "# Pandas settings\n",
        "pd.options.display.max_rows = 1_000\n",
        "pd.options.display.max_columns = 1_000\n",
        "pd.options.display.max_colwidth = 600\n",
        "\n",
        "# Polars settings\n",
        "pl.Config.set_fmt_str_lengths(1_000)\n",
        "pl.Config.set_tbl_cols(n=1_000)\n",
        "pl.Config.set_tbl_rows(n=200)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# auto reload imports# Built-in library\n",
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "from typing import Any, Optional, Union\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "from rich.console import Console\n",
        "from rich.theme import Theme\n",
        "\n",
        "custom_theme = Theme(\n",
        "    {\n",
        "        \"info\": \"#76FF7B\",\n",
        "        \"warning\": \"#FBDDFE\",\n",
        "        \"error\": \"#FF0000\",\n",
        "    }\n",
        ")\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NumPy settings\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "# Pandas settings\n",
        "pd.options.display.max_rows = 1_000\n",
        "pd.options.display.max_columns = 1_000\n",
        "pd.options.display.max_colwidth = 600\n",
        "\n",
        "# Polars settings\n",
        "pl.Config.set_fmt_str_lengths(1_000)\n",
        "pl.Config.set_tbl_cols(n=1_000)\n",
        "pl.Config.set_tbl_rows(500)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# # Black code formatter (Optional)\n",
        "# %load_ext lab_black\n",
        "\n",
        "# # auto reload imports\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, get_dataset_config_names, load_dataset\n",
        "\n",
        "\n",
        "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
        "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJDTIdA4UB0T",
        "outputId": "2f78893d-50c1-4ea7-e411-f6451e7d74ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XTREME has 183 configurations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the config that starts with `PAN`\n",
        "pan_subsets: list[str] = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
        "print(pan_subsets[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ffkse3gUBy8",
        "outputId": "c4fbf80e-18b2-4f61-c06e-63963121c475"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "\n",
        "# Load English subset\n",
        "en_dataset: DatasetDict = load_dataset(\"xtreme\", name=\"PAN-X.en\")\n",
        "en_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2khYdXdoUBvu",
        "outputId": "a255ed40-94ec-450a-da4b-495c3f75a744"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs'],\n",
              "        num_rows: 20000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle\n",
        "en_dataset['train'].shuffle(seed=123)\n",
        "\n",
        "# Select a specific number of records\n",
        "print(en_dataset['train'].select(range(10)))\n",
        "\n",
        "# Check the number pf records\n",
        "print(f\"Number of records: {len(en_dataset['train']):,}\")\n",
        "\n",
        "# OR\n",
        "print(f\"Number of records: {en_dataset['train'].num_rows:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5BmpdS7Z1d2",
        "outputId": "41442a29-b21b-42cf-dca5-13ee224c947d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['tokens', 'ner_tags', 'langs'],\n",
            "    num_rows: 10\n",
            "})\n",
            "Number of records: 20,000\n",
            "Number of records: 20,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Coment\n",
        "\n",
        "- To create a realistic Swiss corpus, we'll sample PAN-X corpora in German (62.9%), French (22.9%), Italian (8.4%), and English (5.9%) according to their spoken proportions in Switzerland.\n",
        "- This will create a language imbalance simulating real-world datasets.\n",
        "- We'll use a Python `defaultdict` to store language codes and corresponding PAN-X corpora."
      ],
      "metadata": {
        "id": "yMh4leIUUBtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "seed: int = 123\n",
        "langs: list[str] = [\"de\", \"fr\", \"it\", \"en\"]\n",
        "fracs: list[float] = [0.629, 0.229, 0.084, 0.059]\n",
        "panx_ch: defaultdict = defaultdict(DatasetDict)\n",
        "\n",
        "for lang, frac in zip(langs, fracs):\n",
        "    # Load dataset\n",
        "    ds: DatasetDict = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
        "    # Shuffle and downsample each split according to spoken proportion\n",
        "    for split in ds:\n",
        "      num_rows: int = ds[split].num_rows\n",
        "      panx_ch[lang][split] = ds[split].shuffle(seed=seed).select(range(int(frac * num_rows)))\n"
      ],
      "metadata": {
        "id": "w6OwVYzkUBrL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "panx_ch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8_zq0OMUBpj",
        "outputId": "2ec711a3-83c6-4c57-85fb-a29aafcfe675"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(datasets.dataset_dict.DatasetDict,\n",
              "            {'de': DatasetDict({\n",
              "                 train: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 12580\n",
              "                 })\n",
              "                 validation: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 6290\n",
              "                 })\n",
              "                 test: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 6290\n",
              "                 })\n",
              "             }),\n",
              "             'fr': DatasetDict({\n",
              "                 train: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 4580\n",
              "                 })\n",
              "                 validation: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 2290\n",
              "                 })\n",
              "                 test: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 2290\n",
              "                 })\n",
              "             }),\n",
              "             'it': DatasetDict({\n",
              "                 train: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 1680\n",
              "                 })\n",
              "                 validation: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 840\n",
              "                 })\n",
              "                 test: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 840\n",
              "                 })\n",
              "             }),\n",
              "             'en': DatasetDict({\n",
              "                 train: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 1180\n",
              "                 })\n",
              "                 validation: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 590\n",
              "                 })\n",
              "                 test: Dataset({\n",
              "                     features: ['tokens', 'ner_tags', 'langs'],\n",
              "                     num_rows: 590\n",
              "                 })\n",
              "             })})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, val in panx_ch.items():\n",
        "  print(val)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw1Q71Ezdu6j",
        "outputId": "07edd4aa-8a74-4f9e-a345-11330b011998"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'langs'],\n",
            "        num_rows: 12580\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'langs'],\n",
            "        num_rows: 6290\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'langs'],\n",
            "        num_rows: 6290\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of training examples per language\n",
        "res: dict[str, int] = {key:val[\"train\"].num_rows for key, val in panx_ch.items()}\n",
        "pl.DataFrame(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "RkzgeVcnUBnG",
        "outputId": "e630f707-e9ed-41c7-81fa-bd13a3a957fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (1, 4)\n",
              "┌───────┬──────┬──────┬──────┐\n",
              "│ de    ┆ fr   ┆ it   ┆ en   │\n",
              "│ ---   ┆ ---  ┆ ---  ┆ ---  │\n",
              "│ i64   ┆ i64  ┆ i64  ┆ i64  │\n",
              "╞═══════╪══════╪══════╪══════╡\n",
              "│ 12580 ┆ 4580 ┆ 1680 ┆ 1180 │\n",
              "└───────┴──────┴──────┴──────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>de</th><th>fr</th><th>it</th><th>en</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>12580</td><td>4580</td><td>1680</td><td>1180</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect one of the languages\n",
        "sample = panx_ch[\"en\"][\"train\"][0]\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo8LrqiGUBkf",
        "outputId": "c8dac141-d314-413d-a77f-5e05c57a814b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['Collin', 'Peterson', '(', 'D-MN', ')'],\n",
              " 'ner_tags': [1, 2, 0, 0, 0],\n",
              " 'langs': ['en', 'en', 'en', 'en', 'en']}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(panx_ch[\"en\"][\"train\"].features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl9rVw5EUBh8",
        "outputId": "58634496-f454-425a-c739-c933229d2cc0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None), 'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_tags = panx_ch[\"en\"][\"train\"].features[\"ner_tags\"]\n",
        "tags = ner_tags.feature\n",
        "print(f\"{ner_tags = }\")\n",
        "print(f\"{tags = }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_cej5NDlZ9Y",
        "outputId": "9639fe18-9be0-4763-9fc5-9b34c2f17993"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ner_tags = Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
            "tags = ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, _ in enumerate(tags.names):\n",
        "  console.print(f\"{idx} ==> {tags.int2str(idx)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "GnndVHfNUBe_",
        "outputId": "248c2fee-e263-498d-aa9e-9049a20d4b27"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m0\u001b[0m ==> O\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> ==&gt; O\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m1\u001b[0m ==> B-PER\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> ==&gt; B-PER\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m2\u001b[0m ==> I-PER\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> ==&gt; I-PER\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m3\u001b[0m ==> B-ORG\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> ==&gt; B-ORG\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m4\u001b[0m ==> I-ORG\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> ==&gt; I-ORG\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m5\u001b[0m ==> B-LOC\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> ==&gt; B-LOC\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m6\u001b[0m ==> I-LOC\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> ==&gt; I-LOC\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(panx_ch[\"en\"][\"train\"][10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViWbYbkYUBc5",
        "outputId": "e193397c-bf90-4a11-d449-5076c33a55f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'langs': ['en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en',\n",
            "           'en'],\n",
            " 'ner_tags': [0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
            " 'tokens': ['Tries',\n",
            "            ':',\n",
            "            'Todd',\n",
            "            'Carney',\n",
            "            ',',\n",
            "            'Ricky',\n",
            "            'Leutele',\n",
            "            ',',\n",
            "            'Michael',\n",
            "            'Gordon',\n",
            "            ',',\n",
            "            'Jeff',\n",
            "            'Robson']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tag_names(batch: DatasetDict) -> dict[str, Any]:\n",
        "  return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
        "\n",
        "\n",
        "panx_de: DatasetDict = panx_ch[\"de\"].map(create_tag_names)\n",
        "\n",
        "panx_de[\"train\"][5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZECwRrdFUBaZ",
        "outputId": "248f434b-821d-4a14-aaab-ea0ad89e0006"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['Die',\n",
              "  'meisten',\n",
              "  'seiner',\n",
              "  'Gemälde',\n",
              "  'sind',\n",
              "  'im',\n",
              "  'Statens',\n",
              "  'Museum',\n",
              "  'for',\n",
              "  'Kunst',\n",
              "  'zu',\n",
              "  'sehen',\n",
              "  '.'],\n",
              " 'ner_tags': [0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 0],\n",
              " 'langs': ['de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de'],\n",
              " 'ner_tags_str': ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-ORG',\n",
              "  'I-ORG',\n",
              "  'I-ORG',\n",
              "  'I-ORG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O']}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl.DataFrame(panx_de[\"train\"].select_columns(['tokens', 'ner_tags_str'])[5]).transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "EPH8cG07UBWn",
        "outputId": "f938e2ff-c7ad-47c0-c7ac-8bba6ed087f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (2, 13)\n",
              "┌─────┬─────┬─────┬────────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐\n",
              "│ col ┆ col ┆ col ┆ column ┆ colum ┆ colum ┆ colum ┆ colum ┆ colum ┆ colum ┆ colum ┆ colum ┆ colum │\n",
              "│ umn ┆ umn ┆ umn ┆ _3     ┆ n_4   ┆ n_5   ┆ n_6   ┆ n_7   ┆ n_8   ┆ n_9   ┆ n_10  ┆ n_11  ┆ n_12  │\n",
              "│ _0  ┆ _1  ┆ _2  ┆ ---    ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   │\n",
              "│ --- ┆ --- ┆ --- ┆ str    ┆ str   ┆ str   ┆ str   ┆ str   ┆ str   ┆ str   ┆ str   ┆ str   ┆ str   │\n",
              "│ str ┆ str ┆ str ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
              "╞═════╪═════╪═════╪════════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╡\n",
              "│ Die ┆ mei ┆ sei ┆ Gemäld ┆ sind  ┆ im    ┆ State ┆ Museu ┆ for   ┆ Kunst ┆ zu    ┆ sehen ┆ .     │\n",
              "│     ┆ ste ┆ ner ┆ e      ┆       ┆       ┆ ns    ┆ m     ┆       ┆       ┆       ┆       ┆       │\n",
              "│     ┆ n   ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
              "│ O   ┆ O   ┆ O   ┆ O      ┆ O     ┆ O     ┆ B-ORG ┆ I-ORG ┆ I-ORG ┆ I-ORG ┆ O     ┆ O     ┆ O     │\n",
              "└─────┴─────┴─────┴────────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (2, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th><th>column_12</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Die&quot;</td><td>&quot;meisten&quot;</td><td>&quot;seiner&quot;</td><td>&quot;Gemälde&quot;</td><td>&quot;sind&quot;</td><td>&quot;im&quot;</td><td>&quot;Statens&quot;</td><td>&quot;Museum&quot;</td><td>&quot;for&quot;</td><td>&quot;Kunst&quot;</td><td>&quot;zu&quot;</td><td>&quot;sehen&quot;</td><td>&quot;.&quot;</td></tr><tr><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;B-ORG&quot;</td><td>&quot;I-ORG&quot;</td><td>&quot;I-ORG&quot;</td><td>&quot;I-ORG&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of all the tags\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "splits_freq = defaultdict(Counter)\n",
        "\n",
        "for split, ds in panx_de.items():\n",
        "  for row in ds[\"ner_tags_str\"]:\n",
        "    for tag in row:\n",
        "      # Focus on the `beginning` tags\n",
        "      if tag.startswith(\"B\"):\n",
        "        tag_type: str = tag.split(\"-\")[1]\n",
        "        splits_freq[split][tag_type] += 1"
      ],
      "metadata": {
        "id": "HZImnXFWDLyZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The tags are roughly equally distributed\n",
        "console.print(f\"{splits_freq = }\")\n",
        "\n",
        "pl.DataFrame(splits_freq).to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "Cm2A_Z2QDLtO",
        "outputId": "354c38ea-b531-41d4-ed69-71d608db8752"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "splits_freq = \u001b[1;35mdefaultdict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'collections.Counter'\u001b[0m\u001b[1m>\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'train'\u001b[0m: \u001b[1;35mCounter\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'LOC'\u001b[0m: \u001b[1;36m6039\u001b[0m, \u001b[32m'PER'\u001b[0m: \u001b[1;36m5862\u001b[0m, \u001b[32m'ORG'\u001b[0m: \n",
              "\u001b[1;36m5413\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'validation'\u001b[0m: \u001b[1;35mCounter\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'LOC'\u001b[0m: \u001b[1;36m3095\u001b[0m, \u001b[32m'PER'\u001b[0m: \u001b[1;36m2837\u001b[0m, \u001b[32m'ORG'\u001b[0m: \u001b[1;36m2721\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'test'\u001b[0m: \u001b[1;35mCounter\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'LOC'\u001b[0m: \u001b[1;36m3145\u001b[0m, \u001b[32m'PER'\u001b[0m: \u001b[1;36m2962\u001b[0m, \n",
              "\u001b[32m'ORG'\u001b[0m: \u001b[1;36m2620\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">splits_freq = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">defaultdict</span><span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'collections.Counter'</span><span style=\"font-weight: bold\">&gt;</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'train'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Counter</span><span style=\"font-weight: bold\">({</span><span style=\"color: #008000; text-decoration-color: #008000\">'LOC'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6039</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'PER'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5862</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ORG'</span>: \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5413</span><span style=\"font-weight: bold\">})</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'validation'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Counter</span><span style=\"font-weight: bold\">({</span><span style=\"color: #008000; text-decoration-color: #008000\">'LOC'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3095</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'PER'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2837</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ORG'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2721</span><span style=\"font-weight: bold\">})</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Counter</span><span style=\"font-weight: bold\">({</span><span style=\"color: #008000; text-decoration-color: #008000\">'LOC'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3145</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'PER'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2962</span>, \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'ORG'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2620</span><span style=\"font-weight: bold\">})})</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     train  \\\n",
              "0  {'PER': 5862, 'LOC': 6039, 'ORG': 5413}   \n",
              "\n",
              "                                validation  \\\n",
              "0  {'PER': 2837, 'LOC': 3095, 'ORG': 2721}   \n",
              "\n",
              "                                      test  \n",
              "0  {'ORG': 2620, 'PER': 2962, 'LOC': 3145}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14cae54b-4bef-4430-a667-e34c38d4052a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>validation</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'PER': 5862, 'LOC': 6039, 'ORG': 5413}</td>\n",
              "      <td>{'PER': 2837, 'LOC': 3095, 'ORG': 2721}</td>\n",
              "      <td>{'ORG': 2620, 'PER': 2962, 'LOC': 3145}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14cae54b-4bef-4430-a667-e34c38d4052a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14cae54b-4bef-4430-a667-e34c38d4052a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14cae54b-4bef-4430-a667-e34c38d4052a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pl\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"train\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"validation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "## Multilingual Transformers\n",
        "\n",
        "- Multilingual transformers are trained on multilingual corpora and they can generalize well across languages for various tasks.\n",
        "\n",
        "- This approach can outperform monolingual models for cross-lingual transfer, avoiding the need to train separate models for each language.\n",
        "\n",
        "- `CoNLL-2002` and `CoNLL-2003` are commonly used benchmarks for NER in these languages.\n",
        "\n",
        "- Multilingual transformer models are usually evaluated in three different ways:\n",
        "  - `en`: Fine-tune on the English training data and then evaluate on each language's test set.\n",
        "  - `each`: Fine-tune and evaluate on monolingual test data to measure per-language performance.\n",
        "  - `all`: Fine-tune on all the training data to evaluate on all on each languag's test set.\n",
        "\n",
        "  <br>\n",
        "\n",
        "- [XLM-RoBERTa](https://huggingface.co/docs/transformers/en/\n",
        "model_doc/xlm-roberta) (`XLM-R`) model will be used.\n",
        "\n",
        "- XLM-RoBERTa (XLM-R) is a multilingual transformer model trained on a massive dataset of text and code in 100 different languages.\n",
        "  \n",
        "- It can be used for a variety of tasks, including:\n",
        "\n",
        "  - Text classification: Sentiment analysis, topic classification, etc.\n",
        "  - Question answering: Extracting answers to questions from a given text.\n",
        "  - Translation: Translating text from one language to another.\n",
        "  - Named entity recognition: Identifying named entities in text, such as people, organizations, and locations.\n",
        "\n",
        "- XLM-R achieves state-of-the-art results on many cross-lingual benchmarks, and it is a powerful tool for natural language processing in multiple languages."
      ],
      "metadata": {
        "id": "8mU2jblxDLpk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9ZycFx6DLlp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenization: SentencePiece\n",
        "\n"
      ],
      "metadata": {
        "id": "GtiqQUzfLlUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "bert_model_name: str = \"bert-base-cased\"\n",
        "xlmr_model_name: str = \"xlm-roberta-base\"\n",
        "\n",
        "bert_tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "xlmr_tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
      ],
      "metadata": {
        "id": "CS53HkpRLlSN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text: str = \"Jack Sparrow loves New York!\"\n",
        "\n",
        "bert_tokens: list[str] = bert_tokenizer(text).tokens()\n",
        "xlmr_tokens: list[str] = xlmr_tokenizer(text).tokens()\n",
        "\n",
        "print(f\"{bert_tokens = }\")\n",
        "print(f\"{xlmr_tokens = }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38TcEJ5fLlO5",
        "outputId": "5a4d09c7-1e76-4ca2-c4fd-b17c65f944f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_tokens = ['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']\n",
            "xlmr_tokens = ['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization Pipeline\n",
        "\n",
        "<br>\n",
        "\n",
        "[![image.png](https://i.postimg.cc/zvJ0SrZz/image.png)](https://postimg.cc/dkx2wgVp)\n",
        "\n",
        "<br>\n",
        "\n",
        "- `Normalization`: it involves cleaning raw text by removing whitespace, accents, and standardizing Unicode characters. It also includes lowercasing to reduce vocabulary size. After normalization, our example string becomes \"jack sparrow loves new york!\".\n",
        "\n",
        "- `Pretokenization`: it splits text into words for easier tokenization. For English and similar languages, this is simple. For languages like Chinese, it's more complex and might require language-specific libraries.\n",
        "\n",
        "- `Tokenizer model`: it splits words into subwords to reduce vocabulary size and out-of-vocabulary tokens. This is done using algorithms like BPE, Unigram, and WordPiece. For example, \"jack sparrow\" might become \"[jack, spa, rrow]\".\n",
        "\n",
        "- `Postprocessing`: it's the final step in tokenization, where additional tokens (like [CLS] and [SEP]) are added to the beginning and end of the token sequence to prepare it for input into a model like BERT.\n",
        "\n",
        "\n",
        "<hr><br>\n",
        "\n",
        "#### SentencePiece Tokenizer\n",
        "\n",
        "- The SentencePiece tokenizer is a flexible subword segmentation method that handles multilingual text effectively by preserving whitespace and using Unicode characters.\n",
        "\n",
        "- It avoids ambiguities in detokenization and can be used for various languages without relying on language-specific pretokenizers."
      ],
      "metadata": {
        "id": "KXYZF4UjLlKU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J31u38l3LlHQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformers For Classification Vs NER\n",
        "\n",
        "**1.) Classification**\n",
        "\n",
        "[![image.png](https://i.postimg.cc/Mph53R2r/image.png)](https://postimg.cc/tsNFYsgh)\n",
        "\n",
        "<br>\n",
        "\n",
        "**2.) Named Entity Recognition**\n",
        "\n",
        "[![image.png](https://i.postimg.cc/26YwrD5Q/image.png)](https://postimg.cc/rdhWN7xs)\n",
        "\n",
        "<br>\n",
        "\n",
        "- In `token classification`, assign the label (e.g., B-PER) to the first subword (\"Chr\") and ignore subsequent subwords (\"##ista\"). This convention follows the BERT paper and maintains the IOB2 format. Postprocessing can propagate the label to all subwords.\n",
        "\n",
        "\n",
        "### Anatomy Transformers Model Class\n",
        "\n",
        "- The Transformers API organizes models by task, but this can be limiting.\n",
        "- If a desired task model doesn't exist, it can be difficult to implement a custom model.\n",
        "- However, Transformers provides tools to load pretrained weights and use task-specific helper functions, making it easier to create custom models.\n",
        "\n",
        "### Bodies And Heads\n",
        "\n",
        "- Transformers are versatile due to their `body-head` structure.\n",
        "- The `head` is task-specific, while the `body` is task-agnostic.\n",
        "- The body includes embeddings and transformer layers. The Transformers code reflects this structure with classes like BertModel and GPT2Model that return hidden states.\n",
        "- Task-specific models such as `BertForMaskedLM` or `BertForSequenceClassification` use the base model and add the necessary head on top of the hidden states.\n",
        "\n",
        "\n",
        "<hr><br>\n",
        "\n",
        "### Creating Custom Model For Token Classification\n",
        "\n",
        "- Building a custom token classification head for XLM-R is similar to RoBERTa and an existing class, XLMRobertaForTokenClassification, can be used directly for this task.\n",
        "- However, going through the exercise of building a custom model for educational purposes.\n",
        "\n",
        "- We need a data structure for our XLM-R NER tagger.\n",
        "- It will have a configuration object and a forward function."
      ],
      "metadata": {
        "id": "UyBSZ304PgU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaConfig, XLMRobertaModel\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "from transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel\n",
        "\n",
        "\n",
        "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
        "    class_config = XLMRobertaConfig\n",
        "\n",
        "    def __init__(self, config) -> None:\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        # Load model body\n",
        "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
        "\n",
        "        # Setup classification head\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        # Load and initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        labels=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        # Get the encoder representations using model body\n",
        "        outputs: Tensor = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        # Apply classifier to encoder reps\n",
        "        sequence_output: Tensor = self.dropout(outputs[0])\n",
        "        logits: Tensor = self.classifier(sequence_output)\n",
        "\n",
        "        # Calculate losses\n",
        "        loss: Optional[Tensor] = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        # Return model output object\n",
        "        return TokenClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )"
      ],
      "metadata": {
        "id": "cyjdnj2rPgAw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment\n",
        "\n",
        "- The config_class ensures standard XLM-R settings.\n",
        "- The super() method calls the initialization function of the RobertaPreTrainedModel class.\n",
        "- The model body is extended with a classification head.\n",
        "- The forward() method defines the model's behavior.\n",
        "- The hidden state is fed through the dropout and classification layers.\n",
        "- The loss is calculated if labels are provided.\n",
        "- The outputs are wrapped in a TokenClassifierOutput object.\n",
        "- This custom transformer model inherits from a PreTrainedModel, allowing access to useful Transformer utilities.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Loading A Custom Model\n"
      ],
      "metadata": {
        "id": "VEvk1kLAPedF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep59CaenMJ8N",
        "outputId": "64255566-f26a-42d4-dd16-0c6f2716e6fa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "\n",
        "index2tag: dict[int, str] = {idx: tag for idx, tag in enumerate(tags.names)}\n",
        "tag2index: dict[str, int] = {tag: idx for idx, tag in enumerate(tags.names)}\n",
        "\n",
        "xlmr_config: XLMRobertaConfig = AutoConfig.from_pretrained(\n",
        "    xlmr_model_name, num_labels=len(tags.names), id2label=index2tag,\n",
        "    label2id=tag2index\n",
        ")\n",
        "xlmr_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pm8OA9DLxPz",
        "outputId": "228dbd28-43d0-449c-824e-3b5aaaa3cafb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaConfig {\n",
              "  \"_name_or_path\": \"xlm-roberta-base\",\n",
              "  \"architectures\": [\n",
              "    \"XLMRobertaForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"O\",\n",
              "    \"1\": \"B-PER\",\n",
              "    \"2\": \"I-PER\",\n",
              "    \"3\": \"B-ORG\",\n",
              "    \"4\": \"I-ORG\",\n",
              "    \"5\": \"B-LOC\",\n",
              "    \"6\": \"I-LOC\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"B-LOC\": 5,\n",
              "    \"B-ORG\": 3,\n",
              "    \"B-PER\": 1,\n",
              "    \"I-LOC\": 6,\n",
              "    \"I-ORG\": 4,\n",
              "    \"I-PER\": 2,\n",
              "    \"O\": 0\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 514,\n",
              "  \"model_type\": \"xlm-roberta\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.42.4\",\n",
              "  \"type_vocab_size\": 1,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 250002\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "xlmr_model = XLMRobertaForTokenClassification.from_pretrained(\n",
        "    xlmr_model_name, config=xlmr_config\n",
        ").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pM1gwj4LxMX",
        "outputId": "b0f3b1ab-dcd7-4c76-db78-edb6ff53f09f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nkT1YmKYNrXL",
        "outputId": "d1002354-dcc8-40ba-e6e8-ad2c5c6d3cad"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Jack Sparrow loves New York!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the tokenizer and model were properly initialized\n",
        "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
        "data: dict[str, int] = {\n",
        "    col: int(val) for col, val in zip(xlmr_tokens, input_ids.flatten())\n",
        "}\n",
        "print(data)\n",
        "\n",
        "pl.DataFrame(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "Z6o_QZoRLxJH",
        "outputId": "074b97f5-6a12-4675-b9a6-2260f6d6b557"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<s>': 0, '▁Jack': 21763, '▁Spar': 37456, 'row': 15555, '▁love': 5161, 's': 7, '▁New': 2356, '▁York': 5753, '!': 38, '</s>': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (1, 10)\n",
              "┌─────┬───────┬───────┬───────┬───────┬─────┬──────┬───────┬─────┬──────┐\n",
              "│ <s> ┆ ▁Jack ┆ ▁Spar ┆ row   ┆ ▁love ┆ s   ┆ ▁New ┆ ▁York ┆ !   ┆ </s> │\n",
              "│ --- ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ --- ┆ ---  ┆ ---   ┆ --- ┆ ---  │\n",
              "│ i64 ┆ i64   ┆ i64   ┆ i64   ┆ i64   ┆ i64 ┆ i64  ┆ i64   ┆ i64 ┆ i64  │\n",
              "╞═════╪═══════╪═══════╪═══════╪═══════╪═════╪══════╪═══════╪═════╪══════╡\n",
              "│ 0   ┆ 21763 ┆ 37456 ┆ 15555 ┆ 5161  ┆ 7   ┆ 2356 ┆ 5753  ┆ 38  ┆ 2    │\n",
              "└─────┴───────┴───────┴───────┴───────┴─────┴──────┴───────┴─────┴──────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>&lt;s&gt;</th><th>▁Jack</th><th>▁Spar</th><th>row</th><th>▁love</th><th>s</th><th>▁New</th><th>▁York</th><th>!</th><th>&lt;/s&gt;</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>21763</td><td>37456</td><td>15555</td><td>5161</td><td>7</td><td>2356</td><td>5753</td><td>38</td><td>2</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the input to the model and extract the predictions\n",
        "outputs = xlmr_model(input_ids.to(device)).logits\n",
        "predictions: Tensor = torch.argmax(outputs, dim=-1)\n",
        "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
        "\n",
        "# (batch_size, num_tokens, num_tags)\n",
        "print(f\"Shape of outputs: {outputs.shape}\")\n",
        "\n",
        "# (batch_size, num_tokens)\n",
        "print(f\"Shape of predictions: {predictions.shape}\")\n",
        "\n",
        "print(f\"{predictions = }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlwpB0shPCie",
        "outputId": "7db12838-bcda-41c4-9532-53f594363073"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens in sequence: 10\n",
            "Shape of outputs: torch.Size([1, 10, 7])\n",
            "Shape of predictions: torch.Size([1, 10])\n",
            "predictions = tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data: dict[str, str] = {\n",
        "    col: tags.names[p] for col, p in zip(xlmr_tokens, predictions.flatten())\n",
        "}\n",
        "print(data)\n",
        "\n",
        "pl.DataFrame(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "elavqWPVLxFg",
        "outputId": "23b1547d-3420-4a5c-cd27-8b3900dd469f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<s>': 'O', '▁Jack': 'O', '▁Spar': 'O', 'row': 'O', '▁love': 'O', 's': 'O', '▁New': 'O', '▁York': 'O', '!': 'O', '</s>': 'O'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (1, 10)\n",
              "┌─────┬───────┬───────┬─────┬───────┬─────┬──────┬───────┬─────┬──────┐\n",
              "│ <s> ┆ ▁Jack ┆ ▁Spar ┆ row ┆ ▁love ┆ s   ┆ ▁New ┆ ▁York ┆ !   ┆ </s> │\n",
              "│ --- ┆ ---   ┆ ---   ┆ --- ┆ ---   ┆ --- ┆ ---  ┆ ---   ┆ --- ┆ ---  │\n",
              "│ str ┆ str   ┆ str   ┆ str ┆ str   ┆ str ┆ str  ┆ str   ┆ str ┆ str  │\n",
              "╞═════╪═══════╪═══════╪═════╪═══════╪═════╪══════╪═══════╪═════╪══════╡\n",
              "│ O   ┆ O     ┆ O     ┆ O   ┆ O     ┆ O   ┆ O    ┆ O     ┆ O   ┆ O    │\n",
              "└─────┴───────┴───────┴─────┴───────┴─────┴──────┴───────┴─────┴──────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>&lt;s&gt;</th><th>▁Jack</th><th>▁Spar</th><th>row</th><th>▁love</th><th>s</th><th>▁New</th><th>▁York</th><th>!</th><th>&lt;/s&gt;</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td><td>&quot;O&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_text(\n",
        "    text: str,\n",
        "    tags: list[str],\n",
        "    model: RobertaModel,\n",
        "    tokenizer: AutoTokenizer,\n",
        ") -> pl.DataFrame:\n",
        "    # Get tokens with special characters\n",
        "    tokens: list[str] = tokenizer(text).tokens()\n",
        "\n",
        "    # Encode\n",
        "    input_ids: Tensor = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    outputs: Tensor = model(input_ids).logits\n",
        "\n",
        "    # Get predictions\n",
        "    predictions: Tensor = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "    data: dict[str, str] = {\n",
        "        col: tags.names[p]\n",
        "        for col, p in zip(tokens, predictions.flatten().cpu().numpy())\n",
        "    }\n",
        "\n",
        "    return pl.DataFrame(data)"
      ],
      "metadata": {
        "id": "v0XuFFQ_LlD5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "### Tokenizing Texts For NER\n",
        "\n",
        "- To prepare the dataset for fine-tuning with XLM-R, we need to tokenize it. - Datasets provides a `map()` function for this.\n",
        "\n",
        "- We need to define a function with the signature:\n",
        "```py\n",
        "function(examples: Dict[str, List]) -> Dict[str, List] to process the dataset.\n",
        "```\n",
        "\n",
        "- The XLM-R tokenizer's output returns input IDs for the model.\n",
        "- To use the model, we need to add an attention mask and label IDs that indicate which tokens correspond to each NER tag.\n",
        "- These can be obtained from the dataset's examples."
      ],
      "metadata": {
        "id": "WmcGC5TwW8i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "id": "eFc5NgQ5avsW",
        "outputId": "a6023638-bca2-4de0-b3ff-7681f141ccce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['Collin', 'Peterson', '(', 'D-MN', ')'],\n",
              " 'ner_tags': [1, 2, 0, 0, 0],\n",
              " 'langs': ['en', 'en', 'en', 'en', 'en']}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words, labels = sample[\"tokens\"], sample[\"ner_tags\"]\n",
        "\n",
        "# Tokenize each word and specify that the input sequence has already been split into words.\n",
        "tokenized_input = xlmr_tokenizer(\n",
        "    words, is_split_into_words=True\n",
        ")\n",
        "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "pl.DataFrame(tokens).transpose()"
      ],
      "metadata": {
        "id": "2-e8M14gbkCb",
        "outputId": "b495b437-2473-4eea-f9a9-b8edcc7fac31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (1, 11)\n",
              "┌────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┐\n",
              "│ column ┆ column ┆ column ┆ column ┆ column ┆ column ┆ column ┆ column ┆ column ┆ column ┆ column │\n",
              "│ _0     ┆ _1     ┆ _2     ┆ _3     ┆ _4     ┆ _5     ┆ _6     ┆ _7     ┆ _8     ┆ _9     ┆ _10    │\n",
              "│ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    │\n",
              "│ str    ┆ str    ┆ str    ┆ str    ┆ str    ┆ str    ┆ str    ┆ str    ┆ str    ┆ str    ┆ str    │\n",
              "╞════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╡\n",
              "│ <s>    ┆ ▁Colli ┆ n      ┆ ▁Peter ┆ son    ┆ ▁(     ┆ ▁D     ┆ -      ┆ MN     ┆ ▁)     ┆ </s>   │\n",
              "└────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;&lt;s&gt;&quot;</td><td>&quot;▁Colli&quot;</td><td>&quot;n&quot;</td><td>&quot;▁Peter&quot;</td><td>&quot;son&quot;</td><td>&quot;▁(&quot;</td><td>&quot;▁D&quot;</td><td>&quot;-&quot;</td><td>&quot;MN&quot;</td><td>&quot;▁)&quot;</td><td>&quot;&lt;/s&gt;&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment\n",
        "\n",
        "- The word `Collin` was split into `Colli` and `n` by the `SentencePience` tokenizer.\n",
        "- Since we want to follow the convection that only `Colli` should be associated with the `B-PER` label,  we need a way to mask the subword representations after the subword.\n",
        "- This can be done using `.word_ids()` method.\n",
        "- `word_ids` has mapped each subword to the corresponding index in the words sequence, so the first subword, “__Colli\", is assigned the index 0, while\n",
        "“▁Peter” and “son” are assigned the index 1 (since “Peterson” is the second\n",
        "word in words).\n",
        "- We can also see that special tokens like `<s>` and `<\\s>` are mapped to\n",
        "None.\n",
        "- Let's set `-100` as the label for these special tokens and the subwords we wish to mask during training."
      ],
      "metadata": {
        "id": "3NFMAdGNW8gW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_ids = tokenized_input.word_ids()\n",
        "data: dict[str, int] = {\n",
        "    col: idx_ for col, idx_ in zip(tokens, word_ids)\n",
        "}\n",
        "\n",
        "pl.DataFrame(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "8CsjBx_MW8d9",
        "outputId": "ed2feaac-64ae-4136-97c3-7e147fc45af3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (1, 11)\n",
              "┌──────┬────────┬─────┬────────┬─────┬─────┬─────┬─────┬─────┬─────┬──────┐\n",
              "│ <s>  ┆ ▁Colli ┆ n   ┆ ▁Peter ┆ son ┆ ▁(  ┆ ▁D  ┆ -   ┆ MN  ┆ ▁)  ┆ </s> │\n",
              "│ ---  ┆ ---    ┆ --- ┆ ---    ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ ---  │\n",
              "│ null ┆ i64    ┆ i64 ┆ i64    ┆ i64 ┆ i64 ┆ i64 ┆ i64 ┆ i64 ┆ i64 ┆ null │\n",
              "╞══════╪════════╪═════╪════════╪═════╪═════╪═════╪═════╪═════╪═════╪══════╡\n",
              "│ null ┆ 0      ┆ 0   ┆ 1      ┆ 1   ┆ 2   ┆ 3   ┆ 3   ┆ 3   ┆ 4   ┆ null │\n",
              "└──────┴────────┴─────┴────────┴─────┴─────┴─────┴─────┴─────┴─────┴──────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>&lt;s&gt;</th><th>▁Colli</th><th>n</th><th>▁Peter</th><th>son</th><th>▁(</th><th>▁D</th><th>-</th><th>MN</th><th>▁)</th><th>&lt;/s&gt;</th></tr><tr><td>null</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>null</td></tr></thead><tbody><tr><td>null</td><td>0</td><td>0</td><td>1</td><td>1</td><td>2</td><td>3</td><td>3</td><td>3</td><td>4</td><td>null</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_ids, labels"
      ],
      "metadata": {
        "id": "tIpF90VbiJko",
        "outputId": "0acd072e-b2d6-40ea-d6fb-f9ba0a93e52a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([None, 0, 0, 1, 1, 2, 3, 3, 3, 4, None], [1, 2, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prev_word_idx: int | None = None\n",
        "label_ids: list[int] = []\n",
        "\n",
        "for word_idx in word_ids:\n",
        "  if word_idx is None or word_idx == prev_word_idx:\n",
        "    label_ids.append(-100)\n",
        "  else:\n",
        "    label_ids.append(labels[word_idx])\n",
        "  prev_word_idx = word_idx\n",
        "\n",
        "\n",
        "# Update the labels\n",
        "labels = [index2tag[l] if l != -100 else \"UKN\" for l in label_ids]\n",
        "index = [\"Tokens\", \"Word IDs\", \"label IDs\", \"Labels\"]\n",
        "\n",
        "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
      ],
      "metadata": {
        "id": "TBM389rusL1q",
        "outputId": "86e7518f-807c-4c84-b4b8-8f3973af96e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0       1     2       3     4   5   6     7     8   9     10\n",
              "Tokens      <s>  ▁Colli     n  ▁Peter   son  ▁(  ▁D     -    MN  ▁)  </s>\n",
              "Word IDs   None       0     0       1     1   2   3     3     3   4  None\n",
              "label IDs  -100       1  -100       2  -100   0   0  -100  -100   0  -100\n",
              "Labels      UKN   B-PER   UKN   I-PER   UKN   O   O   UKN   UKN   O   UKN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2d05745-c42b-4ca6-846d-33d7212af405\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁Colli</td>\n",
              "      <td>n</td>\n",
              "      <td>▁Peter</td>\n",
              "      <td>son</td>\n",
              "      <td>▁(</td>\n",
              "      <td>▁D</td>\n",
              "      <td>-</td>\n",
              "      <td>MN</td>\n",
              "      <td>▁)</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word IDs</th>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label IDs</th>\n",
              "      <td>-100</td>\n",
              "      <td>1</td>\n",
              "      <td>-100</td>\n",
              "      <td>2</td>\n",
              "      <td>-100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-100</td>\n",
              "      <td>-100</td>\n",
              "      <td>0</td>\n",
              "      <td>-100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Labels</th>\n",
              "      <td>UKN</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>UKN</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>UKN</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>UKN</td>\n",
              "      <td>UKN</td>\n",
              "      <td>O</td>\n",
              "      <td>UKN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2d05745-c42b-4ca6-846d-33d7212af405')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2d05745-c42b-4ca6-846d-33d7212af405 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2d05745-c42b-4ca6-846d-33d7212af405');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b3fa928-d8e2-4799-bc50-1c37a006f6ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b3fa928-d8e2-4799-bc50-1c37a006f6ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b3fa928-d8e2-4799-bc50-1c37a006f6ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"<s>\",\n          -100,\n          \"UKN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          \"B-PER\",\n          \"\\u2581Colli\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          \"UKN\",\n          \"n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          \"I-PER\",\n          \"\\u2581Peter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          \"UKN\",\n          \"son\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          \"O\",\n          \"\\u2581(\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          \"O\",\n          \"\\u2581D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          \"UKN\",\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          \"UKN\",\n          \"MN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          \"O\",\n          \"\\u2581)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"</s>\",\n          -100,\n          \"UKN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment\n",
        "\n",
        "- The ID `-100` is used to mask subword representations in PyTorch's cross-entropy loss to ignore them during training, preventing their influence on the model's learning."
      ],
      "metadata": {
        "id": "ulZpdiY6W8Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting it together\n",
        "\n",
        "def tokenize_and_align_labels(examples: dict[str, list]) -> dict[str, list]:\n",
        "    \"\"\"\n",
        "    Tokenize and align labels for named entity recognition.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    examples : dict[str, list]\n",
        "        A dictionary containing 'tokens' and 'ner_tags' as keys.\n",
        "        'tokens' : list of str\n",
        "            List of words in the input sequence.\n",
        "        'ner_tags' : list of int\n",
        "            List of corresponding NER tags for each word.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict[str, list]\n",
        "        A dictionary containing tokenized inputs and aligned labels.\n",
        "        'input_ids' : list of int\n",
        "            Tokenized input sequence.\n",
        "        'attention_mask' : list of int\n",
        "            Attention mask for the tokenized sequence.\n",
        "        'labels' : list of int\n",
        "            Aligned labels for the tokenized sequence.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    This function assumes the existence of a tokenizer named 'xlmr_tokenizer'.\n",
        "    \"\"\"\n",
        "    labels: list[list[int]] = []\n",
        "\n",
        "    # Tokenize each word and specify that the input sequence has\n",
        "    # already been split into words.\n",
        "    tokenized_inputs: dict[str, list] = xlmr_tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "\n",
        "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids: list[int | None] = tokenized_inputs.word_ids(batch_index=idx)\n",
        "        prev_word_idx: int | None = None\n",
        "        label_ids: list[int] = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None or word_idx == prev_word_idx:\n",
        "                label_ids.append(-100)\n",
        "            else:\n",
        "                label_ids.append(label[word_idx])\n",
        "            prev_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    # Add the labels to the inputs\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "def encode_panx_dataset(corpus: Dataset) -> Dataset:\n",
        "    \"\"\"\n",
        "    Encode the PAN-X dataset by applying tokenization and label alignment.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corpus : Dataset\n",
        "        The input corpus to be encoded.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dataset\n",
        "        The encoded dataset with tokenized inputs and aligned labels.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    This function uses the `tokenize_and_align_labels` function to process\n",
        "    the dataset. It removes the original 'tokens', 'ner_tags', and 'langs'\n",
        "    columns from the dataset.\n",
        "    \"\"\"\n",
        "    return corpus.map(\n",
        "        tokenize_and_align_labels,\n",
        "        batched=True,\n",
        "        remove_columns=[\"tokens\", \"ner_tags\", \"langs\"],\n",
        "        desc=\"Running tokenizer on dataset\",\n",
        "    )"
      ],
      "metadata": {
        "id": "XgZYInQYW8WZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply it to the entire dataset\n",
        "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ecb5d09c94e64cc89d8c064d39f56cc1",
            "4f8fb61c411f4556b84afebc23368021",
            "84ae520f7de34158b1dfdfbff81d5137",
            "9747765693904613bffb2c1be3aafc40",
            "aedea8e6e9c74d259442a44477d53283",
            "81d2cb3b92794abea86cfde9be91dd45",
            "8de14b88314f48b78bbfd035c07ffa38",
            "dee70b46f9b34ab097d08f2700eab0c7",
            "d103e0dc6ce4490a84e8cdd85307128a",
            "d5e1c6166fa74939b910ee7a9b7c3a98",
            "88cc486f538143f4ba0d4fb8987b25e4"
          ]
        },
        "id": "Mbkun-heW8Sv",
        "outputId": "e541f432-f542-4484-abe3-e5c76ab2e634"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/6290 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecb5d09c94e64cc89d8c064d39f56cc1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "### Performance Metrics\n",
        "\n",
        "- Evaluating NER models involves precision, recall, and F1-score.\n",
        "- All words of an entity must be predicted correctly.\n",
        "- The `seqeval` library can compute these metrics using the `classification_report()` function."
      ],
      "metadata": {
        "id": "rCbGTS6JT0KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "\n",
        "# Example usage\n",
        "y_true: list[list[str]] = [\n",
        "    [\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
        "    [\"B-PER\", \"I-PER\", \"O\"],\n",
        "]\n",
        "y_pred: list[list[str]] = [\n",
        "    [\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
        "    [\"B-PER\", \"I-PER\", \"O\"],\n",
        "]\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "6DSe2sNg0K75"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YFdwdqdR0K4n"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LsulsWd00K0L"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJjL_qIF0Kx1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-Yoi7wx0Kvf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxeYP2t-0Kr2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RdEbeB3_x_8w"
      },
      "execution_count": 38,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ecb5d09c94e64cc89d8c064d39f56cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f8fb61c411f4556b84afebc23368021",
              "IPY_MODEL_84ae520f7de34158b1dfdfbff81d5137",
              "IPY_MODEL_9747765693904613bffb2c1be3aafc40"
            ],
            "layout": "IPY_MODEL_aedea8e6e9c74d259442a44477d53283"
          }
        },
        "4f8fb61c411f4556b84afebc23368021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d2cb3b92794abea86cfde9be91dd45",
            "placeholder": "​",
            "style": "IPY_MODEL_8de14b88314f48b78bbfd035c07ffa38",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "84ae520f7de34158b1dfdfbff81d5137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dee70b46f9b34ab097d08f2700eab0c7",
            "max": 6290,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d103e0dc6ce4490a84e8cdd85307128a",
            "value": 6290
          }
        },
        "9747765693904613bffb2c1be3aafc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5e1c6166fa74939b910ee7a9b7c3a98",
            "placeholder": "​",
            "style": "IPY_MODEL_88cc486f538143f4ba0d4fb8987b25e4",
            "value": " 6290/6290 [00:01&lt;00:00, 3587.23 examples/s]"
          }
        },
        "aedea8e6e9c74d259442a44477d53283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81d2cb3b92794abea86cfde9be91dd45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8de14b88314f48b78bbfd035c07ffa38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dee70b46f9b34ab097d08f2700eab0c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d103e0dc6ce4490a84e8cdd85307128a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5e1c6166fa74939b910ee7a9b7c3a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88cc486f538143f4ba0d4fb8987b25e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}