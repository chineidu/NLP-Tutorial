{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Masked Language Modelling (MLM)](https://huggingface.co/learn/nlp-course/chapter7/3?fw=pt)\n",
    "\n",
    "- For NLP tasks with Transformer models, you can use pretrained models from Hugging Face and fine-tune them on your data. \n",
    "- Transfer learning works well if the pretraining and fine-tuning corpora are similar. \n",
    "- However, in cases like `legal` or `scientific text`, domain-specific words may be treated as `rare` tokens. \n",
    "- Fine-tuning the language model on in-domain data can improve downstream task performance. \n",
    "- This process is called d`omain adaptation`, popularized by ULMFiT in 2018. \n",
    "- We'll perform a similar process with `Transformers` instead of LSTMs.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Benefits of MLM \n",
    "\n",
    "- **Improved Generalization**: By exposing the model to various masking patterns, MLM enhances its ability to generalize to unseen data and perform well on downstream tasks.\n",
    "\n",
    "- **Effective Pre-training for Diverse Tasks**: MLM has shown to be effective in pre-training language models for a wide range of NLP tasks, including text generation, machine translation, and question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rich import print\n",
    "import torch\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9476a3153d3c49a983f286246dfcc9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e688dff2aaf34592b75e765dd4a492bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "\n",
    "model_checkpoint: str = \"distilbert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; DistilBERT number of parameters: 67M'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> DistilBERT number of parameters: 67M'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; BERT number of parameters: 110M'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> BERT number of parameters: 110M'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distilbert_num_parameters: float = model.num_parameters() / 1_000_000\n",
    "print(f\"'>>> DistilBERT number of parameters: {round(distilbert_num_parameters)}M'\")\n",
    "print(f\"'>>> BERT number of parameters: 110M'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s see what kinds of tokens this model predicts:\n",
    "text: str = \"This is a great [MASK].\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- As humans, we can imagine many possibilities for the [MASK] token, such as “day”, “ride”, or “painting”. \n",
    "- For pretrained models, the predictions depend on the corpus the model was trained on, since it learns to pick up the statistical patterns present in the data. \n",
    "- Like BERT, DistilBERT was pretrained on the [English Wikipedia](https://huggingface.co/datasets/wikipedia) and [BookCorpus datasets](https://huggingface.co/datasets/bookcorpus), so we expect the predictions for [MASK] to reflect these domains. \n",
    "- To predict the mask we need DistilBERT’s tokenizer to produce the inputs for the model, so let’s download that from the Hub as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db39dff2b5e74905bf546b33adb9106f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9741f506bd54fd7baf2b91209ba16da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d1e5681b7a4d4b8054dd00f8ff866b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ -5.5882,  -5.5868,  -5.5958,  ...,  -4.9448,  -4.8174,  -2.9905],\n",
       "         [-11.9031, -11.8872, -12.0623,  ..., -10.9570, -10.6464,  -8.6324],\n",
       "         [-11.9604, -12.1520, -12.1279,  ..., -10.0218,  -8.6074,  -8.0971],\n",
       "         ...,\n",
       "         [ -4.8228,  -4.6268,  -5.1041,  ...,  -4.2771,  -5.0184,  -3.9428],\n",
       "         [-11.2945, -11.2388, -11.3857,  ...,  -9.2063,  -9.3411,  -6.1505],\n",
       "         [ -9.5213,  -9.4632,  -9.5022,  ...,  -8.6561,  -8.4908,  -4.6903]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "inputs: dict[str, Any] = tokenizer(text, return_tensors=\"pt\")\n",
    "token_logits: torch.Tensor = model(**inputs).logits\n",
    "token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">input_ids: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2003</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1037</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2307</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">103</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1012</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "input_ids: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m101\u001b[0m, \u001b[1;36m2023\u001b[0m, \u001b[1;36m2003\u001b[0m, \u001b[1;36m1037\u001b[0m, \u001b[1;36m2307\u001b[0m,  \u001b[1;36m103\u001b[0m, \u001b[1;36m1012\u001b[0m,  \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">mask_token_id: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">103</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "mask_token_id: \u001b[1;36m103\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'input_ids: {inputs[\"input_ids\"]}')\n",
    "print(f\"mask_token_id: {tokenizer.mask_token_id}\")\n",
    "\n",
    "print(inputs[\"input_ids\"].flatten() == tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'this'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'is'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'great'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'[MASK]'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2003</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1037</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2307</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">103</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1012</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'this'\u001b[0m, \u001b[32m'is'\u001b[0m, \u001b[32m'a'\u001b[0m, \u001b[32m'great'\u001b[0m, \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mMASK\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'.'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m2023\u001b[0m, \u001b[1;36m2003\u001b[0m, \u001b[1;36m1037\u001b[0m, \u001b[1;36m2307\u001b[0m, \u001b[1;36m103\u001b[0m, \u001b[1;36m1012\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_tokens: list[str] = tokenizer.tokenize(text)\n",
    "token_ids: list[int] = tokenizer(text).get(\"input_ids\")\n",
    "\n",
    "print(raw_tokens, token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30522</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m30522\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ -5.5882,  -5.5868,  -5.5958,  ...,  -4.9448,  -4.8174,  -2.9905],\n",
       "         [-11.9031, -11.8872, -12.0623,  ..., -10.9570, -10.6464,  -8.6324],\n",
       "         [-11.9604, -12.1520, -12.1279,  ..., -10.0218,  -8.6074,  -8.0971],\n",
       "         ...,\n",
       "         [ -4.8228,  -4.6268,  -5.1041,  ...,  -4.2771,  -5.0184,  -3.9428],\n",
       "         [-11.2945, -11.2388, -11.3857,  ...,  -9.2063,  -9.3411,  -6.1505],\n",
       "         [ -9.5213,  -9.4632,  -9.5022,  ...,  -8.6561,  -8.4908,  -4.6903]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(token_logits.shape)\n",
    "\n",
    "token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.8228, -4.6268, -5.1041,  ..., -4.2771, -5.0184, -3.9428],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits[0, 5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">mask_token_index: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "mask_token_index: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8228, -4.6268, -5.1041,  ..., -4.2771, -5.0184, -3.9428]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the location of [MASK] and extract its logits\n",
    "mask_token_index: torch.Tensor = torch.where(\n",
    "    inputs[\"input_ids\"].flatten() == tokenizer.mask_token_id\n",
    ")[0]\n",
    "mask_token_logits: torch.Tensor = token_logits[0, mask_token_index, :]\n",
    "\n",
    "print(f\"mask_token_index: {mask_token_index}\")\n",
    "\n",
    "mask_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; This is a great deal.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> This is a great deal.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; This is a great success.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> This is a great success.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; This is a great adventure.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> This is a great adventure.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; This is a great idea.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> This is a great idea.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; This is a great feat.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> This is a great feat.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick the [MASK] candidates with the highest logits\n",
    "k: int = 5\n",
    "top_5_tokens = torch.topk(mask_token_logits, k, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The dataset\n",
    "\n",
    "- To showcase domain adaptation, we’ll use the famous [Large Movie Review Dataset (or IMDb for short)](https://huggingface.co/datasets/imdb), which is a corpus of movie reviews that is often used to benchmark sentiment analysis models. \n",
    "- By fine-tuning DistilBERT on this corpus, we expect the language model will adapt its vocabulary from the factual data of Wikipedia that it was pretrained on to the more subjective elements of movie reviews. \n",
    "- We can get the data from the Hugging Face Hub with the load_dataset() function from 🤗 Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d942b3019df406e9b8aef6b0d48bc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511ea99c1a50412393c6ea12ce2f8be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2ac02be0804381baf25115480eb1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fcafbc409548969f4ab084fb5d8646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627552f9cd334049bbcfb851d7e90b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63674c7f46f94a23b2af6e4d2dc67e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb1799abe9c44afa309f7055d7dacab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "\n",
    "data_path: str = \"imdb\"\n",
    "imdb_dataset: Dataset = load_dataset(data_path)\n",
    "\n",
    "imdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Review: There is no relation at all between Fortier and Profiler but the fact that both are police series about\n",
       "violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are \n",
       "far more complicated<span style=\"color: #808000; text-decoration-color: #808000\">...</span> Fortier looks more like Prime Suspect, if we have to spot similarities<span style=\"color: #808000; text-decoration-color: #808000\">...</span> The main \n",
       "character is weak and weirdo, but have <span style=\"color: #008000; text-decoration-color: #008000\">\"clairvoyance\"</span>. People like to compare, to judge, to evaluate. How about \n",
       "just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer \n",
       "American series <span style=\"font-weight: bold\">(</span>!!!<span style=\"font-weight: bold\">)</span>. Maybe it's the language, or the spirit, but I think this series is more English than \n",
       "American. By the way, the actors are really good and funny. The acting is not superficial at all<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Review: There is no relation at all between Fortier and Profiler but the fact that both are police series about\n",
       "violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are \n",
       "far more complicated\u001b[33m...\u001b[0m Fortier looks more like Prime Suspect, if we have to spot similarities\u001b[33m...\u001b[0m The main \n",
       "character is weak and weirdo, but have \u001b[32m\"clairvoyance\"\u001b[0m. People like to compare, to judge, to evaluate. How about \n",
       "just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer \n",
       "American series \u001b[1m(\u001b[0m!!!\u001b[1m)\u001b[0m. Maybe it's the language, or the spirit, but I think this series is more English than \n",
       "American. By the way, the actors are really good and funny. The acting is not superficial at all\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Label: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Label: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Review: This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The \n",
       "movie starts of with a scene where Hank sings a song with a bunch of kids called <span style=\"color: #008000; text-decoration-color: #008000\">\"when you stub your toe on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">moon\"</span> It reminds me of Sinatra's song High Hopes, it is fun and inspirational. The Music is great throughout and my\n",
       "favorite song is sung by the King, Hank <span style=\"font-weight: bold\">(</span>bing Crosby<span style=\"font-weight: bold\">)</span> and Sir <span style=\"color: #008000; text-decoration-color: #008000\">\"Saggy\"</span> Sagamore. OVerall a great family movie or \n",
       "even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming \n",
       "is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this \n",
       "movie.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Review: This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The \n",
       "movie starts of with a scene where Hank sings a song with a bunch of kids called \u001b[32m\"when you stub your toe on the \u001b[0m\n",
       "\u001b[32mmoon\"\u001b[0m It reminds me of Sinatra's song High Hopes, it is fun and inspirational. The Music is great throughout and my\n",
       "favorite song is sung by the King, Hank \u001b[1m(\u001b[0mbing Crosby\u001b[1m)\u001b[0m and Sir \u001b[32m\"Saggy\"\u001b[0m Sagamore. OVerall a great family movie or \n",
       "even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming \n",
       "is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this \n",
       "movie.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Label: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Label: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Review: George P. Cosmatos' <span style=\"color: #008000; text-decoration-color: #008000\">\"Rambo: First Blood Part II\"</span> is pure wish-fulfillment. The United States clearly \n",
       "didn't win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues \n",
       "the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war\n",
       "happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans \n",
       "didn't appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading \n",
       "officers and politicians. Like every film that defends the war <span style=\"font-weight: bold\">(</span>e.g. <span style=\"color: #008000; text-decoration-color: #008000\">\"We Were Soldiers\"</span><span style=\"font-weight: bold\">)</span> also this one avoids the \n",
       "need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for \n",
       "every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole \n",
       "nation. It would have been better to work on how to deal with the memories, rather than suppressing them. <span style=\"color: #008000; text-decoration-color: #008000\">\"Do we </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">get to win this time?\"</span> Yes, you do.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Review: George P. Cosmatos' \u001b[32m\"Rambo: First Blood Part II\"\u001b[0m is pure wish-fulfillment. The United States clearly \n",
       "didn't win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues \n",
       "the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war\n",
       "happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans \n",
       "didn't appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading \n",
       "officers and politicians. Like every film that defends the war \u001b[1m(\u001b[0me.g. \u001b[32m\"We Were Soldiers\"\u001b[0m\u001b[1m)\u001b[0m also this one avoids the \n",
       "need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for \n",
       "every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole \n",
       "nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \u001b[32m\"Do we \u001b[0m\n",
       "\u001b[32mget to win this time?\"\u001b[0m Yes, you do.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Label: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Label: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview a small sample\n",
    "RANDOM_STATE: int = 42\n",
    "sample = imdb_dataset.get(\"train\").shuffle(seed=RANDOM_STATE).select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\">>> Review: {row.get('text')}\")\n",
    "    print(f\">>> Label: {row.get('label')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique labels\n",
    "imdb_dataset.get(\"train\").unique(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Review: If you've seen the classic Roger Corman version starring Vincent Price it's hard to put it out of your \n",
       "head, but you probably should do because this one is totally different. Subtlety has been abandoned in favour of \n",
       "gross-out horror - nudity, gore and all-round unpleasantness. OK it's ridiculous, trashy, sensationalised and \n",
       "historically dubious <span style=\"font-weight: bold\">(</span>did any members of the Inquisition really wear horn-rimmed glasses?<span style=\"font-weight: bold\">)</span>, but despite all this it\n",
       "is strangely compelling. I literally couldn't tear myself away from the screen until the end of the movie. If \n",
       "there's a bigger compliment you can pay to a film I don't know what it is.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Review: If you've seen the classic Roger Corman version starring Vincent Price it's hard to put it out of your \n",
       "head, but you probably should do because this one is totally different. Subtlety has been abandoned in favour of \n",
       "gross-out horror - nudity, gore and all-round unpleasantness. OK it's ridiculous, trashy, sensationalised and \n",
       "historically dubious \u001b[1m(\u001b[0mdid any members of the Inquisition really wear horn-rimmed glasses?\u001b[1m)\u001b[0m, but despite all this it\n",
       "is strangely compelling. I literally couldn't tear myself away from the screen until the end of the movie. If \n",
       "there's a bigger compliment you can pay to a film I don't know what it is.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Label: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Label: \u001b[1;36m-1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Review: For me, this was the most moving film of the decade. Samira Makhmalbaf shows pure bravery and vision in\n",
       "the making. She has an intelligence and gift for speaking to the people, regardless of their nationality or \n",
       "beliefs. I am inspired and touched by her humanity and can only hope that she has touched many people the same way.\n",
       "Her message in this film is strong, simple and pure. The human soul can survive the most unheard of cruelties and \n",
       "repression, yet still have the capability to hope and dream even the biggest dreams. Under the most incredible \n",
       "circumstances, the most unexpected people rise up to be heroes. This young girl who has recently regained her \n",
       "voice, yet is still afraid to use her new found freedom, is our hero. She daydreams of becoming president of war \n",
       "torn Afghanistan, the only vision of power that she can imagine that could truly change her current situation. We \n",
       "catch a glimpse of her spirit while witnessing her hardships. In the end, we are left with hope, hope that when her\n",
       "young voice does eventually speak out, it speaks loud and clear for all to hear- sounding a message that transcends\n",
       "borders, nationality and religion. The true epitome of the phoenix rising from the ashes. Hats off to the simple \n",
       "tale of the complex truth.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Review: For me, this was the most moving film of the decade. Samira Makhmalbaf shows pure bravery and vision in\n",
       "the making. She has an intelligence and gift for speaking to the people, regardless of their nationality or \n",
       "beliefs. I am inspired and touched by her humanity and can only hope that she has touched many people the same way.\n",
       "Her message in this film is strong, simple and pure. The human soul can survive the most unheard of cruelties and \n",
       "repression, yet still have the capability to hope and dream even the biggest dreams. Under the most incredible \n",
       "circumstances, the most unexpected people rise up to be heroes. This young girl who has recently regained her \n",
       "voice, yet is still afraid to use her new found freedom, is our hero. She daydreams of becoming president of war \n",
       "torn Afghanistan, the only vision of power that she can imagine that could truly change her current situation. We \n",
       "catch a glimpse of her spirit while witnessing her hardships. In the end, we are left with hope, hope that when her\n",
       "young voice does eventually speak out, it speaks loud and clear for all to hear- sounding a message that transcends\n",
       "borders, nationality and religion. The true epitome of the phoenix rising from the ashes. Hats off to the simple \n",
       "tale of the complex truth.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Label: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Label: \u001b[1;36m-1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Review: There really isn't much to say about this <span style=\"color: #008000; text-decoration-color: #008000\">\"film\"</span>. It has the odd smile or chuckle moment, but on the \n",
       "whole it's bland, predictable and generally pretty dull.<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">br</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;&lt;br </span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;The only reason I gave it three out of ten was </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">for the annoyingly catchy jingle </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">which I hope I will forget soon</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"color: #000000; text-decoration-color: #000000\">.please God!</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">. Otherwise its junk. Or mostly </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">junk, interspersed with adverts for Smirnoff Ice.&lt;br </span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;&lt;br </span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;The lead characters give OK performances, but they </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">really don't have anything much to work with.&lt;br </span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;&lt;br </span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"font-weight: bold\">&gt;</span>Best advice: Avoid it like a dentist's appointment. Or \n",
       "better yet, make a dentist's appointment instead of watching it.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Review: There really isn't much to say about this \u001b[32m\"film\"\u001b[0m. It has the odd smile or chuckle moment, but on the \n",
       "whole it's bland, predictable and generally pretty dull.\u001b[1m<\u001b[0m\u001b[1;95mbr\u001b[0m\u001b[39m \u001b[0m\u001b[35m/\u001b[0m\u001b[39m><br \u001b[0m\u001b[35m/\u001b[0m\u001b[39m>The only reason I gave it three out of ten was \u001b[0m\n",
       "\u001b[39mfor the annoyingly catchy jingle \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mwhich I hope I will forget soon\u001b[0m\u001b[33m...\u001b[0m\u001b[39m.please God!\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m. Otherwise its junk. Or mostly \u001b[0m\n",
       "\u001b[39mjunk, interspersed with adverts for Smirnoff Ice.<br \u001b[0m\u001b[35m/\u001b[0m\u001b[39m><br \u001b[0m\u001b[35m/\u001b[0m\u001b[39m>The lead characters give OK performances, but they \u001b[0m\n",
       "\u001b[39mreally don't have anything much to work with.<br \u001b[0m\u001b[35m/\u001b[0m\u001b[39m><br \u001b[0m\u001b[35m/\u001b[0m\u001b[1m>\u001b[0mBest advice: Avoid it like a dentist's appointment. Or \n",
       "better yet, make a dentist's appointment instead of watching it.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; Label: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> Label: \u001b[1;36m-1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview a small sample of the unsupervised/unlabelled data\n",
    "sample = imdb_dataset.get(\"unsupervised\").shuffle(seed=RANDOM_STATE).select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\">>> Review: {row.get('text')}\")\n",
    "    print(f\">>> Label: {row.get('label')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique labels\n",
    "imdb_dataset.get(\"unsupervised\").unique(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- For both `auto-regressive` and `masked language modeling`, a common preprocessing step is to `concatenate` all the examples and then split the whole corpus into chunks of equal size. \n",
    "- This is quite different from our usual approach, where we simply tokenize individual examples. Why concatenate everything together? \n",
    "- The reason is that individual examples might get truncated if they’re too long, and that would result in losing information that might be useful for the language modeling task!\n",
    "\n",
    "- To get started, we’ll first tokenize our corpus as usual, but without setting the `truncation=True` option in our tokenizer. \n",
    "- We’ll also grab the word IDs if they are available (which they will be if we’re using a fast tokenizer, as described in Chapter 6), as we will need them later on to do whole word masking. \n",
    "- We’ll wrap this in a simple function, and while we’re at it we’ll remove the `text` and `label` columns since we don’t need them any longer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples: dict[str, Any]) -> dict[str, Any]:\n",
    "    result: dict[str, Any] = tokenizer(examples.get(\"text\"))\n",
    "\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [\n",
    "            result.word_ids(idx) for idx in range(len(result[\"input_ids\"]))\n",
    "        ]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbb5a6cfe72437dafc0c83e3b3ef43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642add4b6f35499c980695c2d0ca6f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446a21d4b22245b7bf928dad97f0c5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = imdb_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\", \"label\"]\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input_ids Vs. Word_ids\n",
    "\n",
    "[![image.png](https://i.postimg.cc/MptyPP3S/image.png)](https://postimg.cc/MnMMXD8P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- Now that we’ve tokenized our movie reviews, the next step is to group them all together and split the result into chunks. \n",
    "- But how big should these chunks be? This will ultimately be determined by the amount of GPU memory that you have available, but a good starting point is to see what the model’s maximum context size is. \n",
    "- This can be inferred by inspecting the model_max_length attribute of the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model's context size\n",
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Review 0 length: 363'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Review 0 length: 363'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Review 1 length: 304'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Review 1 length: 304'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Review 2 length: 133'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Review 2 length: 133'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To run our experiments on GPUs like those found on Google Colab, choose a smaller size that can fit in memory:\n",
    "chunk_size: int = 128\n",
    "\n",
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'word_ids'])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 4, 5]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate lists\n",
    "sum([[10, 4, 5]], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Concatenated reviews length: 800'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Concatenated reviews length: 800'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenate all these examples with a simple dictionary comprehension:\n",
    "concatenated_examples: dict[str, Any] = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length: int = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'word_ids'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_examples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Chunk length: 128'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Chunk length: 128'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Chunk length: 128'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Chunk length: 128'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Chunk length: 128'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Chunk length: 128'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Chunk length: 128'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Chunk length: 128'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Chunk length: 128'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Chunk length: 128'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Chunk length: 128'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Chunk length: 128'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'&gt;&gt;&gt; Chunk length: 32'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'>>> Chunk length: 32'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chunk the data\n",
    "chunks: dict[str, Any] = {\n",
    "    key: [tokens[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for key, tokens in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- As you can see the last chunk will generally be smaller than the maximum chunk size. \n",
    "- There are two main strategies for dealing with this:\n",
    "  - Drop the last chunk if it’s smaller than chunk_size.\n",
    "  - Pad the last chunk until its length equals chunk_size.\n",
    "- We’ll take the first approach here, so let’s wrap all of the above logic in a single function that we can apply to our tokenized datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the data\n",
    "chunks: dict[str, Any] = {\n",
    "    key: [tokens[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for key, tokens in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples: dict[str, Any]) -> dict[str, Any]:\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {key: sum(examples[key], []) for key in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    # Select the 1st item in the list and calculate the length\n",
    "    total_length: int = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length: int = (total_length // chunk_size) * chunk_size\n",
    "    # Chunk the data\n",
    "    chunks: dict[str, Any] = {\n",
    "        key: [tokens[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for key, tokens in concatenated_examples.items()\n",
    "    }\n",
    "\n",
    "    # Create a new labels column\n",
    "    chunks[\"labels\"] = chunks[\"input_ids\"].copy()\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- Note that in the last step of group_texts() we create a new `labels` column which is a copy of the input_ids one. \n",
    "- As we’ll see shortly, that’s because in masked language modeling the objective is to predict randomly masked tokens in the input batch, and by creating a labels column we provide the ground truth for our language model to learn from.\n",
    "- Let’s now apply group_texts() to our tokenized datasets using `Dataset.map()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0b20386ac749d3905c3d416c56542f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48489d5f6d6c4d0ebd538eaa126ed1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89495d34c55d42b2bdeaa3757404461e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 61291\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 59904\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 122957\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- Grouping and then chunking the texts has produced many more examples than the original 25,000 for the train and test splits. \n",
    "- That’s because we now have examples involving contiguous tokens that span across multiple examples from the original corpus. \n",
    "- You can see this explicitly by looking for the special `[SEP]` and `[CLS]` tokens in one of the chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"as the vietnam war and race issues in the united states. in between asking politicians and ordinary denizens of stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men. < br / > < br / > what kills me about i am curious - yellow is that 40 years ago, this was considered pornographic. really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. while my countrymen mind find it shocking, in reality sex and nudity are a major staple in swedish cinema. even ingmar bergman,\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- As expected from our `group_texts()` function above, this looks identical to the decoded input_ids — but then how can our model possibly learn anything? \n",
    "- We’re missing a key step: inserting [MASK] tokens at random positions in the inputs! \n",
    "- Let’s see how we can do this on the fly during fine-tuning using a special data collator.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning DistilBERT with the Trainer API\n",
    "\n",
    "- Fine-tuning a masked language model is almost identical to fine-tuning a sequence classification model.\n",
    "- The only difference is that we need a special data collator that can randomly mask some of the tokens in each batch of texts. \n",
    "- Fortunately, 🤗 Transformers comes prepared with a dedicated DataCollatorForLanguageModeling for just this task. \n",
    "- We just have to pass it the tokenizer and an `mlm_probability` argument that specifies what fraction of the tokens to mask. \n",
    "- We’ll use `15%`, which is the amount used for `BERT` and a common choice in the literature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
