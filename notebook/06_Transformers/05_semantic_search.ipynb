{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Semantic Search](https://huggingface.co/learn/nlp-course/chapter5/6?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from rich import print\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from datasets.dataset_dict import DatasetDict, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
       "    num_rows: 3019\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp: str = \"lewtun/github-issues\"\n",
    "\n",
    "issues_dataset: Dataset = load_dataset(fp, split=\"train\")\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'repository_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944/labels{/name}'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944/comments'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'events_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944/events'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'html_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://github.com/huggingface/datasets/issues/2944'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000544370</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I_kwDODunzps47oxhy'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'number'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2944</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Add  `remove_columns` to `IterableDataset ` '</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'login'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cccntu'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31893406</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'MDQ6VXNlcjMxODkzNDA2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'avatar_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://avatars.githubusercontent.com/u/31893406?v=4'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'gravatar_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'html_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://github.com/cccntu'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'followers_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/followers'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'following_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/following{/other_user}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'gists_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/gists{/gist_id}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'starred_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/starred{/owner}{/repo}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'subscriptions_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/subscriptions'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'organizations_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/orgs'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'repos_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/repos'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'events_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/events{/privacy}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'received_events_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/received_events'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'site_admin'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1935892871</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'MDU6TGFiZWwxOTM1ODkyODcx'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/labels/enhancement'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'enhancement'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'color'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a2eeef'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'New feature or request'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'state'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'open'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'locked'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignee'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignees'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'milestone'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1632110460000</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1632110460000</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'closed_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'author_association'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'CONTRIBUTOR'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_lock_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pull_request'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'body'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'**Is your feature request related to a problem? Please describe.**\\r\\nA clear and concise description </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of what the problem is.\\r\\n\\r\\n```python\\r\\nfrom datasets import load_dataset\\r\\ndataset = load_dataset(\"c4\", </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'realnewslike\\', streaming =True, split=\\'train\\')\\r\\ndataset = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset.remove_columns(\\'url\\')\\r\\n```\\r\\n```\\r\\nAttributeError: \\'IterableDataset\\' object has no attribute </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'remove_columns\\'\\r\\n```\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nIt would be nice to have </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">`.remove_columns()` to match the `Datasets` api. \\r\\n\\r\\n\\r\\n**Describe alternatives you\\'ve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">considered**\\r\\n\\r\\nThis can be done with a single call to `.map()`, \\r\\n\\r\\nI can try to help add this. 🤗'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'timeline_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944/timeline'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'performed_via_github_app'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is_pull_request'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944'\u001b[0m,\n",
       "    \u001b[32m'repository_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets'\u001b[0m,\n",
       "    \u001b[32m'labels_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944/labels\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[32m'comments_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944/comments'\u001b[0m,\n",
       "    \u001b[32m'events_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944/events'\u001b[0m,\n",
       "    \u001b[32m'html_url'\u001b[0m: \u001b[32m'https://github.com/huggingface/datasets/issues/2944'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m: \u001b[1;36m1000544370\u001b[0m,\n",
       "    \u001b[32m'node_id'\u001b[0m: \u001b[32m'I_kwDODunzps47oxhy'\u001b[0m,\n",
       "    \u001b[32m'number'\u001b[0m: \u001b[1;36m2944\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m: \u001b[32m'Add  `remove_columns` to `IterableDataset ` '\u001b[0m,\n",
       "    \u001b[32m'user'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'login'\u001b[0m: \u001b[32m'cccntu'\u001b[0m,\n",
       "        \u001b[32m'id'\u001b[0m: \u001b[1;36m31893406\u001b[0m,\n",
       "        \u001b[32m'node_id'\u001b[0m: \u001b[32m'MDQ6VXNlcjMxODkzNDA2'\u001b[0m,\n",
       "        \u001b[32m'avatar_url'\u001b[0m: \u001b[32m'https://avatars.githubusercontent.com/u/31893406?\u001b[0m\u001b[32mv\u001b[0m\u001b[32m=\u001b[0m\u001b[32m4\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'gravatar_id'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "        \u001b[32m'url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu'\u001b[0m,\n",
       "        \u001b[32m'html_url'\u001b[0m: \u001b[32m'https://github.com/cccntu'\u001b[0m,\n",
       "        \u001b[32m'followers_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/followers'\u001b[0m,\n",
       "        \u001b[32m'following_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/following\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/other_user\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'gists_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/gists\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/gist_id\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'starred_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/starred\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/owner\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/repo\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'subscriptions_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/subscriptions'\u001b[0m,\n",
       "        \u001b[32m'organizations_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/orgs'\u001b[0m,\n",
       "        \u001b[32m'repos_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/repos'\u001b[0m,\n",
       "        \u001b[32m'events_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/events\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/privacy\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'received_events_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/received_events'\u001b[0m,\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'User'\u001b[0m,\n",
       "        \u001b[32m'site_admin'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'labels'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'id'\u001b[0m: \u001b[1;36m1935892871\u001b[0m,\n",
       "            \u001b[32m'node_id'\u001b[0m: \u001b[32m'MDU6TGFiZWwxOTM1ODkyODcx'\u001b[0m,\n",
       "            \u001b[32m'url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/labels/enhancement'\u001b[0m,\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'enhancement'\u001b[0m,\n",
       "            \u001b[32m'color'\u001b[0m: \u001b[32m'a2eeef'\u001b[0m,\n",
       "            \u001b[32m'default'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'description'\u001b[0m: \u001b[32m'New feature or request'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'state'\u001b[0m: \u001b[32m'open'\u001b[0m,\n",
       "    \u001b[32m'locked'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'assignee'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'assignees'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'milestone'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'comments'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m: \u001b[1;36m1632110460000\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m: \u001b[1;36m1632110460000\u001b[0m,\n",
       "    \u001b[32m'closed_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'author_association'\u001b[0m: \u001b[32m'CONTRIBUTOR'\u001b[0m,\n",
       "    \u001b[32m'active_lock_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'pull_request'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'body'\u001b[0m: \u001b[32m'**Is your feature request related to a problem? Please describe.**\\r\\nA clear and concise description \u001b[0m\n",
       "\u001b[32mof what the problem is.\\r\\n\\r\\n```python\\r\\nfrom datasets import load_dataset\\r\\ndataset = load_dataset\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"c4\", \u001b[0m\n",
       "\u001b[32m\\'realnewslike\\', streaming =True, \u001b[0m\u001b[32msplit\u001b[0m\u001b[32m=\\'train\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\r\\ndataset = \u001b[0m\n",
       "\u001b[32mdataset.remove_columns\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\'url\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\r\\n```\\r\\n```\\r\\nAttributeError: \\'IterableDataset\\' object has no attribute \u001b[0m\n",
       "\u001b[32m\\'remove_columns\\'\\r\\n```\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nIt would be nice to have \u001b[0m\n",
       "\u001b[32m`.remove_columns\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m` to match the `Datasets` api. \\r\\n\\r\\n\\r\\n**Describe alternatives you\\'ve \u001b[0m\n",
       "\u001b[32mconsidered**\\r\\n\\r\\nThis can be done with a single call to `.map\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m`, \\r\\n\\r\\nI can try to help add this. 🤗'\u001b[0m,\n",
       "    \u001b[32m'timeline_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944/timeline'\u001b[0m,\n",
       "    \u001b[32m'performed_via_github_app'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'is_pull_request'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(issues_dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'repository_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'events_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'html_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'number'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'state'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'locked'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignee'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignees'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'milestone'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'closed_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'author_association'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_lock_reason'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pull_request'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'body'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'timeline_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'performed_via_github_app'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is_pull_request'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'url'\u001b[0m,\n",
       "    \u001b[32m'repository_url'\u001b[0m,\n",
       "    \u001b[32m'labels_url'\u001b[0m,\n",
       "    \u001b[32m'comments_url'\u001b[0m,\n",
       "    \u001b[32m'events_url'\u001b[0m,\n",
       "    \u001b[32m'html_url'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m,\n",
       "    \u001b[32m'node_id'\u001b[0m,\n",
       "    \u001b[32m'number'\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m,\n",
       "    \u001b[32m'user'\u001b[0m,\n",
       "    \u001b[32m'labels'\u001b[0m,\n",
       "    \u001b[32m'state'\u001b[0m,\n",
       "    \u001b[32m'locked'\u001b[0m,\n",
       "    \u001b[32m'assignee'\u001b[0m,\n",
       "    \u001b[32m'assignees'\u001b[0m,\n",
       "    \u001b[32m'milestone'\u001b[0m,\n",
       "    \u001b[32m'comments'\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m,\n",
       "    \u001b[32m'closed_at'\u001b[0m,\n",
       "    \u001b[32m'author_association'\u001b[0m,\n",
       "    \u001b[32m'active_lock_reason'\u001b[0m,\n",
       "    \u001b[32m'pull_request'\u001b[0m,\n",
       "    \u001b[32m'body'\u001b[0m,\n",
       "    \u001b[32m'timeline_url'\u001b[0m,\n",
       "    \u001b[32m'performed_via_github_app'\u001b[0m,\n",
       "    \u001b[32m'is_pull_request'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(issues_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size if data BEFORE: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3019</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size if data BEFORE: \u001b[1;36m3019\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size if data AFTER: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">808</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size if data AFTER: \u001b[1;36m808\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The issues_dataset contains issues and pull requests.\n",
    "# Select ONLY the issues\n",
    "issues_dataset_1: Dataset = issues_dataset.filter(\n",
    "    (lambda x: x.get(\"is_pull_request\") == False and len(x.get(\"comments\")) > 0),\n",
    ")\n",
    "\n",
    "print(f\"Size if data BEFORE: {issues_dataset.num_rows}\\n\")\n",
    "\n",
    "print(f\"Size if data AFTER: {issues_dataset_1.num_rows}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'events_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'performed_via_github_app'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'repository_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignees'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'author_association'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_lock_reason'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'milestone'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'number'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is_pull_request'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignee'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'locked'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'state'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pull_request'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'closed_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'timeline_url'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'events_url'\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m,\n",
       "    \u001b[32m'user'\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m,\n",
       "    \u001b[32m'comments_url'\u001b[0m,\n",
       "    \u001b[32m'performed_via_github_app'\u001b[0m,\n",
       "    \u001b[32m'repository_url'\u001b[0m,\n",
       "    \u001b[32m'labels_url'\u001b[0m,\n",
       "    \u001b[32m'assignees'\u001b[0m,\n",
       "    \u001b[32m'author_association'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m,\n",
       "    \u001b[32m'active_lock_reason'\u001b[0m,\n",
       "    \u001b[32m'milestone'\u001b[0m,\n",
       "    \u001b[32m'labels'\u001b[0m,\n",
       "    \u001b[32m'number'\u001b[0m,\n",
       "    \u001b[32m'is_pull_request'\u001b[0m,\n",
       "    \u001b[32m'assignee'\u001b[0m,\n",
       "    \u001b[32m'url'\u001b[0m,\n",
       "    \u001b[32m'locked'\u001b[0m,\n",
       "    \u001b[32m'state'\u001b[0m,\n",
       "    \u001b[32m'pull_request'\u001b[0m,\n",
       "    \u001b[32m'node_id'\u001b[0m,\n",
       "    \u001b[32m'closed_at'\u001b[0m,\n",
       "    \u001b[32m'timeline_url'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_columns: list[str] = issues_dataset_1.column_names\n",
    "columns_to_keep: list[str] = [\"title\", \"body\", \"html_url\", \"comments\"]\n",
    "# Columns present in ONLY all_columns\n",
    "columns_to_remove: set = set(columns_to_keep).symmetric_difference(set(all_columns))\n",
    "print(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 808\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_dataset_1 = issues_dataset_1.remove_columns(column_names=columns_to_remove)\n",
    "issues_dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2945</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>[Cool, I think we can do both :), @lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen to protect the master branch only from **merge commits** (see update comment above), so no need to disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to the remote master branch; and eventually reverted without messing up the repo history).]</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2943</td>\n",
       "      <td>Backwards compatibility broken for cached datasets that use `.filter()`</td>\n",
       "      <td>[Hi ! I guess the caching mechanism should have considered the new `filter` to be different from the old one, and don't use cached results from the old `filter`.\\r\\nTo avoid other users from having this issue we could make the caching differentiate the two, what do you think ?, If it's easy enough to implement, then yes please 😄  But this issue can be low-priority, since I've only encountered it in a couple of `transformers` CI tests., Well it can cause issue with anyone that updates `datasets` and re-run some code that uses filter, so I'm creating a PR, I just merged a fix, let me know if...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to datasets `1.12.0`, some cached `.filter()` steps from `1.11.0` started failing with \\r\\n`ValueError: Keys mismatch: between {'indices': Value(dtype='uint64', id=None)} and {'file': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'speaker_id': Value(dtype='int64', id=None), 'chapter_id': Value(dtype='int64', id=None), 'id': Value(dtype='string', id=None)}`\\r\\n\\r\\nRelated feature: https://github.com/huggingface/datasets/pull/2836\\r\\n\\r\\n:question:  This is probably a `wontfix` bug, since it can be solved by simply cleaning the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2941</td>\n",
       "      <td>OSCAR unshuffled_original_ko: NonMatchingSplitsSizesError</td>\n",
       "      <td>[I tried `unshuffled_original_da` and it is also not working]</td>\n",
       "      <td>## Describe the bug\\r\\n\\r\\nCannot download OSCAR `unshuffled_original_ko` due to `NonMatchingSplitsSizesError`.\\r\\n\\r\\n## Steps to reproduce the bug\\r\\n\\r\\n```python\\r\\n&gt;&gt;&gt; dataset = datasets.load_dataset('oscar', 'unshuffled_original_ko')\\r\\nNonMatchingSplitsSizesError: [{'expected': SplitInfo(name='train', num_bytes=25292102197, num_examples=7345075, dataset_name='oscar'), 'recorded': SplitInfo(name='train', num_bytes=25284578514, num_examples=7344907, dataset_name='oscar')}]\\r\\n```\\r\\n\\r\\n## Expected results\\r\\n\\r\\nLoading is successful.\\r\\n\\r\\n## Actual results\\r\\n\\r\\nLoading throws ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2937</td>\n",
       "      <td>load_dataset using default cache on Windows causes PermissionError: [WinError 5] Access is denied</td>\n",
       "      <td>[Hi @daqieq, thanks for reporting.\\r\\n\\r\\nUnfortunately, I was not able to reproduce this bug:\\r\\n```ipython\\r\\nIn [1]: from datasets import load_dataset\\r\\n   ...: ds = load_dataset('wiki_bio')\\r\\nDownloading: 7.58kB [00:00, 26.3kB/s]\\r\\nDownloading: 2.71kB [00:00, ?B/s]\\r\\nUsing custom data configuration default\\r\\nDownloading and preparing dataset wiki_bio/default (download: 318.53 MiB, generated: 736.94 MiB, post-processed: Unknown size, total: 1.03 GiB) to C:\\Users\\username\\.cache\\huggingface\\datasets\\wiki_bio\\default\\\\r\\n1.1.0\\5293ce565954ba965dada626f1e79684e98172d950371d266bf3caaf8...</td>\n",
       "      <td>## Describe the bug\\r\\nStandard process to download and load the wiki_bio dataset causes PermissionError in Windows 10 and 11.\\r\\n\\r\\n## Steps to reproduce the bug\\r\\n```python\\r\\nfrom datasets import load_dataset\\r\\nds = load_dataset('wiki_bio')\\r\\n```\\r\\n\\r\\n## Expected results\\r\\nIt is expected that the dataset downloads without any errors.\\r\\n\\r\\n## Actual results\\r\\nPermissionError see trace below:\\r\\n```\\r\\nUsing custom data configuration default\\r\\nDownloading and preparing dataset wiki_bio/default (download: 318.53 MiB, generated: 736.94 MiB, post-processed: Unknown size, total: 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2934</td>\n",
       "      <td>to_tf_dataset keeps a reference to the open data somewhere, causing issues on windows</td>\n",
       "      <td>[I did some investigation and, as it seems, the bug stems from [this line](https://github.com/huggingface/datasets/blob/8004d7c3e1d74b29c3e5b0d1660331cd26758363/src/datasets/arrow_dataset.py#L325). The lifecycle of the dataset from the linked line is bound to one of the returned `tf.data.Dataset`. So my (hacky) solution involves wrapping the linked dataset with `weakref.proxy` and adding a custom `__del__` to `tf.python.data.ops.dataset_ops.TensorSliceDataset` (this is the type of a dataset that is returned by `tf.data.Dataset.from_tensor_slices`; this works for TF 2.x, but I'm not sure `t...</td>\n",
       "      <td>To reproduce:\\r\\n```python\\r\\nimport datasets as ds\\r\\nimport weakref\\r\\nimport gc\\r\\n\\r\\nd = ds.load_dataset(\"mnist\", split=\"train\")\\r\\nref = weakref.ref(d._data.table)\\r\\ntfd = d.to_tf_dataset(\"image\", batch_size=1, shuffle=False, label_cols=\"label\")\\r\\ndel tfd, d\\r\\ngc.collect()\\r\\nassert ref() is None, \"Error: there is at least one reference left\"\\r\\n```\\r\\n\\r\\nThis causes issues because the table holds a reference to an open arrow file that should be closed. So on windows it's not possible to delete or move the arrow file afterwards.\\r\\n\\r\\nMoreover the CI test of the `to_tf_dataset` ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              html_url  \\\n",
       "0  https://github.com/huggingface/datasets/issues/2945   \n",
       "1  https://github.com/huggingface/datasets/issues/2943   \n",
       "2  https://github.com/huggingface/datasets/issues/2941   \n",
       "3  https://github.com/huggingface/datasets/issues/2937   \n",
       "4  https://github.com/huggingface/datasets/issues/2934   \n",
       "\n",
       "                                                                                               title  \\\n",
       "0                                                                              Protect master branch   \n",
       "1                            Backwards compatibility broken for cached datasets that use `.filter()`   \n",
       "2                                          OSCAR unshuffled_original_ko: NonMatchingSplitsSizesError   \n",
       "3  load_dataset using default cache on Windows causes PermissionError: [WinError 5] Access is denied   \n",
       "4              to_tf_dataset keeps a reference to the open data somewhere, causing issues on windows   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comments  \\\n",
       "0                                                                                                                                                          [Cool, I think we can do both :), @lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen to protect the master branch only from **merge commits** (see update comment above), so no need to disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to the remote master branch; and eventually reverted without messing up the repo history).]   \n",
       "1  [Hi ! I guess the caching mechanism should have considered the new `filter` to be different from the old one, and don't use cached results from the old `filter`.\\r\\nTo avoid other users from having this issue we could make the caching differentiate the two, what do you think ?, If it's easy enough to implement, then yes please 😄  But this issue can be low-priority, since I've only encountered it in a couple of `transformers` CI tests., Well it can cause issue with anyone that updates `datasets` and re-run some code that uses filter, so I'm creating a PR, I just merged a fix, let me know if...   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [I tried `unshuffled_original_da` and it is also not working]   \n",
       "3  [Hi @daqieq, thanks for reporting.\\r\\n\\r\\nUnfortunately, I was not able to reproduce this bug:\\r\\n```ipython\\r\\nIn [1]: from datasets import load_dataset\\r\\n   ...: ds = load_dataset('wiki_bio')\\r\\nDownloading: 7.58kB [00:00, 26.3kB/s]\\r\\nDownloading: 2.71kB [00:00, ?B/s]\\r\\nUsing custom data configuration default\\r\\nDownloading and preparing dataset wiki_bio/default (download: 318.53 MiB, generated: 736.94 MiB, post-processed: Unknown size, total: 1.03 GiB) to C:\\Users\\username\\.cache\\huggingface\\datasets\\wiki_bio\\default\\\\r\\n1.1.0\\5293ce565954ba965dada626f1e79684e98172d950371d266bf3caaf8...   \n",
       "4  [I did some investigation and, as it seems, the bug stems from [this line](https://github.com/huggingface/datasets/blob/8004d7c3e1d74b29c3e5b0d1660331cd26758363/src/datasets/arrow_dataset.py#L325). The lifecycle of the dataset from the linked line is bound to one of the returned `tf.data.Dataset`. So my (hacky) solution involves wrapping the linked dataset with `weakref.proxy` and adding a custom `__del__` to `tf.python.data.ops.dataset_ops.TensorSliceDataset` (this is the type of a dataset that is returned by `tf.data.Dataset.from_tensor_slices`; this works for TF 2.x, but I'm not sure `t...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      body  \n",
       "0  After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...  \n",
       "1  ## Describe the bug\\r\\nAfter upgrading to datasets `1.12.0`, some cached `.filter()` steps from `1.11.0` started failing with \\r\\n`ValueError: Keys mismatch: between {'indices': Value(dtype='uint64', id=None)} and {'file': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'speaker_id': Value(dtype='int64', id=None), 'chapter_id': Value(dtype='int64', id=None), 'id': Value(dtype='string', id=None)}`\\r\\n\\r\\nRelated feature: https://github.com/huggingface/datasets/pull/2836\\r\\n\\r\\n:question:  This is probably a `wontfix` bug, since it can be solved by simply cleaning the...  \n",
       "2  ## Describe the bug\\r\\n\\r\\nCannot download OSCAR `unshuffled_original_ko` due to `NonMatchingSplitsSizesError`.\\r\\n\\r\\n## Steps to reproduce the bug\\r\\n\\r\\n```python\\r\\n>>> dataset = datasets.load_dataset('oscar', 'unshuffled_original_ko')\\r\\nNonMatchingSplitsSizesError: [{'expected': SplitInfo(name='train', num_bytes=25292102197, num_examples=7345075, dataset_name='oscar'), 'recorded': SplitInfo(name='train', num_bytes=25284578514, num_examples=7344907, dataset_name='oscar')}]\\r\\n```\\r\\n\\r\\n## Expected results\\r\\n\\r\\nLoading is successful.\\r\\n\\r\\n## Actual results\\r\\n\\r\\nLoading throws ab...  \n",
       "3  ## Describe the bug\\r\\nStandard process to download and load the wiki_bio dataset causes PermissionError in Windows 10 and 11.\\r\\n\\r\\n## Steps to reproduce the bug\\r\\n```python\\r\\nfrom datasets import load_dataset\\r\\nds = load_dataset('wiki_bio')\\r\\n```\\r\\n\\r\\n## Expected results\\r\\nIt is expected that the dataset downloads without any errors.\\r\\n\\r\\n## Actual results\\r\\nPermissionError see trace below:\\r\\n```\\r\\nUsing custom data configuration default\\r\\nDownloading and preparing dataset wiki_bio/default (download: 318.53 MiB, generated: 736.94 MiB, post-processed: Unknown size, total: 1....  \n",
       "4  To reproduce:\\r\\n```python\\r\\nimport datasets as ds\\r\\nimport weakref\\r\\nimport gc\\r\\n\\r\\nd = ds.load_dataset(\"mnist\", split=\"train\")\\r\\nref = weakref.ref(d._data.table)\\r\\ntfd = d.to_tf_dataset(\"image\", batch_size=1, shuffle=False, label_cols=\"label\")\\r\\ndel tfd, d\\r\\ngc.collect()\\r\\nassert ref() is None, \"Error: there is at least one reference left\"\\r\\n```\\r\\n\\r\\nThis causes issues because the table holds a reference to an open arrow file that should be closed. So on windows it's not possible to delete or move the arrow file afterwards.\\r\\n\\r\\nMoreover the CI test of the `to_tf_dataset` ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_dataset_1.set_format(\"pandas\")\n",
    "df: pd.DataFrame = issues_dataset_1[:]\n",
    "# OR df = issues_dataset_1.to_pandas()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Cool, I think we can do both :)'</span>\n",
       " <span style=\"color: #008000; text-decoration-color: #008000\">'@lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to protect the master branch only from **merge commits** (see update comment above), so no need to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the remote master branch; and eventually reverted without messing up the repo history).'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'Cool, I think we can do both :\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       " \u001b[32m'@lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen \u001b[0m\n",
       "\u001b[32mto protect the master branch only from **merge commits** \u001b[0m\u001b[32m(\u001b[0m\u001b[32msee update comment above\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, so no need to \u001b[0m\n",
       "\u001b[32mdisable/re-enable the protection on each release \u001b[0m\u001b[32m(\u001b[0m\u001b[32mdirect commits, different from merge commits, can be pushed to \u001b[0m\n",
       "\u001b[32mthe remote master branch; and eventually reverted without messing up the repo history\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df[\"comments\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are two comments in this particular comment index\n",
    "print(len(df[\"comments\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2945</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>Cool, I think we can do both :)</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2945</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>@lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen to protect the master branch only from **merge commits** (see update comment above), so no need to disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to the remote master branch; and eventually reverted without messing up the repo history).</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2943</td>\n",
       "      <td>Backwards compatibility broken for cached datasets that use `.filter()`</td>\n",
       "      <td>Hi ! I guess the caching mechanism should have considered the new `filter` to be different from the old one, and don't use cached results from the old `filter`.\\r\\nTo avoid other users from having this issue we could make the caching differentiate the two, what do you think ?</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to datasets `1.12.0`, some cached `.filter()` steps from `1.11.0` started failing with \\r\\n`ValueError: Keys mismatch: between {'indices': Value(dtype='uint64', id=None)} and {'file': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'speaker_id': Value(dtype='int64', id=None), 'chapter_id': Value(dtype='int64', id=None), 'id': Value(dtype='string', id=None)}`\\r\\n\\r\\nRelated feature: https://github.com/huggingface/datasets/pull/2836\\r\\n\\r\\n:question:  This is probably a `wontfix` bug, since it can be solved by simply cleaning the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              html_url  \\\n",
       "0  https://github.com/huggingface/datasets/issues/2945   \n",
       "1  https://github.com/huggingface/datasets/issues/2945   \n",
       "2  https://github.com/huggingface/datasets/issues/2943   \n",
       "\n",
       "                                                                     title  \\\n",
       "0                                                    Protect master branch   \n",
       "1                                                    Protect master branch   \n",
       "2  Backwards compatibility broken for cached datasets that use `.filter()`   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                       comments  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                               Cool, I think we can do both :)   \n",
       "1  @lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen to protect the master branch only from **merge commits** (see update comment above), so no need to disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to the remote master branch; and eventually reverted without messing up the repo history).   \n",
       "2                                                                                                                                          Hi ! I guess the caching mechanism should have considered the new `filter` to be different from the old one, and don't use cached results from the old `filter`.\\r\\nTo avoid other users from having this issue we could make the caching differentiate the two, what do you think ?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      body  \n",
       "0  After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...  \n",
       "1  After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...  \n",
       "2  ## Describe the bug\\r\\nAfter upgrading to datasets `1.12.0`, some cached `.filter()` steps from `1.11.0` started failing with \\r\\n`ValueError: Keys mismatch: between {'indices': Value(dtype='uint64', id=None)} and {'file': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'speaker_id': Value(dtype='int64', id=None), 'chapter_id': Value(dtype='int64', id=None), 'id': Value(dtype='string', id=None)}`\\r\\n\\r\\nRelated feature: https://github.com/huggingface/datasets/pull/2836\\r\\n\\r\\n:question:  This is probably a `wontfix` bug, since it can be solved by simply cleaning the...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the explode method to create a row for each comment in a given index.\n",
    "# i.e. index 0 with 2 comments creates 2 rows and index 1 with 6 comments creates 6 rows, etc.\n",
    "comments_df: pd.DataFrame = df.explode(\"comments\", ignore_index=True)\n",
    "comments_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 2964\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert back to Dataset\n",
    "comments_dataset: Dataset = Dataset.from_pandas(comments_df)\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05cda94c5754850a0a3c6ff20b87282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body', 'comment_length'],\n",
       "    num_rows: 2964\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add n new columns\n",
    "comments_dataset = comments_dataset.map(\n",
    "    lambda x: {\"comment_length\": len(x.get(\"comments\").split())}\n",
    ")\n",
    "\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comments': ['https://github.com/huggingface/datasets/blob/6c766f9115d686182d76b1b937cb27e099c45d68/src/datasets/builder.py#L179-L186',\n",
       "  'https://github.com/huggingface/datasets/blob/6c766f9115d686182d76b1b937cb27e099c45d68/src/datasets/builder.py#L179-L186',\n",
       "  '@albertvillanova ',\n",
       "  'Thanks!',\n",
       "  '#self-assign',\n",
       "  '#take',\n",
       "  '#take',\n",
       "  '#self-assign',\n",
       "  'Resolved',\n",
       "  'Ty!'],\n",
       " 'comment_length': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Short comments\n",
    "comments_dataset.sort(\"comment_length\").select_columns([\"comments\", \"comment_length\"])[\n",
    "    :10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b22db812c754220b3fae9efebc382a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body', 'comment_length'],\n",
       "    num_rows: 2175\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop short comments.\n",
    "# i.e comments like: 'Thanks!', '#self-assign', etc.\n",
    "comments_dataset = comments_dataset.filter(lambda x: x.get(\"comment_length\") > 15)\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
