{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Semantic Search](https://huggingface.co/learn/nlp-course/chapter5/6?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from rich import print\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from datasets.dataset_dict import DatasetDict, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
       "    num_rows: 3019\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp: str = \"lewtun/github-issues\"\n",
    "\n",
    "issues_dataset: Dataset = load_dataset(fp, split=\"train\")\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'repository_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944/labels{/name}'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944/comments'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'events_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944/events'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'html_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://github.com/huggingface/datasets/issues/2944'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000544370</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I_kwDODunzps47oxhy'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'number'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2944</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Add  `remove_columns` to `IterableDataset ` '</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'login'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cccntu'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31893406</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'MDQ6VXNlcjMxODkzNDA2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'avatar_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://avatars.githubusercontent.com/u/31893406?v=4'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'gravatar_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'html_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://github.com/cccntu'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'followers_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/followers'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'following_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/following{/other_user}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'gists_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/gists{/gist_id}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'starred_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/starred{/owner}{/repo}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'subscriptions_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/subscriptions'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'organizations_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/orgs'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'repos_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/repos'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'events_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/events{/privacy}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'received_events_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/users/cccntu/received_events'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'site_admin'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1935892871</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'MDU6TGFiZWwxOTM1ODkyODcx'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/labels/enhancement'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'enhancement'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'color'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a2eeef'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'New feature or request'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'state'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'open'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'locked'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignee'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignees'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'milestone'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1632110460000</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1632110460000</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'closed_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'author_association'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'CONTRIBUTOR'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_lock_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pull_request'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'body'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'**Is your feature request related to a problem? Please describe.**\\r\\nA clear and concise description </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of what the problem is.\\r\\n\\r\\n```python\\r\\nfrom datasets import load_dataset\\r\\ndataset = load_dataset(\"c4\", </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'realnewslike\\', streaming =True, split=\\'train\\')\\r\\ndataset = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset.remove_columns(\\'url\\')\\r\\n```\\r\\n```\\r\\nAttributeError: \\'IterableDataset\\' object has no attribute </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'remove_columns\\'\\r\\n```\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nIt would be nice to have </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">`.remove_columns()` to match the `Datasets` api. \\r\\n\\r\\n\\r\\n**Describe alternatives you\\'ve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">considered**\\r\\n\\r\\nThis can be done with a single call to `.map()`, \\r\\n\\r\\nI can try to help add this. ðŸ¤—'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'timeline_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.github.com/repos/huggingface/datasets/issues/2944/timeline'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'performed_via_github_app'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is_pull_request'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944'\u001b[0m,\n",
       "    \u001b[32m'repository_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets'\u001b[0m,\n",
       "    \u001b[32m'labels_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944/labels\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[32m'comments_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944/comments'\u001b[0m,\n",
       "    \u001b[32m'events_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944/events'\u001b[0m,\n",
       "    \u001b[32m'html_url'\u001b[0m: \u001b[32m'https://github.com/huggingface/datasets/issues/2944'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m: \u001b[1;36m1000544370\u001b[0m,\n",
       "    \u001b[32m'node_id'\u001b[0m: \u001b[32m'I_kwDODunzps47oxhy'\u001b[0m,\n",
       "    \u001b[32m'number'\u001b[0m: \u001b[1;36m2944\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m: \u001b[32m'Add  `remove_columns` to `IterableDataset ` '\u001b[0m,\n",
       "    \u001b[32m'user'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'login'\u001b[0m: \u001b[32m'cccntu'\u001b[0m,\n",
       "        \u001b[32m'id'\u001b[0m: \u001b[1;36m31893406\u001b[0m,\n",
       "        \u001b[32m'node_id'\u001b[0m: \u001b[32m'MDQ6VXNlcjMxODkzNDA2'\u001b[0m,\n",
       "        \u001b[32m'avatar_url'\u001b[0m: \u001b[32m'https://avatars.githubusercontent.com/u/31893406?\u001b[0m\u001b[32mv\u001b[0m\u001b[32m=\u001b[0m\u001b[32m4\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'gravatar_id'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "        \u001b[32m'url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu'\u001b[0m,\n",
       "        \u001b[32m'html_url'\u001b[0m: \u001b[32m'https://github.com/cccntu'\u001b[0m,\n",
       "        \u001b[32m'followers_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/followers'\u001b[0m,\n",
       "        \u001b[32m'following_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/following\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/other_user\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'gists_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/gists\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/gist_id\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'starred_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/starred\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/owner\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/repo\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'subscriptions_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/subscriptions'\u001b[0m,\n",
       "        \u001b[32m'organizations_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/orgs'\u001b[0m,\n",
       "        \u001b[32m'repos_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/repos'\u001b[0m,\n",
       "        \u001b[32m'events_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/events\u001b[0m\u001b[32m{\u001b[0m\u001b[32m/privacy\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'received_events_url'\u001b[0m: \u001b[32m'https://api.github.com/users/cccntu/received_events'\u001b[0m,\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'User'\u001b[0m,\n",
       "        \u001b[32m'site_admin'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'labels'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'id'\u001b[0m: \u001b[1;36m1935892871\u001b[0m,\n",
       "            \u001b[32m'node_id'\u001b[0m: \u001b[32m'MDU6TGFiZWwxOTM1ODkyODcx'\u001b[0m,\n",
       "            \u001b[32m'url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/labels/enhancement'\u001b[0m,\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'enhancement'\u001b[0m,\n",
       "            \u001b[32m'color'\u001b[0m: \u001b[32m'a2eeef'\u001b[0m,\n",
       "            \u001b[32m'default'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'description'\u001b[0m: \u001b[32m'New feature or request'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'state'\u001b[0m: \u001b[32m'open'\u001b[0m,\n",
       "    \u001b[32m'locked'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'assignee'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'assignees'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'milestone'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'comments'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m: \u001b[1;36m1632110460000\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m: \u001b[1;36m1632110460000\u001b[0m,\n",
       "    \u001b[32m'closed_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'author_association'\u001b[0m: \u001b[32m'CONTRIBUTOR'\u001b[0m,\n",
       "    \u001b[32m'active_lock_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'pull_request'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'body'\u001b[0m: \u001b[32m'**Is your feature request related to a problem? Please describe.**\\r\\nA clear and concise description \u001b[0m\n",
       "\u001b[32mof what the problem is.\\r\\n\\r\\n```python\\r\\nfrom datasets import load_dataset\\r\\ndataset = load_dataset\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"c4\", \u001b[0m\n",
       "\u001b[32m\\'realnewslike\\', streaming =True, \u001b[0m\u001b[32msplit\u001b[0m\u001b[32m=\\'train\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\r\\ndataset = \u001b[0m\n",
       "\u001b[32mdataset.remove_columns\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\'url\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\r\\n```\\r\\n```\\r\\nAttributeError: \\'IterableDataset\\' object has no attribute \u001b[0m\n",
       "\u001b[32m\\'remove_columns\\'\\r\\n```\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nIt would be nice to have \u001b[0m\n",
       "\u001b[32m`.remove_columns\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m` to match the `Datasets` api. \\r\\n\\r\\n\\r\\n**Describe alternatives you\\'ve \u001b[0m\n",
       "\u001b[32mconsidered**\\r\\n\\r\\nThis can be done with a single call to `.map\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m`, \\r\\n\\r\\nI can try to help add this. ðŸ¤—'\u001b[0m,\n",
       "    \u001b[32m'timeline_url'\u001b[0m: \u001b[32m'https://api.github.com/repos/huggingface/datasets/issues/2944/timeline'\u001b[0m,\n",
       "    \u001b[32m'performed_via_github_app'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'is_pull_request'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(issues_dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'repository_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'events_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'html_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'number'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'state'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'locked'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignee'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignees'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'milestone'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'closed_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'author_association'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_lock_reason'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pull_request'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'body'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'timeline_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'performed_via_github_app'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is_pull_request'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'url'\u001b[0m,\n",
       "    \u001b[32m'repository_url'\u001b[0m,\n",
       "    \u001b[32m'labels_url'\u001b[0m,\n",
       "    \u001b[32m'comments_url'\u001b[0m,\n",
       "    \u001b[32m'events_url'\u001b[0m,\n",
       "    \u001b[32m'html_url'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m,\n",
       "    \u001b[32m'node_id'\u001b[0m,\n",
       "    \u001b[32m'number'\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m,\n",
       "    \u001b[32m'user'\u001b[0m,\n",
       "    \u001b[32m'labels'\u001b[0m,\n",
       "    \u001b[32m'state'\u001b[0m,\n",
       "    \u001b[32m'locked'\u001b[0m,\n",
       "    \u001b[32m'assignee'\u001b[0m,\n",
       "    \u001b[32m'assignees'\u001b[0m,\n",
       "    \u001b[32m'milestone'\u001b[0m,\n",
       "    \u001b[32m'comments'\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m,\n",
       "    \u001b[32m'closed_at'\u001b[0m,\n",
       "    \u001b[32m'author_association'\u001b[0m,\n",
       "    \u001b[32m'active_lock_reason'\u001b[0m,\n",
       "    \u001b[32m'pull_request'\u001b[0m,\n",
       "    \u001b[32m'body'\u001b[0m,\n",
       "    \u001b[32m'timeline_url'\u001b[0m,\n",
       "    \u001b[32m'performed_via_github_app'\u001b[0m,\n",
       "    \u001b[32m'is_pull_request'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(issues_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size if data BEFORE: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3019</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size if data BEFORE: \u001b[1;36m3019\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size if data AFTER: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">808</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size if data AFTER: \u001b[1;36m808\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The issues_dataset contains issues and pull requests.\n",
    "# Select ONLY the issues\n",
    "issues_dataset_1: Dataset = issues_dataset.filter(\n",
    "    (lambda x: x.get(\"is_pull_request\") == False and len(x.get(\"comments\")) > 0),\n",
    ")\n",
    "\n",
    "print(f\"Size if data BEFORE: {issues_dataset.num_rows}\\n\")\n",
    "\n",
    "print(f\"Size if data AFTER: {issues_dataset_1.num_rows}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'events_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'comments_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'performed_via_github_app'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'repository_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels_url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignees'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'author_association'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_lock_reason'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'milestone'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'number'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is_pull_request'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'assignee'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'locked'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'state'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pull_request'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_id'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'closed_at'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'timeline_url'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'events_url'\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m,\n",
       "    \u001b[32m'user'\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m,\n",
       "    \u001b[32m'comments_url'\u001b[0m,\n",
       "    \u001b[32m'performed_via_github_app'\u001b[0m,\n",
       "    \u001b[32m'repository_url'\u001b[0m,\n",
       "    \u001b[32m'labels_url'\u001b[0m,\n",
       "    \u001b[32m'assignees'\u001b[0m,\n",
       "    \u001b[32m'author_association'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m,\n",
       "    \u001b[32m'active_lock_reason'\u001b[0m,\n",
       "    \u001b[32m'milestone'\u001b[0m,\n",
       "    \u001b[32m'labels'\u001b[0m,\n",
       "    \u001b[32m'number'\u001b[0m,\n",
       "    \u001b[32m'is_pull_request'\u001b[0m,\n",
       "    \u001b[32m'assignee'\u001b[0m,\n",
       "    \u001b[32m'url'\u001b[0m,\n",
       "    \u001b[32m'locked'\u001b[0m,\n",
       "    \u001b[32m'state'\u001b[0m,\n",
       "    \u001b[32m'pull_request'\u001b[0m,\n",
       "    \u001b[32m'node_id'\u001b[0m,\n",
       "    \u001b[32m'closed_at'\u001b[0m,\n",
       "    \u001b[32m'timeline_url'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_columns: list[str] = issues_dataset_1.column_names\n",
    "columns_to_keep: list[str] = [\"title\", \"body\", \"html_url\", \"comments\"]\n",
    "# Columns present in ONLY all_columns\n",
    "columns_to_remove: set = set(columns_to_keep).symmetric_difference(set(all_columns))\n",
    "print(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 808\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_dataset_1 = issues_dataset_1.remove_columns(column_names=columns_to_remove)\n",
    "issues_dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2945</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>[Cool, I think we can do both :), @lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen to protect the master branch only from **merge commits** (see update comment above), so no need to disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to the remote master branch; and eventually reverted without messing up the repo history).]</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2943</td>\n",
       "      <td>Backwards compatibility broken for cached datasets that use `.filter()`</td>\n",
       "      <td>[Hi ! I guess the caching mechanism should have considered the new `filter` to be different from the old one, and don't use cached results from the old `filter`.\\r\\nTo avoid other users from having this issue we could make the caching differentiate the two, what do you think ?, If it's easy enough to implement, then yes please ðŸ˜„  But this issue can be low-priority, since I've only encountered it in a couple of `transformers` CI tests., Well it can cause issue with anyone that updates `datasets` and re-run some code that uses filter, so I'm creating a PR, I just merged a fix, let me know if...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to datasets `1.12.0`, some cached `.filter()` steps from `1.11.0` started failing with \\r\\n`ValueError: Keys mismatch: between {'indices': Value(dtype='uint64', id=None)} and {'file': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'speaker_id': Value(dtype='int64', id=None), 'chapter_id': Value(dtype='int64', id=None), 'id': Value(dtype='string', id=None)}`\\r\\n\\r\\nRelated feature: https://github.com/huggingface/datasets/pull/2836\\r\\n\\r\\n:question:  This is probably a `wontfix` bug, since it can be solved by simply cleaning the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2941</td>\n",
       "      <td>OSCAR unshuffled_original_ko: NonMatchingSplitsSizesError</td>\n",
       "      <td>[I tried `unshuffled_original_da` and it is also not working]</td>\n",
       "      <td>## Describe the bug\\r\\n\\r\\nCannot download OSCAR `unshuffled_original_ko` due to `NonMatchingSplitsSizesError`.\\r\\n\\r\\n## Steps to reproduce the bug\\r\\n\\r\\n```python\\r\\n&gt;&gt;&gt; dataset = datasets.load_dataset('oscar', 'unshuffled_original_ko')\\r\\nNonMatchingSplitsSizesError: [{'expected': SplitInfo(name='train', num_bytes=25292102197, num_examples=7345075, dataset_name='oscar'), 'recorded': SplitInfo(name='train', num_bytes=25284578514, num_examples=7344907, dataset_name='oscar')}]\\r\\n```\\r\\n\\r\\n## Expected results\\r\\n\\r\\nLoading is successful.\\r\\n\\r\\n## Actual results\\r\\n\\r\\nLoading throws ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2937</td>\n",
       "      <td>load_dataset using default cache on Windows causes PermissionError: [WinError 5] Access is denied</td>\n",
       "      <td>[Hi @daqieq, thanks for reporting.\\r\\n\\r\\nUnfortunately, I was not able to reproduce this bug:\\r\\n```ipython\\r\\nIn [1]: from datasets import load_dataset\\r\\n   ...: ds = load_dataset('wiki_bio')\\r\\nDownloading: 7.58kB [00:00, 26.3kB/s]\\r\\nDownloading: 2.71kB [00:00, ?B/s]\\r\\nUsing custom data configuration default\\r\\nDownloading and preparing dataset wiki_bio/default (download: 318.53 MiB, generated: 736.94 MiB, post-processed: Unknown size, total: 1.03 GiB) to C:\\Users\\username\\.cache\\huggingface\\datasets\\wiki_bio\\default\\\\r\\n1.1.0\\5293ce565954ba965dada626f1e79684e98172d950371d266bf3caaf8...</td>\n",
       "      <td>## Describe the bug\\r\\nStandard process to download and load the wiki_bio dataset causes PermissionError in Windows 10 and 11.\\r\\n\\r\\n## Steps to reproduce the bug\\r\\n```python\\r\\nfrom datasets import load_dataset\\r\\nds = load_dataset('wiki_bio')\\r\\n```\\r\\n\\r\\n## Expected results\\r\\nIt is expected that the dataset downloads without any errors.\\r\\n\\r\\n## Actual results\\r\\nPermissionError see trace below:\\r\\n```\\r\\nUsing custom data configuration default\\r\\nDownloading and preparing dataset wiki_bio/default (download: 318.53 MiB, generated: 736.94 MiB, post-processed: Unknown size, total: 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2934</td>\n",
       "      <td>to_tf_dataset keeps a reference to the open data somewhere, causing issues on windows</td>\n",
       "      <td>[I did some investigation and, as it seems, the bug stems from [this line](https://github.com/huggingface/datasets/blob/8004d7c3e1d74b29c3e5b0d1660331cd26758363/src/datasets/arrow_dataset.py#L325). The lifecycle of the dataset from the linked line is bound to one of the returned `tf.data.Dataset`. So my (hacky) solution involves wrapping the linked dataset with `weakref.proxy` and adding a custom `__del__` to `tf.python.data.ops.dataset_ops.TensorSliceDataset` (this is the type of a dataset that is returned by `tf.data.Dataset.from_tensor_slices`; this works for TF 2.x, but I'm not sure `t...</td>\n",
       "      <td>To reproduce:\\r\\n```python\\r\\nimport datasets as ds\\r\\nimport weakref\\r\\nimport gc\\r\\n\\r\\nd = ds.load_dataset(\"mnist\", split=\"train\")\\r\\nref = weakref.ref(d._data.table)\\r\\ntfd = d.to_tf_dataset(\"image\", batch_size=1, shuffle=False, label_cols=\"label\")\\r\\ndel tfd, d\\r\\ngc.collect()\\r\\nassert ref() is None, \"Error: there is at least one reference left\"\\r\\n```\\r\\n\\r\\nThis causes issues because the table holds a reference to an open arrow file that should be closed. So on windows it's not possible to delete or move the arrow file afterwards.\\r\\n\\r\\nMoreover the CI test of the `to_tf_dataset` ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              html_url  \\\n",
       "0  https://github.com/huggingface/datasets/issues/2945   \n",
       "1  https://github.com/huggingface/datasets/issues/2943   \n",
       "2  https://github.com/huggingface/datasets/issues/2941   \n",
       "3  https://github.com/huggingface/datasets/issues/2937   \n",
       "4  https://github.com/huggingface/datasets/issues/2934   \n",
       "\n",
       "                                                                                               title  \\\n",
       "0                                                                              Protect master branch   \n",
       "1                            Backwards compatibility broken for cached datasets that use `.filter()`   \n",
       "2                                          OSCAR unshuffled_original_ko: NonMatchingSplitsSizesError   \n",
       "3  load_dataset using default cache on Windows causes PermissionError: [WinError 5] Access is denied   \n",
       "4              to_tf_dataset keeps a reference to the open data somewhere, causing issues on windows   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comments  \\\n",
       "0                                                                                                                                                          [Cool, I think we can do both :), @lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen to protect the master branch only from **merge commits** (see update comment above), so no need to disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to the remote master branch; and eventually reverted without messing up the repo history).]   \n",
       "1  [Hi ! I guess the caching mechanism should have considered the new `filter` to be different from the old one, and don't use cached results from the old `filter`.\\r\\nTo avoid other users from having this issue we could make the caching differentiate the two, what do you think ?, If it's easy enough to implement, then yes please ðŸ˜„  But this issue can be low-priority, since I've only encountered it in a couple of `transformers` CI tests., Well it can cause issue with anyone that updates `datasets` and re-run some code that uses filter, so I'm creating a PR, I just merged a fix, let me know if...   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [I tried `unshuffled_original_da` and it is also not working]   \n",
       "3  [Hi @daqieq, thanks for reporting.\\r\\n\\r\\nUnfortunately, I was not able to reproduce this bug:\\r\\n```ipython\\r\\nIn [1]: from datasets import load_dataset\\r\\n   ...: ds = load_dataset('wiki_bio')\\r\\nDownloading: 7.58kB [00:00, 26.3kB/s]\\r\\nDownloading: 2.71kB [00:00, ?B/s]\\r\\nUsing custom data configuration default\\r\\nDownloading and preparing dataset wiki_bio/default (download: 318.53 MiB, generated: 736.94 MiB, post-processed: Unknown size, total: 1.03 GiB) to C:\\Users\\username\\.cache\\huggingface\\datasets\\wiki_bio\\default\\\\r\\n1.1.0\\5293ce565954ba965dada626f1e79684e98172d950371d266bf3caaf8...   \n",
       "4  [I did some investigation and, as it seems, the bug stems from [this line](https://github.com/huggingface/datasets/blob/8004d7c3e1d74b29c3e5b0d1660331cd26758363/src/datasets/arrow_dataset.py#L325). The lifecycle of the dataset from the linked line is bound to one of the returned `tf.data.Dataset`. So my (hacky) solution involves wrapping the linked dataset with `weakref.proxy` and adding a custom `__del__` to `tf.python.data.ops.dataset_ops.TensorSliceDataset` (this is the type of a dataset that is returned by `tf.data.Dataset.from_tensor_slices`; this works for TF 2.x, but I'm not sure `t...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      body  \n",
       "0  After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...  \n",
       "1  ## Describe the bug\\r\\nAfter upgrading to datasets `1.12.0`, some cached `.filter()` steps from `1.11.0` started failing with \\r\\n`ValueError: Keys mismatch: between {'indices': Value(dtype='uint64', id=None)} and {'file': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'speaker_id': Value(dtype='int64', id=None), 'chapter_id': Value(dtype='int64', id=None), 'id': Value(dtype='string', id=None)}`\\r\\n\\r\\nRelated feature: https://github.com/huggingface/datasets/pull/2836\\r\\n\\r\\n:question:  This is probably a `wontfix` bug, since it can be solved by simply cleaning the...  \n",
       "2  ## Describe the bug\\r\\n\\r\\nCannot download OSCAR `unshuffled_original_ko` due to `NonMatchingSplitsSizesError`.\\r\\n\\r\\n## Steps to reproduce the bug\\r\\n\\r\\n```python\\r\\n>>> dataset = datasets.load_dataset('oscar', 'unshuffled_original_ko')\\r\\nNonMatchingSplitsSizesError: [{'expected': SplitInfo(name='train', num_bytes=25292102197, num_examples=7345075, dataset_name='oscar'), 'recorded': SplitInfo(name='train', num_bytes=25284578514, num_examples=7344907, dataset_name='oscar')}]\\r\\n```\\r\\n\\r\\n## Expected results\\r\\n\\r\\nLoading is successful.\\r\\n\\r\\n## Actual results\\r\\n\\r\\nLoading throws ab...  \n",
       "3  ## Describe the bug\\r\\nStandard process to download and load the wiki_bio dataset causes PermissionError in Windows 10 and 11.\\r\\n\\r\\n## Steps to reproduce the bug\\r\\n```python\\r\\nfrom datasets import load_dataset\\r\\nds = load_dataset('wiki_bio')\\r\\n```\\r\\n\\r\\n## Expected results\\r\\nIt is expected that the dataset downloads without any errors.\\r\\n\\r\\n## Actual results\\r\\nPermissionError see trace below:\\r\\n```\\r\\nUsing custom data configuration default\\r\\nDownloading and preparing dataset wiki_bio/default (download: 318.53 MiB, generated: 736.94 MiB, post-processed: Unknown size, total: 1....  \n",
       "4  To reproduce:\\r\\n```python\\r\\nimport datasets as ds\\r\\nimport weakref\\r\\nimport gc\\r\\n\\r\\nd = ds.load_dataset(\"mnist\", split=\"train\")\\r\\nref = weakref.ref(d._data.table)\\r\\ntfd = d.to_tf_dataset(\"image\", batch_size=1, shuffle=False, label_cols=\"label\")\\r\\ndel tfd, d\\r\\ngc.collect()\\r\\nassert ref() is None, \"Error: there is at least one reference left\"\\r\\n```\\r\\n\\r\\nThis causes issues because the table holds a reference to an open arrow file that should be closed. So on windows it's not possible to delete or move the arrow file afterwards.\\r\\n\\r\\nMoreover the CI test of the `to_tf_dataset` ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_dataset_1.set_format(\"pandas\")\n",
    "df: pd.DataFrame = issues_dataset_1[:]\n",
    "# OR df = issues_dataset_1.to_pandas()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Cool, I think we can do both :)'</span>\n",
       " <span style=\"color: #008000; text-decoration-color: #008000\">'@lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to protect the master branch only from **merge commits** (see update comment above), so no need to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the remote master branch; and eventually reverted without messing up the repo history).'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'Cool, I think we can do both :\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       " \u001b[32m'@lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen \u001b[0m\n",
       "\u001b[32mto protect the master branch only from **merge commits** \u001b[0m\u001b[32m(\u001b[0m\u001b[32msee update comment above\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, so no need to \u001b[0m\n",
       "\u001b[32mdisable/re-enable the protection on each release \u001b[0m\u001b[32m(\u001b[0m\u001b[32mdirect commits, different from merge commits, can be pushed to \u001b[0m\n",
       "\u001b[32mthe remote master branch; and eventually reverted without messing up the repo history\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df[\"comments\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are two comments in this particular comment index\n",
    "print(len(df[\"comments\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2945</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>Cool, I think we can do both :)</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2945</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>@lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen to protect the master branch only from **merge commits** (see update comment above), so no need to disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to the remote master branch; and eventually reverted without messing up the repo history).</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2943</td>\n",
       "      <td>Backwards compatibility broken for cached datasets that use `.filter()`</td>\n",
       "      <td>Hi ! I guess the caching mechanism should have considered the new `filter` to be different from the old one, and don't use cached results from the old `filter`.\\r\\nTo avoid other users from having this issue we could make the caching differentiate the two, what do you think ?</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to datasets `1.12.0`, some cached `.filter()` steps from `1.11.0` started failing with \\r\\n`ValueError: Keys mismatch: between {'indices': Value(dtype='uint64', id=None)} and {'file': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'speaker_id': Value(dtype='int64', id=None), 'chapter_id': Value(dtype='int64', id=None), 'id': Value(dtype='string', id=None)}`\\r\\n\\r\\nRelated feature: https://github.com/huggingface/datasets/pull/2836\\r\\n\\r\\n:question:  This is probably a `wontfix` bug, since it can be solved by simply cleaning the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              html_url  \\\n",
       "0  https://github.com/huggingface/datasets/issues/2945   \n",
       "1  https://github.com/huggingface/datasets/issues/2945   \n",
       "2  https://github.com/huggingface/datasets/issues/2943   \n",
       "\n",
       "                                                                     title  \\\n",
       "0                                                    Protect master branch   \n",
       "1                                                    Protect master branch   \n",
       "2  Backwards compatibility broken for cached datasets that use `.filter()`   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                       comments  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                               Cool, I think we can do both :)   \n",
       "1  @lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen to protect the master branch only from **merge commits** (see update comment above), so no need to disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to the remote master branch; and eventually reverted without messing up the repo history).   \n",
       "2                                                                                                                                          Hi ! I guess the caching mechanism should have considered the new `filter` to be different from the old one, and don't use cached results from the old `filter`.\\r\\nTo avoid other users from having this issue we could make the caching differentiate the two, what do you think ?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      body  \n",
       "0  After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...  \n",
       "1  After accidental merge commit (91c55355b634d0dc73350a7ddee1a6776dbbdd69) into `datasets` master branch, all commits present in the feature branch were permanently added to `datasets` master branch history, as e.g.:\\r\\n- 00cc036fea7c7745cfe722360036ed306796a3f2\\r\\n- 13ae8c98602bbad8197de3b9b425f4c78f582af1\\r\\n- ...\\r\\n\\r\\nI propose to protect our master branch, so that we avoid we can accidentally make this kind of mistakes in the future:\\r\\n- [x] For Pull Requests using GitHub, allow only squash merging, so that only a single commit per Pull Request is merged into the master branch\\r\\n  - ...  \n",
       "2  ## Describe the bug\\r\\nAfter upgrading to datasets `1.12.0`, some cached `.filter()` steps from `1.11.0` started failing with \\r\\n`ValueError: Keys mismatch: between {'indices': Value(dtype='uint64', id=None)} and {'file': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'speaker_id': Value(dtype='int64', id=None), 'chapter_id': Value(dtype='int64', id=None), 'id': Value(dtype='string', id=None)}`\\r\\n\\r\\nRelated feature: https://github.com/huggingface/datasets/pull/2836\\r\\n\\r\\n:question:  This is probably a `wontfix` bug, since it can be solved by simply cleaning the...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the explode method to create a row for each comment in a given index.\n",
    "# i.e. index 0 with 2 comments creates 2 rows and index 1 with 6 comments creates 6 rows, etc.\n",
    "comments_df: pd.DataFrame = df.explode(\"comments\", ignore_index=True)\n",
    "comments_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 2964\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert back to Dataset\n",
    "comments_dataset: Dataset = Dataset.from_pandas(comments_df)\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05cda94c5754850a0a3c6ff20b87282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body', 'comment_length'],\n",
       "    num_rows: 2964\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add n new columns\n",
    "comments_dataset = comments_dataset.map(\n",
    "    lambda x: {\"comment_length\": len(x.get(\"comments\").split())}\n",
    ")\n",
    "\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comments': ['https://github.com/huggingface/datasets/blob/6c766f9115d686182d76b1b937cb27e099c45d68/src/datasets/builder.py#L179-L186',\n",
       "  'https://github.com/huggingface/datasets/blob/6c766f9115d686182d76b1b937cb27e099c45d68/src/datasets/builder.py#L179-L186',\n",
       "  '@albertvillanova ',\n",
       "  'Thanks!',\n",
       "  '#self-assign',\n",
       "  '#take',\n",
       "  '#take',\n",
       "  '#self-assign',\n",
       "  'Resolved',\n",
       "  'Ty!'],\n",
       " 'comment_length': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Short comments\n",
    "comments_dataset.sort(\"comment_length\").select_columns([\"comments\", \"comment_length\"])[\n",
    "    :10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b22db812c754220b3fae9efebc382a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body', 'comment_length'],\n",
       "    num_rows: 2175\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop short comments.\n",
    "# i.e comments like: 'Thanks!', '#self-assign', etc.\n",
    "comments_dataset = comments_dataset.filter(lambda x: x.get(\"comment_length\") > 15)\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
