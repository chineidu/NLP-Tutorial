{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chineidu/NLP-Tutorial/blob/main/notebook/06_Transformers/06a_tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg18cCaBfQLh"
      },
      "source": [
        "# Training A New Tokenizer From An Old Tokenizer\n",
        "\n",
        "- Check [this](https://huggingface.co/learn/nlp-course/chapter6/2?fw=pt) for info on how to finetune a pretrained tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rich\n",
        "!pip install transformers[torch]\n",
        "!pip install torch datasets evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flr9QrW-0GdS",
        "outputId": "1a990abb-f906-49cb-f9df-821e83c7a412"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (13.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hlPhcPL7fQLj"
      },
      "outputs": [],
      "source": [
        "# Built-in library\n",
        "import re\n",
        "import json\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rich import print\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Pandas settings\n",
        "pd.options.display.max_rows = 1_000\n",
        "pd.options.display.max_columns = 1_000\n",
        "pd.options.display.max_colwidth = 600\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Black code formatter (Optional)\n",
        "# %load_ext lab_black\n",
        "\n",
        "# auto reload imports\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiyRUp1TfQLl"
      },
      "source": [
        "<hr><br>\n",
        "\n",
        "## Batch Encoding Using Fast Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "K_u65tWffQLl",
        "outputId": "bea48383-cb9e-41a7-e84e-3c94bf806776"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'transformers.tokenization_utils_base.BatchEncoding'\u001b[0m\u001b[1m>\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'transformers.tokenization_utils_base.BatchEncoding'</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "CHECKPOINT: str = \"bert-base-cased\"\n",
        "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "example: str = \"My name is Chineidu and I work at Hugging Face In Brooklyn.\"\n",
        "encoding: dict[\"str\", Any] = tokenizer(example)\n",
        "\n",
        "print(type(encoding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "4EQK5u9AfQLm",
        "outputId": "ac02fd00-6a75-4a92-b4e9-1602c5203ee5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'input_ids'\u001b[0m: \u001b[1m[\u001b[0m\n",
              "        \u001b[1;36m101\u001b[0m,\n",
              "        \u001b[1;36m1422\u001b[0m,\n",
              "        \u001b[1;36m1271\u001b[0m,\n",
              "        \u001b[1;36m1110\u001b[0m,\n",
              "        \u001b[1;36m19935\u001b[0m,\n",
              "        \u001b[1;36m6851\u001b[0m,\n",
              "        \u001b[1;36m7641\u001b[0m,\n",
              "        \u001b[1;36m1105\u001b[0m,\n",
              "        \u001b[1;36m146\u001b[0m,\n",
              "        \u001b[1;36m1250\u001b[0m,\n",
              "        \u001b[1;36m1120\u001b[0m,\n",
              "        \u001b[1;36m20164\u001b[0m,\n",
              "        \u001b[1;36m10932\u001b[0m,\n",
              "        \u001b[1;36m10289\u001b[0m,\n",
              "        \u001b[1;36m1130\u001b[0m,\n",
              "        \u001b[1;36m6010\u001b[0m,\n",
              "        \u001b[1;36m119\u001b[0m,\n",
              "        \u001b[1;36m102\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[32m'token_type_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[32m'attention_mask'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span>: <span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1422</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1271</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1110</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19935</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6851</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7641</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1105</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1250</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1120</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20164</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10932</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10289</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1130</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6010</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span>,\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'token_type_ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mCLS\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
              "    \u001b[32m'My'\u001b[0m,\n",
              "    \u001b[32m'name'\u001b[0m,\n",
              "    \u001b[32m'is'\u001b[0m,\n",
              "    \u001b[32m'Chin'\u001b[0m,\n",
              "    \u001b[32m'##ei'\u001b[0m,\n",
              "    \u001b[32m'##du'\u001b[0m,\n",
              "    \u001b[32m'and'\u001b[0m,\n",
              "    \u001b[32m'I'\u001b[0m,\n",
              "    \u001b[32m'work'\u001b[0m,\n",
              "    \u001b[32m'at'\u001b[0m,\n",
              "    \u001b[32m'Hu'\u001b[0m,\n",
              "    \u001b[32m'##gging'\u001b[0m,\n",
              "    \u001b[32m'Face'\u001b[0m,\n",
              "    \u001b[32m'In'\u001b[0m,\n",
              "    \u001b[32m'Brooklyn'\u001b[0m,\n",
              "    \u001b[32m'.'\u001b[0m,\n",
              "    \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mSEP\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'[CLS]'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'My'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'is'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'Chin'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'##ei'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'##du'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'I'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'work'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'at'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'Hu'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'##gging'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'Face'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'In'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'Brooklyn'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'[SEP]'</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(encoding)\n",
        "\n",
        "# Access the tokens (w/o converting the IDs back to tokens)\n",
        "print(encoding.tokens())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "OWMVVX9xfQLm",
        "outputId": "4e2bc049-5034-41f3-cbfa-e1a2cf866e41"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[3;35mNone\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m9\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get the index of the word each token comes from.\n",
        "# The special tokens [CLS] and [SEP] are represented as None.\n",
        "print(encoding.word_ids())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "i5F5Uf63fQLn",
        "outputId": "e5c695d9-851b-4807-837b-a900bf005365"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'input_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m2387\u001b[0m, \u001b[1;36m766\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m732\u001b[0m, \u001b[1;36m833\u001b[0m, \u001b[1;36m808\u001b[0m, \u001b[1;36m257\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m38\u001b[0m, \u001b[1;36m173\u001b[0m, \u001b[1;36m23\u001b[0m, \u001b[1;36m30581\u001b[0m, \u001b[1;36m3923\u001b[0m, \u001b[1;36m12346\u001b[0m, \u001b[1;36m96\u001b[0m, \u001b[1;36m6314\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[32m'attention_mask'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2387</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">766</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">732</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">833</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">808</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">173</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30581</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3923</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12346</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6314</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32ms\u001b[0m\u001b[32m>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'My'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'Ġname'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'Ġis'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'ĠCh'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'ine'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'id'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'u'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'Ġand'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'ĠI'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'Ġwork'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'Ġat'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'ĠHug'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'ging'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'ĠFace'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'ĠIn'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'ĠBrooklyn'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'.'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'</s\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'&lt;s&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'My'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ġname'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ġis'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'ĠCh'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'ine'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'u'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ġand'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'ĠI'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ġwork'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ġat'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'ĠHug'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'ging'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'ĠFace'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'ĠIn'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'ĠBrooklyn'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'.'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;/s&gt;'</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Try another tokenizer!\n",
        "CHECKPOINT: str = \"roberta-base\"\n",
        "tokenizer_2: AutoTokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "example_2: str = \"My name is Chineidu and I work at Hugging Face In Brooklyn.\"\n",
        "encoding_2: dict[\"str\", Any] = tokenizer_2(example_2)\n",
        "\n",
        "print(encoding_2)\n",
        "\n",
        "# Access the tokens (w/o converting the IDs back to tokens)\n",
        "print(encoding_2.tokens())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "fGLRji0yfQLn",
        "outputId": "82779e3e-7e4b-4e4e-bc79-5368a65c7f08"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "My name is Chineidu and I work at Hugging Face In Brooklyn.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">My name is Chineidu and I work at Hugging Face In Brooklyn.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[3;35mNone\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m9\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mCLS\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
              "    \u001b[32m'My'\u001b[0m,\n",
              "    \u001b[32m'name'\u001b[0m,\n",
              "    \u001b[32m'is'\u001b[0m,\n",
              "    \u001b[32m'Chin'\u001b[0m,\n",
              "    \u001b[32m'##ei'\u001b[0m,\n",
              "    \u001b[32m'##du'\u001b[0m,\n",
              "    \u001b[32m'and'\u001b[0m,\n",
              "    \u001b[32m'I'\u001b[0m,\n",
              "    \u001b[32m'work'\u001b[0m,\n",
              "    \u001b[32m'at'\u001b[0m,\n",
              "    \u001b[32m'Hu'\u001b[0m,\n",
              "    \u001b[32m'##gging'\u001b[0m,\n",
              "    \u001b[32m'Face'\u001b[0m,\n",
              "    \u001b[32m'In'\u001b[0m,\n",
              "    \u001b[32m'Brooklyn'\u001b[0m,\n",
              "    \u001b[32m'.'\u001b[0m,\n",
              "    \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mSEP\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'[CLS]'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'My'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'is'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'Chin'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'##ei'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'##du'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'I'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'work'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'at'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'Hu'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'##gging'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'Face'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'In'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'Brooklyn'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'[SEP]'</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(example)\n",
        "print(encoding.word_ids())\n",
        "\n",
        "# Access the tokens (w/o converting the IDs back to tokens)\n",
        "print(encoding.tokens())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LnnYnuOfQLn"
      },
      "source": [
        "```text\n",
        "- We can map any word or token to characters in the original text, and vice versa,\n",
        "* via the:\n",
        "  - word_to_chars()\n",
        "  - or token_to_chars() and char_to_word()\n",
        "  - or char_to_token() methods.\n",
        "  \n",
        "- The word_ids() method told us that ##ei is part of the word at index 3, but which word is it in the sentence? We can find out like this:\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J69MqNp9fQLo",
        "outputId": "834298fd-50b9-452c-cf36-84d68f4bb1f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chineidu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "start, end = encoding.word_to_chars(3)\n",
        "example[start:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9ybOU9BfQLo"
      },
      "source": [
        "<hr><br>\n",
        "\n",
        "## [Text Classification Pipeline](https://huggingface.co/learn/nlp-course/chapter6/3?fw=pt)\n",
        "\n",
        "```text\n",
        "- Using a token classification pipeline, we can get some results to compare manually.\n",
        "- The model used by default is dbmdz/bert-large-cased-finetuned-conll03-english and it performs NER on sentences.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0-6FPrqfQLo",
        "outputId": "8e517ec2-858a-4349-c453-73de7567c6a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'I-PER',\n",
              "  'score': 0.99802446,\n",
              "  'index': 4,\n",
              "  'word': 'Chin',\n",
              "  'start': 11,\n",
              "  'end': 15},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.96976656,\n",
              "  'index': 5,\n",
              "  'word': '##ei',\n",
              "  'start': 15,\n",
              "  'end': 17},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.99290186,\n",
              "  'index': 6,\n",
              "  'word': '##du',\n",
              "  'start': 17,\n",
              "  'end': 19},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.99207014,\n",
              "  'index': 11,\n",
              "  'word': 'Hu',\n",
              "  'start': 34,\n",
              "  'end': 36},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.99378514,\n",
              "  'index': 12,\n",
              "  'word': '##gging',\n",
              "  'start': 36,\n",
              "  'end': 41},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.9924396,\n",
              "  'index': 13,\n",
              "  'word': 'Face',\n",
              "  'start': 42,\n",
              "  'end': 46},\n",
              " {'entity': 'I-LOC',\n",
              "  'score': 0.9217939,\n",
              "  'index': 15,\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 50,\n",
              "  'end': 58}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "TASK: str = \"token-classification\"  # Named Entity Recognition (NER)\n",
        "token_classifier: pipeline = pipeline(task=TASK)\n",
        "example: str = \"My name is Chineidu and I work at Hugging Face In Brooklyn.\"\n",
        "\n",
        "token_classifier(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpmzt708fQLp"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### Comment\n",
        "\n",
        "```text\n",
        "- The model properly identified each token generated by `Chineidu` as a person, each token generated by “Hugging Face” as an organization, and the token “Brooklyn” as a location. We can also ask the pipeline to group together the tokens that correspond to the same entity:\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO3wDGRrfQLp",
        "outputId": "6459d39a-318d-49c2-d590-c4f0bec80a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.98689765,\n",
              "  'word': 'Chineidu',\n",
              "  'start': 11,\n",
              "  'end': 19},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.99276495,\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 34,\n",
              "  'end': 46},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9217939,\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 50,\n",
              "  'end': 58}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "TASK: str = \"token-classification\"  # Named Entity Recognition (NER)\n",
        "\n",
        "# With \"simple\" the score is just the mean of the scores of each token in the\n",
        "# given entity: e.g., the score of “Chineidu” is the mean of the scores\n",
        "# we saw in the previous example for the tokens Chin, ##ei, and ##du\n",
        "token_classifier: pipeline = pipeline(task=TASK, aggregation_strategy=\"simple\")\n",
        "example: str = \"My name is Chineidu and I work at Hugging Face In Brooklyn.\"\n",
        "\n",
        "token_classifier(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Other Strategies:\n",
        "\n",
        "```text\n",
        "- \"first\", where the score of each entity is the score of the first token of that entity (so for “Chineidu” it would be 0.99802446, the score of the token Chin)\n",
        "\n",
        "- \"max\", where the score of each entity is the maximum score of the tokens in that entity (so for “Hugging Face” it would be 0.98879766, the score of “Face”)\n",
        "\n",
        "- \"average\", where the score of each entity is the average of the scores of the words composing that entity (so for “Chineidu” there would be no difference from the \"simple\" strategy, but “Hugging Face” would have a score of 0.9819, the average of the scores for “Hugging”, 0.975, and “Face”, 0.98879)\n",
        "```"
      ],
      "metadata": {
        "id": "dD23VqjG2fcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "model_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
        "\n",
        "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
        "inputs = tokenizer(example, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGOhBh4Y3iwa",
        "outputId": "f93c9fe0-1a63-4f31-d94a-199680da6710"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "\n",
        "model_checkpoint: str = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
        "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model: AutoModelForTokenClassification = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
        "\n",
        "example: str = \"My name is Chineidu and I work at Hugging Face In Brooklyn.\"\n",
        "inputs: dict[str, Any] = tokenizer(example, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfjD7e2C3ijV",
        "outputId": "366c30ac-6d3d-4982-9810-2ce0978b5cfe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89ch4N7G5KBH",
        "outputId": "0e51b1f3-953c-4094-ca80-3a8ca6fa192a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs[\"input_ids\"].shape)\n",
        "print(outputs.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Ls_Y5Foi3igC",
        "outputId": "1261be8f-044b-4f72-f9b5-c6d0a96a726f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m18\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m18\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment:\n",
        "\n",
        "```text\n",
        "- The output is a batch with 1 sequence of 18 tokens and the model has 9 different labels, so the output of the model has a shape of 1 x 18 x 9.\n",
        "\n",
        "- Like for the text classification pipeline, a softmax function is used to convert those logits to probabilities, and the argmax is calculated to get predictions (note that we can take the argmax on the logits because the softmax does not change the order)\n",
        "```"
      ],
      "metadata": {
        "id": "8oofwwgO5cn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "probabilities: list[float] = F.softmax(outputs.logits, dim=-1)[0].tolist()\n",
        "predictions: list[int] = outputs.logits.argmax(dim=-1)[0].tolist()\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "p6LieGbF3icH",
        "outputId": "8b1aef95-981a-4cd0-a9e1-1159b680369c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The model.config.id2label attribute contains the mapping of indexes to labels\n",
        "# that we can use to make sense of the predictions:\n",
        "print(model.config.id2label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "eJ6FRGgD3iY-",
        "outputId": "7a6e0b1b-4517-4df7-a058-851a59b05d44"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[32m'O'\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[32m'B-MISC'\u001b[0m, \u001b[1;36m2\u001b[0m: \u001b[32m'I-MISC'\u001b[0m, \u001b[1;36m3\u001b[0m: \u001b[32m'B-PER'\u001b[0m, \u001b[1;36m4\u001b[0m: \u001b[32m'I-PER'\u001b[0m, \u001b[1;36m5\u001b[0m: \u001b[32m'B-ORG'\u001b[0m, \u001b[1;36m6\u001b[0m: \u001b[32m'I-ORG'\u001b[0m, \u001b[1;36m7\u001b[0m: \u001b[32m'B-LOC'\u001b[0m, \u001b[1;36m8\u001b[0m: \u001b[32m'I-LOC'\u001b[0m\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'O'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'B-MISC'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-MISC'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'B-PER'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-PER'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'B-ORG'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-ORG'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'B-LOC'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-LOC'</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(probabilities[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "UVfMlHzr9Ssj",
        "outputId": "63049e22-3b2a-4c63-a88c-1cf89fb77e97"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1;36m0.00028339651180431247\u001b[0m,\n",
              "    \u001b[1;36m2.604038490972016e-05\u001b[0m,\n",
              "    \u001b[1;36m7.13504123268649e-05\u001b[0m,\n",
              "    \u001b[1;36m1.6001637050067075e-05\u001b[0m,\n",
              "    \u001b[1;36m0.9980244636535645\u001b[0m,\n",
              "    \u001b[1;36m2.297280116181355e-05\u001b[0m,\n",
              "    \u001b[1;36m0.0003457609855104238\u001b[0m,\n",
              "    \u001b[1;36m2.0992732970626093e-05\u001b[0m,\n",
              "    \u001b[1;36m0.001188966678455472\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00028339651180431247</span>,\n",
              "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.604038490972016e-05</span>,\n",
              "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.13504123268649e-05</span>,\n",
              "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.6001637050067075e-05</span>,\n",
              "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9980244636535645</span>,\n",
              "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.297280116181355e-05</span>,\n",
              "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0003457609855104238</span>,\n",
              "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0992732970626093e-05</span>,\n",
              "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.001188966678455472</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# entity, score\n",
        "print((model.config.id2label[4], probabilities[4][4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "wyYVQTiw9sHv",
        "outputId": "e2ff9121-a37c-4cb4-af11-35ca225b934e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m(\u001b[0m\u001b[32m'I-PER'\u001b[0m, \u001b[1;36m0.9980244636535645\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'I-PER'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9980244636535645</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Note:\n",
        "\n",
        "```text\n",
        "- There are 9 labels:\n",
        "  - O is the label for the tokens that are not in any named entity (it stands for “outside”), and we then have two labels for each type of entity (miscellaneous, person, organization, and location).\n",
        "  - The label B-XXX indicates the token is at the beginning of an entity XXX and the label I-XXX indicates the token is inside the entity XXX. For instance, in the current example we would expect our model to classify the token `Chin` as B-PER (beginning of a person entity) and the tokens ##ei, and ##du as I-PER (inside a person entity).\n",
        "```"
      ],
      "metadata": {
        "id": "-MzN2QXM66Ia"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "xZSlJnCRfQLp",
        "outputId": "74d9d8ad-b7d8-429d-f8f9-b01bab383ac4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-PER'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9980244636535645\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m4\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Chin'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-PER'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9697666764259338\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'##ei'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-PER'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9929018616676331\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m6\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'##du'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-ORG'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9920702576637268\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Hu'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-ORG'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9937851428985596\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m12\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'##gging'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-ORG'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9924396276473999\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m13\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Face'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-LOC'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9217939376831055\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m15\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Brooklyn'\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-PER'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9980244636535645</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chin'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-PER'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9697666764259338</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'##ei'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-PER'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9929018616676331</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'##du'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-ORG'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9920702576637268</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Hu'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-ORG'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9937851428985596</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'##gging'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-ORG'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9924396276473999</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Face'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-LOC'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9217939376831055</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Brooklyn'</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# With this map, we are ready to reproduce (almost entirely) the results of the first pipeline\n",
        "# we can just grab the score and label of each token that was not classified as O:\n",
        "results: list[str] = []\n",
        "tokens: list[str] = inputs.tokens()\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    label = model.config.id2label[pred]\n",
        "    if label != \"O\": # label for tokens that's `outside`\n",
        "        results.append(\n",
        "            {\n",
        "                \"entity\": label, \"score\": probabilities[idx][pred],\n",
        "                \"index\":idx , \"word\": tokens[idx]\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To obtain the `start` and `end` of each entity in the original sentence,\n",
        "# add `return_offsets_mapping=True`.\n",
        "inputs_with_offsets: dict[str, Any] = tokenizer(example, return_offsets_mapping=True)\n",
        "inputs_with_offsets[\"offset_mapping\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP8wNjiF_MJP",
        "outputId": "ca1676d8-b529-404f-dda2-24621d509014"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0),\n",
              " (0, 2),\n",
              " (3, 7),\n",
              " (8, 10),\n",
              " (11, 15),\n",
              " (15, 17),\n",
              " (17, 19),\n",
              " (20, 23),\n",
              " (24, 25),\n",
              " (26, 30),\n",
              " (31, 33),\n",
              " (34, 36),\n",
              " (36, 41),\n",
              " (42, 46),\n",
              " (47, 49),\n",
              " (50, 58),\n",
              " (58, 59),\n",
              " (0, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJyFgZy4fQLp",
        "outputId": "99c18bd9-9482-4582-cab5-780d7a00e9d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('is', 'Chin')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "example[8:10], example[11:15]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the logic!\n",
        "results: list[str] = []\n",
        "tokens: list[str] = inputs.tokens()\n",
        "offsets:list[tuple[int]] = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    label = model.config.id2label[pred]\n",
        "    if label != \"O\": # label for tokens that's `outside`\n",
        "        start, end = offsets[idx]\n",
        "        results.append(\n",
        "            {\n",
        "                \"entity\": label, \"score\": probabilities[idx][pred],\n",
        "                \"index\":idx , \"word\": tokens[idx],\n",
        "                \"start\": start, \"end\": end,\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "FoqLX9FO_45k",
        "outputId": "10655781-a811-4f5f-eb09-7f3a1e0b9957"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-PER'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9980244636535645\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m4\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Chin'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m15\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-PER'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9697666764259338\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'##ei'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m15\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m17\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-PER'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9929018616676331\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m6\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'##du'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m17\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m19\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-ORG'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9920702576637268\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Hu'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m34\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m36\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-ORG'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9937851428985596\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m12\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'##gging'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m36\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m41\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-ORG'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9924396276473999\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m13\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Face'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m42\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m46\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-LOC'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9217939376831055\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m15\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Brooklyn'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m50\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m58\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-PER'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9980244636535645</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chin'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-PER'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9697666764259338</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'##ei'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-PER'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9929018616676331</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'##du'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-ORG'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9920702576637268</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Hu'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-ORG'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9937851428985596</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'##gging'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-ORG'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9924396276473999</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Face'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-LOC'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9217939376831055</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Brooklyn'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gTV19SlR_42r"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Grouping Entities\n",
        "\n",
        "```text\n",
        "\n",
        "- Using the offsets to determine the start and end keys for each entity is handy, but that information isn’t strictly necessary.\n",
        "- When we want to group the entities together, however, the offsets will save us a lot of messy code. e.g., if we wanted to group together the tokens Hu, ##gging, and Face, we could make special rules that say the first two should be attached while removing the ##, and the Face should be added with a space since it does not begin with ## — but that would only work for this particular type of tokenizer. We would have to write another set of rules for a SentencePiece or a Byte-Pair-Encoding tokenizer (discussed later in this chapter).\n",
        "\n",
        "- With the offsets, all that custom code goes away: we just can take the span in the original text that begins with the first token and ends with the last token. So, in the case of the tokens Hu, ##gging, and Face, we should start at character 33 (the beginning of Hu) and end before character 45 (the end of Face):\n",
        "```"
      ],
      "metadata": {
        "id": "Y50Jcf_UE6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example[34:46]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pKBe1T5v_4zt",
        "outputId": "01a178f8-2d51-47dd-add3-27c197ccfdde"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hugging Face'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To write the code that post-processes the predictions while grouping entities, we will group together\n",
        "# entities that are consecutive and labeled with I-XXX, except for the first one, which can be labeled as\n",
        "# B-XXX or I-XXX (so, we stop grouping an entity when we get a O, a new type of entity, or a B-XXX that\n",
        "# tells us an entity of the same type is starting):\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "results: list[str] = []\n",
        "inputs_with_offsets: dict[str, Any] = tokenizer(example, return_offsets_mapping=True)\n",
        "tokens: list[str] = inputs_with_offsets.tokens()\n",
        "offsets:list[tuple[int]] = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "idx: int = 0\n",
        "while idx < len(predictions):\n",
        "    pred = predictions[idx]\n",
        "    label = model.config.id2label[pred]\n",
        "    if label != \"O\":\n",
        "        # Remove the B- or I-\n",
        "        label = label[2:]\n",
        "        start, _ = offsets[idx]\n",
        "\n",
        "        # Grab all the tokens labeled with I-label\n",
        "        all_scores = []\n",
        "        while (\n",
        "            idx < len(predictions)\n",
        "            and model.config.id2label[predictions[idx]] == f\"I-{label}\"\n",
        "        ):\n",
        "            all_scores.append(probabilities[idx][pred])\n",
        "            _, end = offsets[idx]\n",
        "            idx += 1\n",
        "\n",
        "        # The score is the mean of all the scores of the tokens in that grouped entity\n",
        "        score = np.mean(all_scores).item()\n",
        "        word = example[start:end]\n",
        "        results.append(\n",
        "            {\n",
        "                \"entity_group\": label,\n",
        "                \"score\": score,\n",
        "                \"word\": word,\n",
        "                \"start\": start,\n",
        "                \"end\": end,\n",
        "            }\n",
        "        )\n",
        "    idx += 1\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "xNYQo2O1FUPS",
        "outputId": "4cc4b9ed-3c99-4db3-8bf8-8b7dbc394034"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity_group'\u001b[0m: \u001b[32m'PER'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9868976672490438\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Chineidu'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m19\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity_group'\u001b[0m: \u001b[32m'ORG'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9927650094032288\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Hugging Face'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m34\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m46\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'entity_group'\u001b[0m: \u001b[32m'LOC'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9217939376831055\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Brooklyn'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m50\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m58\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity_group'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PER'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9868976672490438</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chineidu'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity_group'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ORG'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9927650094032288</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Hugging Face'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity_group'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LOC'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9217939376831055</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Brooklyn'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rl_lSSmjFUII"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>\n",
        "\n",
        "### [Fast Tokenizers In THe QA Pipeline](https://huggingface.co/learn/nlp-course/chapter6/3b?fw=pt)"
      ],
      "metadata": {
        "id": "i8Vj9KqnHEfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "TASK: str = \"question-answering\"\n",
        "question_answerer:pipeline = pipeline(TASK)\n",
        "context: str = \"\"\"\n",
        "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch, and TensorFlow — with a seamless integration\n",
        "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\"\"\"\n",
        "question: str = \"Which deep learning libraries back 🤗 Transformers?\"\n",
        "question_answerer(question=question, context=context)"
      ],
      "metadata": {
        "id": "ttOxb1o6HV-p",
        "outputId": "b2a6eef4-aec3-4b97-bd2e-f9b3ce5c7768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9802603125572205,\n",
              " 'start': 78,\n",
              " 'end': 106,\n",
              " 'answer': 'Jax, PyTorch, and TensorFlow'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase the qs\n",
        "question: str = \"What packages power transformers behind the scenes?\"\n",
        "question_answerer(question=question, context=context)"
      ],
      "metadata": {
        "id": "e8wJFPMLHV8G",
        "outputId": "2629453d-badc-4254-b27c-5b5fc1b65f65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.8080288171768188,\n",
              " 'start': 78,\n",
              " 'end': 106,\n",
              " 'answer': 'Jax, PyTorch, and TensorFlow'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unlike the other pipelines, which can’t truncate and split texts that are longer than the maximum length\n",
        "# accepted by the model (and thus may miss information at the end of a document), this pipeline can deal with\n",
        "# very long contexts and will return the answer to the question even if it’s at the end:\n",
        "long_context: str = \"\"\"\n",
        "🤗 Transformers: State of the Art NLP\n",
        "\n",
        "🤗 Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,\n",
        "question answering, summarization, translation, text generation and more in over 100 languages.\n",
        "Its aim is to make cutting-edge NLP easier to use for everyone.\n",
        "\n",
        "🤗 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and\n",
        "then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and\n",
        "can be modified to enable quick research experiments.\n",
        "\n",
        "Why should I use transformers?\n",
        "\n",
        "1. Easy-to-use state-of-the-art models:\n",
        "  - High performance on NLU and NLG tasks.\n",
        "  - Low barrier to entry for educators and practitioners.\n",
        "  - Few user-facing abstractions with just three classes to learn.\n",
        "  - A unified API for using all our pretrained models.\n",
        "  - Lower compute costs, smaller carbon footprint:\n",
        "\n",
        "2. Researchers can share trained models instead of always retraining.\n",
        "  - Practitioners can reduce compute time and production costs.\n",
        "  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.\n",
        "\n",
        "3. Choose the right framework for every part of a model's lifetime:\n",
        "  - Train state-of-the-art models in 3 lines of code.\n",
        "  - Move a single model between TF2.0/PyTorch frameworks at will.\n",
        "  - Seamlessly pick the right framework for training, evaluation and production.\n",
        "\n",
        "4. Easily customize a model or an example to your needs:\n",
        "  - We provide examples for each architecture to reproduce the results published by its original authors.\n",
        "  - Model internals are exposed as consistently as possible.\n",
        "  - Model files can be used independently of the library for quick experiments.\n",
        "\n",
        "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration\n",
        "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\"\"\"\n",
        "question: str = \"Which deep learning libraries back 🤗 Transformers?\"\n",
        "\n",
        "question_answerer(question=question, context=long_context)"
      ],
      "metadata": {
        "id": "rnYGaO6BHV5a",
        "outputId": "d7292092-59aa-4dd1-9287-6780d6fcd73c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9714871048927307,\n",
              " 'start': 1892,\n",
              " 'end': 1919,\n",
              " 'answer': 'Jax, PyTorch and TensorFlow'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Breaking Down The QA Pipeline\n",
        "\n",
        "```text\n",
        "- We start by tokenizing our input and then send it through the model.\n",
        "- The checkpoint used by default for the question-answering pipeline is distilbert-base-cased-distilled-squad (the “squad” in the name comes from the dataset on which the model was fine-tuned; we’ll talk more about the SQuAD dataset in Chapter 7)\n",
        "```"
      ],
      "metadata": {
        "id": "fp7Zsa8GIoMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "\n",
        "model_checkpoint: str = \"distilbert-base-cased-distilled-squad\"\n",
        "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model: AutoModelForQuestionAnswering = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "\n",
        "inputs: dict[str, Any] = tokenizer(question, context, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "OCYpZfpFHV3R"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![image.png](https://i.postimg.cc/9XBkyMSp/image.png)](https://postimg.cc/nMCTJHnj)\n",
        "\n",
        "<br>\n",
        "\n",
        "```text\n",
        "- Models for question answering work a little differently from the models we’ve seen up to now.\n",
        "- Using the picture above as an example, the model has been trained to predict the index of the token starting the answer (here 21) and the index of the token where the answer ends (here 24).\n",
        "- This is why those models don’t return one tensor of logits but two: one for the logits corresponding to the start token of the answer, and one for the logits corresponding to the end token of the answer.\n",
        "- Since in this case we have only one input containing 66 tokens, we get:\n",
        "```"
      ],
      "metadata": {
        "id": "M6tInri-JfFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "start_logits: torch.Tensor = outputs.start_logits\n",
        "end_logits: torch.Tensor = outputs.end_logits\n",
        "\n",
        "print(start_logits.shape, end_logits.shape)"
      ],
      "metadata": {
        "id": "emfhcLAMHV0i",
        "outputId": "1dd93473-b5df-4b9f-a46d-0b3712e27c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m67\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m67\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span><span style=\"font-weight: bold\">])</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits"
      ],
      "metadata": {
        "id": "8qnN3SIWHVyr",
        "outputId": "1d7cfc00-ace6-4450-8518-4feeaa2f97de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.4952, -6.4454, -4.7115, -7.0968, -7.0726, -7.4981, -5.5397, -4.1368,\n",
              "         -5.9199, -5.4193, -1.5920, -1.0857, -5.0981, -2.9331, -3.4070,  2.2467,\n",
              "          5.1563, -1.3602, -2.2209, -0.9686, -4.8112, -2.2527,  1.4383, 10.1211,\n",
              "         -1.5311,  2.2685, -1.8951, -2.2108, -4.2142, -2.5571, -2.3252, -2.6046,\n",
              "          1.7047, -1.9867, -1.7211, -0.5415, -2.0239, -4.4246, -5.1012, -4.4966,\n",
              "         -7.8940, -6.7200, -4.6759, -6.3278, -4.8339, -5.1839, -3.3724, -7.4120,\n",
              "         -8.1542, -4.4871, -7.4659, -4.3293, -4.2293, -3.1903, -7.9467, -5.2665,\n",
              "         -7.5902, -5.0570, -7.4476, -7.9083, -6.5951, -7.4061, -8.8821, -7.6749,\n",
              "         -6.9879, -7.0466, -5.4193]], grad_fn=<CloneBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment\n",
        "\n",
        "```text\n",
        "- To convert those logits into probabilities, we will apply a softmax function — but before that, we need to make sure we mask the indices that are not part of the context. Our input is [CLS] question [SEP] context [SEP], so we need to mask the tokens of the question as well as the [SEP] token.\n",
        "- We’ll keep the [CLS] token, however, as some models use it to indicate that the answer is not in the context.\n",
        "\n",
        "- Since we will apply a softmax afterward, we just need to replace the logits we want to mask with a large negative number. Here, we use -10000:\n",
        "```"
      ],
      "metadata": {
        "id": "BYwUEmRQK-Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "sequence_ids: list[Optional[int]] = inputs.sequence_ids()\n",
        "\n",
        "# Mask everything apart from the tokens of the context\n",
        "mask: list[bool] = [i != 1 for i in sequence_ids]\n",
        "\n",
        "# Unmask the [CLS] token\n",
        "mask[0] = False\n",
        "mask = torch.tensor(mask)[None]\n",
        "\n",
        "# Replace the logits you want to mask with a large negative number. e.g. -10000\n",
        "start_logits[mask] = -10000\n",
        "end_logits[mask] = -10000"
      ],
      "metadata": {
        "id": "YtUQ3ci7HVvt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply softmax\n",
        "\n",
        "start_probabilities: torch.Tensor = F.softmax(start_logits, dim=-1)[0]\n",
        "end_probabilities: torch.Tensor = F.softmax(end_logits, dim=-1)[0]"
      ],
      "metadata": {
        "id": "deKpBjwhHVuB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_probabilities"
      ],
      "metadata": {
        "id": "VexpHcVTHVsD",
        "outputId": "4bff244b-e6f0-4769-efac-ec6045665ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.4531e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1185e-06, 1.3470e-05,\n",
              "        2.4368e-07, 2.1236e-06, 1.3220e-06, 3.7722e-04, 6.9219e-03, 1.0237e-05,\n",
              "        4.3289e-06, 1.5143e-05, 3.2463e-07, 4.1933e-06, 1.6808e-04, 9.9179e-01,\n",
              "        8.6288e-06, 3.8557e-04, 5.9956e-06, 4.3725e-06, 5.8977e-07, 3.0929e-06,\n",
              "        3.8999e-06, 2.9493e-06, 2.1940e-04, 5.4713e-06, 7.1354e-06, 2.3212e-05,\n",
              "        5.2711e-06, 4.7788e-07, 2.4291e-07, 4.4467e-07, 1.4879e-08, 4.8133e-08,\n",
              "        3.7169e-07, 7.1242e-08, 3.1735e-07, 2.2365e-07, 1.3685e-06, 2.4093e-08,\n",
              "        1.1470e-08, 4.4891e-07, 2.2828e-08, 5.2562e-07, 5.8092e-07, 1.6419e-06,\n",
              "        1.4114e-08, 2.0591e-07, 2.0161e-08, 2.5390e-07, 2.3251e-08, 1.4667e-08,\n",
              "        5.4533e-08, 2.4235e-08, 5.5390e-09, 1.8524e-08, 3.6818e-08, 3.4721e-08,\n",
              "        0.0000e+00], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First let’s compute all the possible products:\n",
        "scores: torch.Tensor = start_probabilities[:, None] * end_probabilities[None, :]"
      ],
      "metadata": {
        "id": "noaeumMnHVnL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then we’ll mask the values where start_index > end_index by setting them to 0\n",
        "# (the other probabilities are all positive numbers). The torch.triu() function\n",
        "# returns the upper triangular part of the 2D tensor passed as an argument, so it will do that masking for us:\n",
        "scores: torch.Tensor = torch.triu(scores)"
      ],
      "metadata": {
        "id": "466AMk3HHVko"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we just have to get the index of the maximum. Since PyTorch will return the index in the flattened\n",
        "# tensor, we need to use the floor division // and modulus % operations to get the start_index and end_index:\n",
        "max_index: int = scores.argmax().item()\n",
        "start_index: int = max_index // scores.shape[1]\n",
        "end_index: int = max_index % scores.shape[1]\n",
        "print(scores[start_index, end_index])"
      ],
      "metadata": {
        "id": "Ey8CZN8OHVh_",
        "outputId": "79ef559b-272d-4007-d2e8-2b75a723c930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.9803\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSelectBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9803</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SelectBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the start_index and end_index to the character indices in the context.\n",
        "# We can grab them using the offset_mapping:\n",
        "\n",
        "inputs_with_offsets: dict[str, Any] = tokenizer(question, context, return_offsets_mapping=True)\n",
        "offsets: list[tuple[int]] = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "start_char, _ = offsets[start_index]\n",
        "_, end_char = offsets[end_index]\n",
        "answer = context[start_char:end_char]"
      ],
      "metadata": {
        "id": "4caoolkZHVce"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result: dict[str, Any] = {\n",
        "    \"answer\": answer,\n",
        "    \"start\": start_char,\n",
        "    \"end\": end_char,\n",
        "    \"score\": scores[start_index, end_index],\n",
        "}\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "7l9U0U_VHVZ2",
        "outputId": "8ea9235b-a811-4e6c-ead8-4ddf6fa7bbfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Jax, PyTorch, and TensorFlow'\u001b[0m,\n",
              "    \u001b[32m'start'\u001b[0m: \u001b[1;36m78\u001b[0m,\n",
              "    \u001b[32m'end'\u001b[0m: \u001b[1;36m106\u001b[0m,\n",
              "    \u001b[32m'score'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.9803\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSelectBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Jax, PyTorch, and TensorFlow'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">106</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9803</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SelectBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ex: Try it out! Use the best scores you computed earlier to show the five most likely answers.\n",
        "# To check your results, go back to the first pipeline and pass in top_k=5 when calling it.\n",
        "long_context: str = \"\"\"\n",
        "🤗 Transformers: State of the Art NLP\n",
        "\n",
        "🤗 Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,\n",
        "question answering, summarization, translation, text generation and more in over 100 languages.\n",
        "Its aim is to make cutting-edge NLP easier to use for everyone.\n",
        "\n",
        "🤗 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and\n",
        "then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and\n",
        "can be modified to enable quick research experiments.\n",
        "\n",
        "Why should I use transformers?\n",
        "\n",
        "1. Easy-to-use state-of-the-art models:\n",
        "  - High performance on NLU and NLG tasks.\n",
        "  - Low barrier to entry for educators and practitioners.\n",
        "  - Few user-facing abstractions with just three classes to learn.\n",
        "  - A unified API for using all our pretrained models.\n",
        "  - Lower compute costs, smaller carbon footprint:\n",
        "\n",
        "2. Researchers can share trained models instead of always retraining.\n",
        "  - Practitioners can reduce compute time and production costs.\n",
        "  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.\n",
        "\n",
        "3. Choose the right framework for every part of a model's lifetime:\n",
        "  - Train state-of-the-art models in 3 lines of code.\n",
        "  - Move a single model between TF2.0/PyTorch frameworks at will.\n",
        "  - Seamlessly pick the right framework for training, evaluation and production.\n",
        "\n",
        "4. Easily customize a model or an example to your needs:\n",
        "  - We provide examples for each architecture to reproduce the results published by its original authors.\n",
        "  - Model internals are exposed as consistently as possible.\n",
        "  - Model files can be used independently of the library for quick experiments.\n",
        "\n",
        "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration\n",
        "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\"\"\"\n",
        "question: str = \"Which deep learning libraries back 🤗 Transformers?\"\n",
        "\n",
        "question_answerer(question=question, context=long_context, top_k=5)"
      ],
      "metadata": {
        "id": "JXqTq0NyOABB",
        "outputId": "c0a6356f-5c0d-4327-db42-7692a4a9a211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9714871048927307,\n",
              "  'start': 1892,\n",
              "  'end': 1919,\n",
              "  'answer': 'Jax, PyTorch and TensorFlow'},\n",
              " {'score': 0.14949701726436615,\n",
              "  'start': 17,\n",
              "  'end': 37,\n",
              "  'answer': 'State of the Art NLP'},\n",
              " {'score': 0.015565173700451851,\n",
              "  'start': 1892,\n",
              "  'end': 1921,\n",
              "  'answer': 'Jax, PyTorch and TensorFlow —'},\n",
              " {'score': 0.01370556652545929, 'start': 34, 'end': 37, 'answer': 'NLP'},\n",
              " {'score': 0.010596856474876404,\n",
              "  'start': 3,\n",
              "  'end': 37,\n",
              "  'answer': 'Transformers: State of the Art NLP'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "### Handling long contexts\n",
        "\n",
        "```text\n",
        "If we try to tokenize the question and long context we used as an example previously, we’ll get a number of tokens higher than the maximum length used in the question-answering pipeline (which is 384):\n",
        "```"
      ],
      "metadata": {
        "id": "Pvvcw1gwOmOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs: dict[str, Any] = tokenizer(question, long_context)\n",
        "\n",
        "print(len(inputs[\"input_ids\"]))"
      ],
      "metadata": {
        "id": "z2gDOswDN_-W",
        "outputId": "e04eb3b5-1efc-4e58-d147-c72c6979c0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m461\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">461</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To address the issue of exceeding the maximum input length, we can truncate the context while\n",
        "# keeping the question intact using the \"only_second\" truncation strategy. However, this approach\n",
        "# may lead to the omission of the answer in the truncated context.\n",
        "\n",
        "inputs: dict[str, Any] = tokenizer(question, long_context, max_length=384, truncation=\"only_second\")\n",
        "print(tokenizer.decode(inputs[\"input_ids\"]))"
      ],
      "metadata": {
        "id": "dnH1WU20N_5Z",
        "outputId": "e43d8a10-26a9-479b-fb37-09e73dcfdaae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mCLS\u001b[1m]\u001b[0m Which deep learning libraries back \u001b[1m[\u001b[0mUNK\u001b[1m]\u001b[0m Transformers? \u001b[1m[\u001b[0mSEP\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mUNK\u001b[1m]\u001b[0m Transformers : State of the Art NLP \u001b[1m[\u001b[0mUNK\u001b[1m]\u001b[0m \n",
              "Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information \n",
              "extraction, question answering, summarization, translation, text generation and more in over \u001b[1;36m100\u001b[0m languages. Its aim\n",
              "is to make cutting - edge NLP easier to use for everyone. \u001b[1m[\u001b[0mUNK\u001b[1m]\u001b[0m Transformers provides APIs to quickly download and \n",
              "use those pretrained models on a given text, fine - tune them on your own datasets and then share them with the \n",
              "community on our model hub. At the same time, each python module defining an architecture is fully standalone and \n",
              "can be modified to enable quick research experiments. Why should I use transformers? \u001b[1;36m1\u001b[0m. Easy - to - use state - of \n",
              "- the - art models : - High performance on NLU and NLG tasks. - Low barrier to entry for educators and \n",
              "practitioners. - Few user - facing abstractions with just three classes to learn. - A unified API for using all our\n",
              "pretrained models. - Lower compute costs, smaller carbon footprint : \u001b[1;36m2\u001b[0m. Researchers can share trained models \n",
              "instead of always retraining. - Practitioners can reduce compute time and production costs. - Dozens of \n",
              "architectures with over \u001b[1;36m10\u001b[0m, \u001b[1;36m000\u001b[0m pretrained models, some in more than \u001b[1;36m100\u001b[0m languages. \u001b[1;36m3\u001b[0m. Choose the right framework \n",
              "for every part of a model's lifetime : - Train state - of - the - art models in \u001b[1;36m3\u001b[0m lines of code. - Move a single \n",
              "model between TF2. \u001b[1;36m0\u001b[0m \u001b[35m/\u001b[0m PyTorch frameworks at will. - Seamlessly pick the right framework for training, evaluation \n",
              "and production. \u001b[1;36m4\u001b[0m. Easily customize a model or an example to your needs : - We provide examples for each \n",
              "architecture to reproduce the results published by its original authors. - Model internal \u001b[1m[\u001b[0mSEP\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CLS<span style=\"font-weight: bold\">]</span> Which deep learning libraries back <span style=\"font-weight: bold\">[</span>UNK<span style=\"font-weight: bold\">]</span> Transformers? <span style=\"font-weight: bold\">[</span>SEP<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>UNK<span style=\"font-weight: bold\">]</span> Transformers : State of the Art NLP <span style=\"font-weight: bold\">[</span>UNK<span style=\"font-weight: bold\">]</span> \n",
              "Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information \n",
              "extraction, question answering, summarization, translation, text generation and more in over <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> languages. Its aim\n",
              "is to make cutting - edge NLP easier to use for everyone. <span style=\"font-weight: bold\">[</span>UNK<span style=\"font-weight: bold\">]</span> Transformers provides APIs to quickly download and \n",
              "use those pretrained models on a given text, fine - tune them on your own datasets and then share them with the \n",
              "community on our model hub. At the same time, each python module defining an architecture is fully standalone and \n",
              "can be modified to enable quick research experiments. Why should I use transformers? <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Easy - to - use state - of \n",
              "- the - art models : - High performance on NLU and NLG tasks. - Low barrier to entry for educators and \n",
              "practitioners. - Few user - facing abstractions with just three classes to learn. - A unified API for using all our\n",
              "pretrained models. - Lower compute costs, smaller carbon footprint : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Researchers can share trained models \n",
              "instead of always retraining. - Practitioners can reduce compute time and production costs. - Dozens of \n",
              "architectures with over <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> pretrained models, some in more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> languages. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Choose the right framework \n",
              "for every part of a model's lifetime : - Train state - of - the - art models in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> lines of code. - Move a single \n",
              "model between TF2. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> PyTorch frameworks at will. - Seamlessly pick the right framework for training, evaluation \n",
              "and production. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Easily customize a model or an example to your needs : - We provide examples for each \n",
              "architecture to reproduce the results published by its original authors. - Model internal <span style=\"font-weight: bold\">[</span>SEP<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This means the model will have a hard time picking the correct answer. To fix this, the question-answering pipeline allows\n",
        "# us to split the context into smaller chunks, specifying the maximum length. To make sure we don’t split the context at exactly\n",
        "# the wrong place to make it possible to find the answer, it also includes some overlap between the chunks.\n",
        "# We can have the tokenizer (fast or slow) do this for us by adding return_overflowing_tokens=True, and we can specify the overlap\n",
        "# we want with the stride argument. Here is an example, using a smaller sentence:\n",
        "sentence: str = \"This sentence is not too long but we are going to split it anyway.\"\n",
        "inputs: dict[str, Any] = tokenizer(\n",
        "    sentence, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2\n",
        ")\n",
        "\n",
        "\n",
        "for ids in inputs[\"input_ids\"]:\n",
        "    print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "id": "l5Jr4bxERM0M",
        "outputId": "ca2daaec-3be2-46c8-99bf-9ca84c4ca745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mCLS\u001b[1m]\u001b[0m This sentence is not \u001b[1m[\u001b[0mSEP\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CLS<span style=\"font-weight: bold\">]</span> This sentence is not <span style=\"font-weight: bold\">[</span>SEP<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mCLS\u001b[1m]\u001b[0m is not too long \u001b[1m[\u001b[0mSEP\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CLS<span style=\"font-weight: bold\">]</span> is not too long <span style=\"font-weight: bold\">[</span>SEP<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mCLS\u001b[1m]\u001b[0m too long but we \u001b[1m[\u001b[0mSEP\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CLS<span style=\"font-weight: bold\">]</span> too long but we <span style=\"font-weight: bold\">[</span>SEP<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mCLS\u001b[1m]\u001b[0m but we are going \u001b[1m[\u001b[0mSEP\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CLS<span style=\"font-weight: bold\">]</span> but we are going <span style=\"font-weight: bold\">[</span>SEP<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mCLS\u001b[1m]\u001b[0m are going to split \u001b[1m[\u001b[0mSEP\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CLS<span style=\"font-weight: bold\">]</span> are going to split <span style=\"font-weight: bold\">[</span>SEP<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mCLS\u001b[1m]\u001b[0m to split it anyway \u001b[1m[\u001b[0mSEP\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CLS<span style=\"font-weight: bold\">]</span> to split it anyway <span style=\"font-weight: bold\">[</span>SEP<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mCLS\u001b[1m]\u001b[0m it anyway. \u001b[1m[\u001b[0mSEP\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CLS<span style=\"font-weight: bold\">]</span> it anyway. <span style=\"font-weight: bold\">[</span>SEP<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment\n",
        "\n",
        "```text\n",
        "- As we can see, the sentence has been split into chunks in such a way that each entry in inputs[\"input_ids\"] has at most 6 tokens (we would need to add padding to have the last entry be the same size as the others) and there is an overlap of 2 tokens between each of the entries.\n",
        "\n",
        "- Let’s take a closer look at the result of the tokenization:\n",
        "```"
      ],
      "metadata": {
        "id": "FXfwJsm_R1-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.keys())"
      ],
      "metadata": {
        "id": "Np8q7-p6RMsm",
        "outputId": "85c96dd2-e84d-492d-8ab8-019bca4c5799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mdict_keys\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'input_ids'\u001b[0m, \u001b[32m'attention_mask'\u001b[0m, \u001b[32m'overflow_to_sample_mapping'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">dict_keys</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'overflow_to_sample_mapping'</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As expected, we get input IDs and an attention mask. The last key, overflow_to_sample_mapping, is a map that tells us which sentence each\n",
        "# of the results corresponds to — here we have 7 results that all come from the (only) sentence we passed the tokenizer:\n",
        "print(inputs[\"overflow_to_sample_mapping\"])"
      ],
      "metadata": {
        "id": "idO5B29pPwSb",
        "outputId": "3ade04fa-4d33-462b-9143-20ed3844eaee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is more useful when we tokenize several sentences together. For instance, this:\n",
        "sentences: list[str] = [\n",
        "    \"This sentence is not too long but we are going to split it anyway.\",\n",
        "    \"This sentence is shorter but will still get split.\",\n",
        "]\n",
        "inputs: dict[str, Any] = tokenizer(\n",
        "    sentences, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "rUmT98tKPwP0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This means that the 1st sentence is split into 7 chunks as before, and the next 4 chunks come from the second sentence.\n",
        "print(inputs[\"overflow_to_sample_mapping\"])"
      ],
      "metadata": {
        "id": "ev_HW1ZTN_2t",
        "outputId": "c72ba729-2aa6-49e6-caa6-559403aabe97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs)"
      ],
      "metadata": {
        "id": "ibGaY6LZHVXX",
        "outputId": "a60b2b6c-e29d-4573-b727-ea24745aebae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'input_ids'\u001b[0m: \u001b[1m[\u001b[0m\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1188\u001b[0m, \u001b[1;36m5650\u001b[0m, \u001b[1;36m1110\u001b[0m, \u001b[1;36m1136\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1110\u001b[0m, \u001b[1;36m1136\u001b[0m, \u001b[1;36m1315\u001b[0m, \u001b[1;36m1263\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1315\u001b[0m, \u001b[1;36m1263\u001b[0m, \u001b[1;36m1133\u001b[0m, \u001b[1;36m1195\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1133\u001b[0m, \u001b[1;36m1195\u001b[0m, \u001b[1;36m1132\u001b[0m, \u001b[1;36m1280\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1132\u001b[0m, \u001b[1;36m1280\u001b[0m, \u001b[1;36m1106\u001b[0m, \u001b[1;36m3325\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1106\u001b[0m, \u001b[1;36m3325\u001b[0m, \u001b[1;36m1122\u001b[0m, \u001b[1;36m4050\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1122\u001b[0m, \u001b[1;36m4050\u001b[0m, \u001b[1;36m119\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1188\u001b[0m, \u001b[1;36m5650\u001b[0m, \u001b[1;36m1110\u001b[0m, \u001b[1;36m7681\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1110\u001b[0m, \u001b[1;36m7681\u001b[0m, \u001b[1;36m1133\u001b[0m, \u001b[1;36m1209\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1133\u001b[0m, \u001b[1;36m1209\u001b[0m, \u001b[1;36m1253\u001b[0m, \u001b[1;36m1243\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m1253\u001b[0m, \u001b[1;36m1243\u001b[0m, \u001b[1;36m3325\u001b[0m, \u001b[1;36m119\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[32m'attention_mask'\u001b[0m: \u001b[1m[\u001b[0m\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[32m'overflow_to_sample_mapping'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span>: <span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1188</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5650</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1136</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1136</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1315</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1263</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1315</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1263</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1133</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1195</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1133</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1195</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1132</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1280</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1132</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1280</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1106</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3325</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1106</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3325</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1122</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4050</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1122</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4050</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1188</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5650</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7681</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7681</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1133</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1209</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1133</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1209</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1253</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1243</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1253</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1243</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3325</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask'</span>: <span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'overflow_to_sample_mapping'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When tokenizing the long context, the question-answering pipeline follows a default maximum length of 384 and\n",
        "# a stride of 128, aligned with the model's fine-tuning. Padding and offset information will also be included.\n",
        "inputs: dict[str, Any] = tokenizer(\n",
        "    question,\n",
        "    long_context,\n",
        "    stride=128,\n",
        "    max_length=384,\n",
        "    padding=\"longest\",\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        ")"
      ],
      "metadata": {
        "id": "liLR2w-lUUg3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The inputs contain the input IDs and attention masks the model expects.\n",
        "# Pop the offsets and the overflow_to_sample_mapping out of the inputs before converting it to a tensor:\n",
        "\n",
        "_ = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "offsets = inputs.pop(\"offset_mapping\")\n",
        "\n",
        "inputs: dict[str, Any] = inputs.convert_to_tensors(\"pt\")\n",
        "print(inputs[\"input_ids\"].shape)"
      ],
      "metadata": {
        "id": "AJp0WxRFUUdH",
        "outputId": "23ee0399-f038-4591-bab2-1962168a21cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our long context was split in two, which means that after it goes through our model, we will have two sets of start and end logits:\n",
        "outputs = model(**inputs)\n",
        "\n",
        "start_logits: torch.Tensor = outputs.start_logits\n",
        "end_logits: torch.Tensor = outputs.end_logits\n",
        "print(start_logits.shape, end_logits.shape)"
      ],
      "metadata": {
        "id": "244I4pmPWBrJ",
        "outputId": "947a5df4-3b80-4728-8df2-1d72b525d12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask the tokens that are not part of the context before taking the softmax.\n",
        "# Mask also all the padding tokens (as flagged by the attention mask):\n",
        "sequence_ids: list[Optional[int]] = inputs.sequence_ids()\n",
        "# Mask everything apart from the tokens of the context\n",
        "mask: list[bool] = [i != 1 for i in sequence_ids]\n",
        "# Unmask the [CLS] token\n",
        "mask[0] = False\n",
        "# Mask all the [PAD] tokens\n",
        "mask = torch.logical_or(torch.tensor(mask)[None], (inputs[\"attention_mask\"] == 0))\n",
        "\n",
        "start_logits[mask] = -10000\n",
        "end_logits[mask] = -10000"
      ],
      "metadata": {
        "id": "3U6tc-WhFUFP"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the logits to probabilities:\n",
        "start_probabilities: torch.Tensor = F.softmax(start_logits, dim=-1)\n",
        "end_probabilities: torch.Tensor = F.softmax(end_logits, dim=-1)"
      ],
      "metadata": {
        "id": "4gzoE3FlWpaf"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For each of the two chunks, we assign scores to all potential answer spans and select the one with the highest score.\n",
        "\n",
        "candidates: list[tuple[float]] = []\n",
        "for start_probs, end_probs in zip(start_probabilities, end_probabilities):\n",
        "    scores: torch.Tensor = start_probs[:, None] * end_probs[None, :]\n",
        "    idx: int = torch.triu(scores).argmax().item()\n",
        "\n",
        "    start_idx: int = idx // scores.shape[1]\n",
        "    end_idx: int = idx % scores.shape[1]\n",
        "    score: float = scores[start_idx, end_idx].item()\n",
        "    candidates.append((start_idx, end_idx, score))\n",
        "\n",
        "print(candidates)"
      ],
      "metadata": {
        "id": "OEcYylDRWpYI",
        "outputId": "e2a47f2c-f1df-4ac2-aa4a-29453ed6c620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m18\u001b[0m, \u001b[1;36m0.3386707305908203\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m173\u001b[0m, \u001b[1;36m184\u001b[0m, \u001b[1;36m0.9714868664741516\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3386707305908203</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">173</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">184</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9714868664741516</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for candidate, offset in zip(candidates, offsets):\n",
        "    start_token, end_token, score = candidate\n",
        "    start_char, _ = offset[start_token]\n",
        "    _, end_char = offset[end_token]\n",
        "    answer: str = long_context[start_char:end_char]\n",
        "    result: dict[str, Any] = {\"answer\": answer, \"start\": start_char, \"end\": end_char, \"score\": score}\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "mOYeoOCJWpT3",
        "outputId": "3254775f-cc23-4596-b922-68324968accd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\u001b[32m'answer'\u001b[0m: \u001b[32m'\\n🤗 Transformers: State of the Art NLP'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m37\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.3386707305908203\u001b[0m\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\n🤗 Transformers: State of the Art NLP'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3386707305908203</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\u001b[32m'answer'\u001b[0m: \u001b[32m'Jax, PyTorch and TensorFlow'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m1892\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m1919\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9714868664741516\u001b[0m\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Jax, PyTorch and TensorFlow'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1892</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1919</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9714868664741516</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Br74hDpTWpRJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "l_xdwgDffQLq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}