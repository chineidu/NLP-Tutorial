{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# Built-in library\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "from typing import Union, Optional, Any\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_data(*, filepath: Path, label: int) -> pd.DataFrame:\n",
    "    \"\"\"This loads the text data, assigns a label and returns a DF.\"\"\"\n",
    "    with open(filepath, \"r\") as file:\n",
    "        # Remove empty lines: using len(line) > 5\n",
    "        data = [(line.strip(), label) for line in file.readlines() if len(line) > 5]\n",
    "    # Convert to DF\n",
    "    df = pd.DataFrame(data=data, columns=[\"text\", \"label\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_punctuations(text: str) -> str:\n",
    "    import string\n",
    "\n",
    "    \"\"\"This returns the text without punctuations\"\"\"\n",
    "    cleaned_text = re.compile(pattern=f\"[{re.escape(string.punctuation)}]\").sub(\n",
    "        repl=\"\", string=str(text)\n",
    "    )\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LO! Death hath rear'd himself a throne</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a strange city, all alone,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Far down within the dim west</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where the good, and the bad, and the worst, and the best,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have gone to their eternal rest.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  label\n",
       "0                     LO! Death hath rear'd himself a throne      0\n",
       "1                              In a strange city, all alone,      0\n",
       "2                               Far down within the dim west      0\n",
       "3  Where the good, and the bad, and the worst, and the best,      0\n",
       "4                           Have gone to their eternal rest.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = \"edgar_allan_poe.txt\"\n",
    "fp1 = \"robert_frost.txt\"\n",
    "label_0, label_1 = 0, 1\n",
    "\n",
    "edgar_allan_poe = extract_text_data(filepath=fp, label=label_0)\n",
    "robert_frost = extract_text_data(filepath=fp1, label=label_1)\n",
    "\n",
    "edgar_allan_poe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two roads diverged in a yellow wood,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And sorry I could not travel both</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And be one traveler, long I stood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And looked down one as far as I could</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To where it bent in the undergrowth;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  label\n",
       "0   Two roads diverged in a yellow wood,      1\n",
       "1      And sorry I could not travel both      1\n",
       "2      And be one traveler, long I stood      1\n",
       "3  And looked down one as far as I could      1\n",
       "4   To where it bent in the undergrowth;      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robert_frost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>Not bluebells gracing a tunnel mouth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>Of door and headboard Where it wants to get</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Hath ever told or is it of a thought</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>To the Lethean peace of the skies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Then desolately fall</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>That from new fountains overflow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>Whats this</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Of its own fervour  what had oer it power</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>The way a man with one leg and a crutch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>How shall we</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text  label\n",
       "1703         Not bluebells gracing a tunnel mouth      1\n",
       "1275  Of door and headboard Where it wants to get      1\n",
       "294          Hath ever told or is it of a thought      0\n",
       "551             To the Lethean peace of the skies      0\n",
       "426                          Then desolately fall      0\n",
       "662              That from new fountains overflow      0\n",
       "2055                                   Whats this      1\n",
       "611     Of its own fervour  what had oer it power      0\n",
       "1303      The way a man with one leg and a crutch      1\n",
       "1641                                 How shall we      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the data\n",
    "\n",
    "RANDOM_STATE = 2\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "data = pd.concat([edgar_allan_poe, robert_frost], axis=\"rows\").reset_index(drop=True)\n",
    "# Remove punctuations\n",
    "data = data.assign(text=data[\"text\"].apply(remove_punctuations))\n",
    "\n",
    "data.sample(n=10, random_state=RANDOM_STATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split The Data Into Train And Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text\"]\n",
    "y = data[\"label\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    \"\"\"This is the blueprint used for building ML models.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"This is the string representation of the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def fit(\n",
    "        self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series]\n",
    "    ) -> None:\n",
    "        \"\"\"This is used to train the model.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series]\n",
    "    ) -> None:\n",
    "        \"\"\"This is used to make predictions using new data.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     LO Death hath reard himself a throne\n",
       "1                              In a strange city all alone\n",
       "2                             Far down within the dim west\n",
       "3    Where the good and the bad and the worst and the best\n",
       "4                          Have gone to their eternal rest\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Nomial Naive Bayes\n",
    "\n",
    "* **Transition Matrix** $\\mathbf{A_{ij}}$: This is the probability of a state, `t`, given a previous state, `t-1`. This is a matrix (2-D array).\n",
    "  \n",
    "$$\n",
    "\\mathbf{A_{ij}} = p(s_{t} = j | s_{t-1} = i)\n",
    "$$\n",
    "\n",
    "* Predicted/Estimate Transition Matrix\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{A}_{ij}} = \\frac{count(i \\rightarrow j)}{count(i)}\n",
    "$$\n",
    "\n",
    "* **Initial State Distribution** $\\mathbf{\\pi_{i}} $: This is the probability of an initial state in a sequence. This is a vector (1-D array).\n",
    "\n",
    "$$\n",
    "\\mathbf{\\pi_{i}} = p(s_{1} = i)\n",
    "$$\n",
    "\n",
    "* Estimated Initial State Distribution\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{\\pi_{i}}} = \\frac{count(s_{1} = i)}{N}\n",
    "$$\n",
    "\n",
    "\n",
    "```text\n",
    "where\n",
    "N = Number of sequences.\n",
    "```\n",
    "\n",
    "$$\n",
    "\\mathbf{p(y|X)} = \\frac{p(X|y).p(y)}{p(X)}\n",
    "$$\n",
    "\n",
    "```text\n",
    "where\n",
    "p(y|X) = Posterior probability\n",
    "p(X|y) = Class conditional probability or likelihood\n",
    "p(y) = Prior probability of y\n",
    "p(X) = Marginal probability of X\n",
    "```\n",
    "\n",
    "* Since $p(X)$ does not depend on `y`, we can ignore it.\n",
    "\n",
    "$$\n",
    "\\mathbf{p(y|X)} = {p(X|y).p(y)}\n",
    "$$\n",
    "\n",
    "* If we have `n` features, it becomes:\n",
    "\n",
    "$$\n",
    "\\mathbf{p(y|X)} = {p(x_{1}|y).p(x_{2}|y)...p(x_{n}|y).p(y)}\n",
    "$$\n",
    "\n",
    "* Taking the log, we have:\n",
    "\n",
    "$$\n",
    "\\mathbf{p(y|X)} = {log(p(x_{1}|y))+log(p(x_{2}|y))+...+log(p(x_{n}|y))+log(p(y)})\n",
    "$$\n",
    "\n",
    "\n",
    "**Note**: $\\hat{A}_{ij}$ and $\\hat{\\pi_{i}}$ will be used to model the `class conditional probability`.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Steps Required To Build The Model From Scratch\n",
    "\n",
    "### Training:\n",
    "\n",
    "1. Determine the vocabulary and tokenize the documents.\n",
    "2. Initialize the parameters: $\\hat{A}_{ij}$, $\\hat{\\pi_{i}}$, and $p(y)$ for each class label. \\\n",
    "i.e we need to initialize two variables per parameters since we have two class labels. e.g.  $\\hat{A}0_{ij}$,  $\\hat{A}1_{ij}$, etc.\n",
    "3. Compute the count of A and Pi. i.e A_hat and Pi_hat.\n",
    "4. Calculate the log probabilities of A_hat and Pi_hat.\n",
    "5. \n",
    "\n",
    "### Making Predictions\n",
    "\n",
    "$$\n",
    "\\mathbf{p(y|X)} = argmax({log(p(x_{1}|y))+log(p(x_{2}|y))+...+log(p(x_{n}|y))+log(p(y)}))\n",
    "$$\n",
    "\n",
    "1. Calculate the posteriors. i.e for the classes.\n",
    "2. Find `y` by calculating the `argmax` of the class given the input over all classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiNomial_NB(BaseModel):\n",
    "    def __init__(self) -> None:\n",
    "        self.transition_matrix = None\n",
    "        self.initial_state_distr = None\n",
    "        self.priors = None\n",
    "        self.vocab = {\"unk\": 0}\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{__class__.__name__}()\"\n",
    "\n",
    "    def fit(\n",
    "        self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series]\n",
    "    ) -> None:\n",
    "        return self\n",
    "\n",
    "    def _init_params(\n",
    "        self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series]\n",
    "    ):\n",
    "        \"\"\"This is used to initialize the training parameters.\"\"\"\n",
    "        A_0, Pi_0 = MultiNomial_NB._init_A_and_Pi(X=X)\n",
    "        A_1, Pi_1 = MultiNomial_NB._init_A_and_Pi(X=X)\n",
    "        log_y1, log_y2 = MultiNomial_NB._log_priors(y=y)\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_A_and_Pi(*, X: Union[np.ndarray, pd.Series]) -> tuple:\n",
    "        \"\"\"This is used to initialize the state transition matrix\n",
    "        and the initial state distribution.\"\"\"\n",
    "        vocab = MultiNomial_NB._get_vacabulary(documents=X)\n",
    "        V = len(vocab)\n",
    "        # Add add-one smoothering\n",
    "        # A is a matrix and Pi is a vector\n",
    "        A = np.ones(shape=(V, V), dtype=float)\n",
    "        Pi = np.ones(shape=(V), dtype=float)\n",
    "        return (A, Pi)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_vacabulary(*, documents: pd.Series) -> dict:\n",
    "        \"\"\"This is used to create the vocabulary of the corpus.\"\"\"\n",
    "        # Create a dict that'll be used to store unique words and their integer\n",
    "        # mappings as key-value pairs. Add a custom token `unk` with a value of 0\n",
    "        # which will be used for tokens that are not present in the training data.\n",
    "        vocab = {\"unk\": 0}\n",
    "        count = 1\n",
    "\n",
    "        for doc in documents:\n",
    "            # Tokenize the document\n",
    "            tokenized_doc = [x.lower() for x in doc.split()]\n",
    "            for term in tokenized_doc:\n",
    "                if term not in vocab:\n",
    "                    vocab[term] = count\n",
    "                    count += 1\n",
    "        return vocab\n",
    "\n",
    "    @staticmethod\n",
    "    def _tokenize_document(*, X: Union[np.ndarray, pd.Series]) -> list[int]:\n",
    "        \"\"\"This is used to tokenize the documents.\n",
    "        It returns the tokenized documents as list of integers.\"\"\"\n",
    "        tokenized_documents = []\n",
    "        vocab = MultiNomial_NB._get_vacabulary(documents=X)\n",
    "        for doc in X:\n",
    "            # Tokenize the document\n",
    "            tokenized_doc = [x.lower() for x in doc.split()]\n",
    "            # Get the integer values of the tokens\n",
    "            tokenized_doc = [vocab.get(term) for term in tokenized_doc]\n",
    "            tokenized_documents.append(tokenized_doc)\n",
    "\n",
    "        return tokenized_documents\n",
    "\n",
    "    @staticmethod\n",
    "    def _log_priors(*, y: np.ndarray) -> list[float]:\n",
    "        \"\"\"This returns the log priors of y.\n",
    "\n",
    "        Returns:\n",
    "            log_probs: A list containing the log probabilities\n",
    "            of the class labels.\n",
    "        \"\"\"\n",
    "        # Get the counts; calculate the log probabilities\n",
    "        # using the probabilities obtained from the counts.\n",
    "        counts = np.bincount(y)\n",
    "        probs = counts / len(y)\n",
    "        log_probs = [(np.log(p_i)) for p_i in probs if p_i > 0]\n",
    "        return log_probs\n",
    "\n",
    "    @staticmethod\n",
    "    def _count_state_transitions(\n",
    "        *, X: Union[np.ndarray, pd.Series]\n",
    "    ) -> tuple[np.ndarray]:\n",
    "        \"\"\"This is used to count the occurrences of transitions.\n",
    "        i.e calculate the counts of A_hat and Pi_hat.\n",
    "\n",
    "        Returns:\n",
    "            (A_hat, Pi_hat)\n",
    "        \"\"\"\n",
    "        # Init params\n",
    "        A_hat, Pi_hat = MultiNomial_NB._init_A_and_Pi(X=X)\n",
    "\n",
    "        # To calculate the Pi_hat, we need to count the number of times\n",
    "        # the initial state was `i` divided by the number of state sequences.\n",
    "        # Pi_hat = (count(state = i) / N)\n",
    "        # A_hat: count of the number of times we transitioned from the prev state `i`\n",
    "        # to the current state `j` divided by the count of the prev state `i`.\n",
    "        # i.e. A_hat = ( count(state_i to state_j) / (count(state_i)) )\n",
    "        tokenized_documents = MultiNomial_NB._tokenize_document(X=X)\n",
    "        for tokenized_doc in tokenized_documents:\n",
    "            prev_token = None\n",
    "            for token in tokenized_doc:\n",
    "                if prev_token is None:\n",
    "                    Pi_hat[token] += 1\n",
    "                else:\n",
    "                    A_hat[prev_token, token]\n",
    "        return (A_hat, Pi_hat)\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_log_likelihoods(\n",
    "        *, X: Union[np.ndarray, pd.Series]\n",
    "    ) -> tuple[np.ndarray]:\n",
    "        \"\"\"This is used to calculate the log of the class conditional\n",
    "        probability given a specific class label.\n",
    "\n",
    "        Returns:\n",
    "            (log(A_hat), log(Pi_hat))\n",
    "        \"\"\"\n",
    "        A_hat, Pi_hat = MultiNomial_NB._count_state_transitions(X=X)\n",
    "        # Calculate the probabilities\n",
    "        A_hat /= A_hat.sum(axis=1, keepdims=True)  # OR A_hat/ A_hat.shape[0]\n",
    "        Pi_hat /= Pi_hat.sum(axis=0)\n",
    "        return (np.log(A_hat), np.log(Pi_hat))\n",
    "\n",
    "    def predict(\n",
    "        self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series]\n",
    "    ) -> None:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiNomial_NB()"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_nb = MultiNomial_NB()\n",
    "m_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>And yet it need not be that object hid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>Had checked the pace</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>The rare and radiant flowers of song</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>And that has made all the difference</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>The upper shelf the tin box Thats the one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text  label\n",
       "301      And yet it need not be that object hid      0\n",
       "1826                       Had checked the pace      1\n",
       "669        The rare and radiant flowers of song      0\n",
       "737        And that has made all the difference      1\n",
       "2053  The upper shelf the tin box Thats the one      1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.sample(n=20, random_state=1).copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.45532112, -3.15273602, -4.76217393, -4.06902675, -4.76217393,\n",
       "       -4.35670883, -4.35670883, -4.06902675, -4.76217393, -4.76217393,\n",
       "       -4.06902675, -4.76217393, -2.97041447, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -3.8458832 , -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.06902675, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.06902675,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.35670883, -4.76217393, -4.76217393, -4.35670883, -3.8458832 ,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.35670883,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.35670883, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.35670883,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_hat, Pi_hat = m_nb._calculate_log_likelihoods(X=df[\"text\"])\n",
    "\n",
    "Pi_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.45532112, -3.15273602, -4.76217393, -4.06902675, -4.76217393,\n",
       "       -4.35670883, -4.35670883, -4.06902675, -4.76217393, -4.76217393,\n",
       "       -4.06902675, -4.76217393, -2.97041447, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -3.8458832 , -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.06902675, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.06902675,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.35670883, -4.76217393, -4.76217393, -4.35670883, -3.8458832 ,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.35670883,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.35670883, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.35670883,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393, -4.76217393, -4.76217393, -4.76217393,\n",
       "       -4.76217393, -4.76217393])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_hat, Pi_hat = m_nb._count_state_transitions(X=df[\"text\"])\n",
    "np.log(Pi_hat / 234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pi_hat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14 / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
