{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune A Language Model\n",
    "\n",
    "- We'll be finetuning an LLM on a specific target task, such as classifying text.\n",
    "- Using:\n",
    "  - Hugging Face Transformers\n",
    "  - PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "numpy       : 1.26.4\n",
      "pandas      : 2.2.1\n",
      "polars      : 0.20.18\n",
      "torch       : 2.2.2\n",
      "lightning   : 2.2.1\n",
      "transformers: 4.39.3\n",
      "\n",
      "conda environment: torch_p11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,torch,lightning,transformers --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/neidu/Desktop/Projects/Personal/My_Projects/NLP-Tutorial/notebook\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from utils import go_up_from_current_directory\n",
    "\n",
    "go_up_from_current_directory(go_up=1)\n",
    "from data_prep.data_prep import DataCleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (1608255, 4) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>nuban</th><th>description</th><th>label</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;33950&quot;</td><td>1</td><td>&quot;Quantum USSD&quot;</td><td>&quot;noSpend&quot;</td></tr><tr><td>&quot;33950&quot;</td><td>1</td><td>&quot;Quantum USSD&quot;</td><td>&quot;noSpend&quot;</td></tr><tr><td>&quot;33950&quot;</td><td>1</td><td>&quot;Quantum USSD&quot;</td><td>&quot;noSpend&quot;</td></tr><tr><td>&quot;33950&quot;</td><td>1</td><td>&quot;Quantum USSD&quot;</td><td>&quot;noSpend&quot;</td></tr><tr><td>&quot;33950&quot;</td><td>1</td><td>&quot;Quantum USSD&quot;</td><td>&quot;noSpend&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────┬───────┬──────────────┬─────────┐\n",
       "│ customer_id ┆ nuban ┆ description  ┆ label   │\n",
       "│ ---         ┆ ---   ┆ ---          ┆ ---     │\n",
       "│ str         ┆ i64   ┆ str          ┆ str     │\n",
       "╞═════════════╪═══════╪══════════════╪═════════╡\n",
       "│ 33950       ┆ 1     ┆ Quantum USSD ┆ noSpend │\n",
       "│ 33950       ┆ 1     ┆ Quantum USSD ┆ noSpend │\n",
       "│ 33950       ┆ 1     ┆ Quantum USSD ┆ noSpend │\n",
       "│ 33950       ┆ 1     ┆ Quantum USSD ┆ noSpend │\n",
       "│ 33950       ┆ 1     ┆ Quantum USSD ┆ noSpend │\n",
       "└─────────────┴───────┴──────────────┴─────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp: str = \"./models/spend_df.parquet\"\n",
    "\n",
    "df: pl.DataFrame = pl.read_parquet(fp).drop(\n",
    "    [\"index\", \"date\", \"type\", \"amount\", \"balance\", \"tags\"]\n",
    ")\n",
    "print(f\"Shape of data: {df.shape} \\n\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan</td>\n",
       "      <td>41454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>savingsAndInvestments</td>\n",
       "      <td>4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noSpend</td>\n",
       "      <td>1529430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bills</td>\n",
       "      <td>33312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label      len\n",
       "0                   loan    41454\n",
       "1  savingsAndInvestments     4059\n",
       "2                noSpend  1529430\n",
       "3                  bills    33312"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group_by(\"label\").agg(pl.len()).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>nuban</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  nuban   description    label  cleaned_text\n",
       "0       33950      1  Quantum USSD  noSpend  quantum ussd\n",
       "1       33950      1  Quantum USSD  noSpend  quantum ussd\n",
       "2       33950      1  Quantum USSD  noSpend  quantum ussd\n",
       "3       33950      1  Quantum USSD  noSpend  quantum ussd\n",
       "4       33950      1  Quantum USSD  noSpend  quantum ussd"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT_COLUMN: str = \"description\"\n",
    "\n",
    "df = DataCleaner(data=df, text_column=TEXT_COLUMN).prepare_data()\n",
    "df.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>nuban</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>desc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33950</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>noSpend</td>\n",
       "      <td>quantum ussd</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  nuban   description    label  cleaned_text  desc_length\n",
       "0       33950      1  Quantum USSD  noSpend  quantum ussd           12\n",
       "1       33950      1  Quantum USSD  noSpend  quantum ussd           12\n",
       "2       33950      1  Quantum USSD  noSpend  quantum ussd           12\n",
       "3       33950      1  Quantum USSD  noSpend  quantum ussd           12\n",
       "4       33950      1  Quantum USSD  noSpend  quantum ussd           12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT_COLUMN: str = \"cleaned_text\"\n",
    "df = df.with_columns(desc_length=pl.col(TEXT_COLUMN).str.len_chars())\n",
    "\n",
    "df.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>customer_id</th><th>nuban</th><th>description</th><th>label</th><th>cleaned_text</th><th>desc_length</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;1608255&quot;</td><td>1.608255e6</td><td>&quot;1608255&quot;</td><td>&quot;1608255&quot;</td><td>&quot;1608255&quot;</td><td>1.608255e6</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>32.907305</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>16.400539</td></tr><tr><td>&quot;min&quot;</td><td>&quot;33790&quot;</td><td>1.0</td><td>&quot;    WASIU ABAS…</td><td>&quot;bills&quot;</td><td>&quot;&quot;</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>18.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>34.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>45.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;36192&quot;</td><td>1.0</td><td>&quot;yunusa  Badama…</td><td>&quot;savingsAndInve…</td><td>&quot;zuriyat ladidi…</td><td>136.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌────────────┬─────────────┬────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ statistic  ┆ customer_id ┆ nuban      ┆ description  ┆ label        ┆ cleaned_text ┆ desc_length │\n",
       "│ ---        ┆ ---         ┆ ---        ┆ ---          ┆ ---          ┆ ---          ┆ ---         │\n",
       "│ str        ┆ str         ┆ f64        ┆ str          ┆ str          ┆ str          ┆ f64         │\n",
       "╞════════════╪═════════════╪════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ count      ┆ 1608255     ┆ 1.608255e6 ┆ 1608255      ┆ 1608255      ┆ 1608255      ┆ 1.608255e6  │\n",
       "│ null_count ┆ 0           ┆ 0.0        ┆ 0            ┆ 0            ┆ 0            ┆ 0.0         │\n",
       "│ mean       ┆ null        ┆ 1.0        ┆ null         ┆ null         ┆ null         ┆ 32.907305   │\n",
       "│ std        ┆ null        ┆ 0.0        ┆ null         ┆ null         ┆ null         ┆ 16.400539   │\n",
       "│ min        ┆ 33790       ┆ 1.0        ┆ WASIU ABASS  ┆ bills        ┆              ┆ 0.0         │\n",
       "│            ┆             ┆            ┆ - 033        ┆              ┆              ┆             │\n",
       "│ 25%        ┆ null        ┆ 1.0        ┆ null         ┆ null         ┆ null         ┆ 18.0        │\n",
       "│ 50%        ┆ null        ┆ 1.0        ┆ null         ┆ null         ┆ null         ┆ 34.0        │\n",
       "│ 75%        ┆ null        ┆ 1.0        ┆ null         ┆ null         ┆ null         ┆ 45.0        │\n",
       "│ max        ┆ 36192       ┆ 1.0        ┆ yunusa       ┆ savingsAndIn ┆ zuriyat      ┆ 136.0       │\n",
       "│            ┆             ┆            ┆ Badamasi-    ┆ vestments    ┆ ladidi idris ┆             │\n",
       "│            ┆             ┆            ┆ 305          ┆              ┆              ┆             │\n",
       "└────────────┴─────────────┴────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>customer_id</th><th>nuban</th><th>description</th><th>label</th><th>cleaned_text</th><th>desc_length</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;1142266&quot;</td><td>1.142266e6</td><td>&quot;1142266&quot;</td><td>&quot;1142266&quot;</td><td>&quot;1142266&quot;</td><td>1.142266e6</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>40.87574</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>12.394284</td></tr><tr><td>&quot;min&quot;</td><td>&quot;33790&quot;</td><td>1.0</td><td>&quot;   ABAROGU  OG…</td><td>&quot;bills&quot;</td><td>&quot;   _rvsl__ bil…</td><td>20.0</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>33.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>40.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>49.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;36192&quot;</td><td>1.0</td><td>&quot;yerima samuel …</td><td>&quot;savingsAndInve…</td><td>&quot;zuriyat ladidi…</td><td>136.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌────────────┬─────────────┬────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ statistic  ┆ customer_id ┆ nuban      ┆ description  ┆ label        ┆ cleaned_text ┆ desc_length │\n",
       "│ ---        ┆ ---         ┆ ---        ┆ ---          ┆ ---          ┆ ---          ┆ ---         │\n",
       "│ str        ┆ str         ┆ f64        ┆ str          ┆ str          ┆ str          ┆ f64         │\n",
       "╞════════════╪═════════════╪════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ count      ┆ 1142266     ┆ 1.142266e6 ┆ 1142266      ┆ 1142266      ┆ 1142266      ┆ 1.142266e6  │\n",
       "│ null_count ┆ 0           ┆ 0.0        ┆ 0            ┆ 0            ┆ 0            ┆ 0.0         │\n",
       "│ mean       ┆ null        ┆ 1.0        ┆ null         ┆ null         ┆ null         ┆ 40.87574    │\n",
       "│ std        ┆ null        ┆ 0.0        ┆ null         ┆ null         ┆ null         ┆ 12.394284   │\n",
       "│ min        ┆ 33790       ┆ 1.0        ┆ ABAROGU      ┆ bills        ┆ _rvsl__      ┆ 20.0        │\n",
       "│            ┆             ┆            ┆ OGBONNA      ┆              ┆ bills        ┆             │\n",
       "│            ┆             ┆            ┆ OKORAFOR -   ┆              ┆ payment ussd ┆             │\n",
       "│            ┆             ┆            ┆ 0…           ┆              ┆              ┆             │\n",
       "│ 25%        ┆ null        ┆ 1.0        ┆ null         ┆ null         ┆ null         ┆ 33.0        │\n",
       "│ 50%        ┆ null        ┆ 1.0        ┆ null         ┆ null         ┆ null         ┆ 40.0        │\n",
       "│ 75%        ┆ null        ┆ 1.0        ┆ null         ┆ null         ┆ null         ┆ 49.0        │\n",
       "│ max        ┆ 36192       ┆ 1.0        ┆ yerima       ┆ savingsAndIn ┆ zuriyat      ┆ 136.0       │\n",
       "│            ┆             ┆            ┆ samuel       ┆ vestments    ┆ ladidi idris ┆             │\n",
       "│            ┆             ┆            ┆ samaila- 305 ┆              ┆              ┆             │\n",
       "└────────────┴─────────────┴────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length: int = 20\n",
    "\n",
    "df = df.filter(pl.col(\"desc_length\").ge(text_length))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noSpend</td>\n",
       "      <td>1080524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>savingsAndInvestments</td>\n",
       "      <td>4056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bills</td>\n",
       "      <td>16555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loan</td>\n",
       "      <td>41131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label      len\n",
       "0                noSpend  1080524\n",
       "1  savingsAndInvestments     4056\n",
       "2                  bills    16555\n",
       "3                   loan    41131"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group_by(\"label\").agg(pl.len()).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (20000, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trf shop rent lawyer fees frm oyeleye oluwatosin kolawole adewoyin</td>\n",
       "      <td>bills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos web pmt piggyvest  pstk lang</td>\n",
       "      <td>savingsAndInvestments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trf isaiah frm isaiah prince boon mfy fairmoney henry isaiah</td>\n",
       "      <td>loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main interest liquidation ilattw eaa</td>\n",
       "      <td>loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main interest liquidation ilatb d</td>\n",
       "      <td>loan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         cleaned_text  \\\n",
       "0  trf shop rent lawyer fees frm oyeleye oluwatosin kolawole adewoyin   \n",
       "1                                    pos web pmt piggyvest  pstk lang   \n",
       "2       trf isaiah frm isaiah prince boon mfy fairmoney henry isaiah    \n",
       "3                                main interest liquidation ilattw eaa   \n",
       "4                                   main interest liquidation ilatb d   \n",
       "\n",
       "                   label  \n",
       "0                  bills  \n",
       "1  savingsAndInvestments  \n",
       "2                   loan  \n",
       "3                   loan  \n",
       "4                   loan  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N: int = 5_000\n",
    "seed: int = 123\n",
    "selected_columns: list[str] = [TEXT_COLUMN, \"label\"]\n",
    "\n",
    "loan: pl.DataFrame = df.filter(pl.col(\"label\").eq(\"loan\")).sample(n=N, seed=seed)\n",
    "noSpend: pl.DataFrame = df.filter(pl.col(\"label\").eq(\"noSpend\")).sample(n=N, seed=seed)\n",
    "bills: pl.DataFrame = df.filter(pl.col(\"label\").eq(\"bills\")).sample(n=N, seed=seed)\n",
    "savings: pl.DataFrame = df.filter(pl.col(\"label\").eq(\"savingsAndInvestments\")).sample(\n",
    "    n=N,\n",
    "    seed=seed,\n",
    "    with_replacement=True,  # NEW!\n",
    ")\n",
    "\n",
    "data: pl.DataFrame = (\n",
    "    pl.concat([loan, noSpend, bills, savings], how=\"vertical\")\n",
    "    .sample(fraction=1, seed=seed, shuffle=True)\n",
    "    .select(selected_columns)\n",
    ")\n",
    "print(f\"Shape of data: {data.shape} \\n\")\n",
    "data.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>savingsAndInvestments</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noSpend</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bills</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loan</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label   len\n",
       "0  savingsAndInvestments  5000\n",
       "1                noSpend  5000\n",
       "2                  bills  5000\n",
       "3                   loan  5000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.group_by(\"label\").agg(pl.len()).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "      <th>desc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trf shop rent lawyer fees frm oyeleye oluwatosin kolawole adewoyin</td>\n",
       "      <td>bills</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos web pmt piggyvest  pstk lang</td>\n",
       "      <td>savingsAndInvestments</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trf isaiah frm isaiah prince boon mfy fairmoney henry isaiah</td>\n",
       "      <td>loan</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main interest liquidation ilattw eaa</td>\n",
       "      <td>loan</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main interest liquidation ilatb d</td>\n",
       "      <td>loan</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         cleaned_text  \\\n",
       "0  trf shop rent lawyer fees frm oyeleye oluwatosin kolawole adewoyin   \n",
       "1                                    pos web pmt piggyvest  pstk lang   \n",
       "2       trf isaiah frm isaiah prince boon mfy fairmoney henry isaiah    \n",
       "3                                main interest liquidation ilattw eaa   \n",
       "4                                   main interest liquidation ilatb d   \n",
       "\n",
       "                   label  desc_length  \n",
       "0                  bills           66  \n",
       "1  savingsAndInvestments           32  \n",
       "2                   loan           61  \n",
       "3                   loan           36  \n",
       "4                   loan           33  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.with_columns(desc_length=pl.col(TEXT_COLUMN).str.len_chars())\n",
    "\n",
    "data.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>cleaned_text</th><th>label</th><th>desc_length</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;20000&quot;</td><td>&quot;20000&quot;</td><td>20000.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>39.61795</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>13.289767</td></tr><tr><td>&quot;min&quot;</td><td>&quot;   rvsl  airti…</td><td>&quot;bills&quot;</td><td>20.0</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>32.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>34.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>45.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;yusuf durojaiy…</td><td>&quot;savingsAndInve…</td><td>129.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 4)\n",
       "┌────────────┬───────────────────────────────────┬───────────────────────┬─────────────┐\n",
       "│ statistic  ┆ cleaned_text                      ┆ label                 ┆ desc_length │\n",
       "│ ---        ┆ ---                               ┆ ---                   ┆ ---         │\n",
       "│ str        ┆ str                               ┆ str                   ┆ f64         │\n",
       "╞════════════╪═══════════════════════════════════╪═══════════════════════╪═════════════╡\n",
       "│ count      ┆ 20000                             ┆ 20000                 ┆ 20000.0     │\n",
       "│ null_count ┆ 0                                 ┆ 0                     ┆ 0.0         │\n",
       "│ mean       ┆ null                              ┆ null                  ┆ 39.61795    │\n",
       "│ std        ┆ null                              ┆ null                  ┆ 13.289767   │\n",
       "│ min        ┆    rvsl  airtime topup  ussdalus… ┆ bills                 ┆ 20.0        │\n",
       "│ 25%        ┆ null                              ┆ null                  ┆ 32.0        │\n",
       "│ 50%        ┆ null                              ┆ null                  ┆ 34.0        │\n",
       "│ 75%        ┆ null                              ┆ null                  ┆ 45.0        │\n",
       "│ max        ┆ yusuf durojaiye otunba            ┆ savingsAndInvestments ┆ 129.0       │\n",
       "└────────────┴───────────────────────────────────┴───────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>label</th><th>len</th></tr><tr><td>u8</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>5000</td></tr><tr><td>0</td><td>5000</td></tr><tr><td>2</td><td>5000</td></tr><tr><td>3</td><td>5000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 2)\n",
       "┌───────┬──────┐\n",
       "│ label ┆ len  │\n",
       "│ ---   ┆ ---  │\n",
       "│ u8    ┆ u32  │\n",
       "╞═══════╪══════╡\n",
       "│ 1     ┆ 5000 │\n",
       "│ 0     ┆ 5000 │\n",
       "│ 2     ┆ 5000 │\n",
       "│ 3     ┆ 5000 │\n",
       "└───────┴──────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the labels\n",
    "mappings: dict[str, int] = {\n",
    "    \"bills\": 0,\n",
    "    \"loan\": 1,\n",
    "    \"savingsAndInvestments\": 2,\n",
    "    \"noSpend\": 3,\n",
    "}\n",
    "data = data.with_columns(label=pl.col(\"label\").replace(mappings).cast(pl.UInt8))\n",
    "\n",
    "data.group_by(\"label\").agg(pl.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape = (16200, 3), val_data.shape = (1800, 3), test_data.shape = (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "## Split the data into tran, validation and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data: pl.DataFrame\n",
    "val_data: pl.DataFrame\n",
    "test_data: pl.DataFrame\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "    data, stratify=data.select(\"label\"), test_size=0.1, random_state=seed\n",
    ")\n",
    "train_data, val_data = train_test_split(\n",
    "    train_data, stratify=train_data.select(\"label\"), test_size=0.1, random_state=seed\n",
    ")\n",
    "\n",
    "print(f\"{train_data.shape = }, {val_data.shape = }, {test_data.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 19:45:46.412169: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, DataCollatorWithPadding\n",
    "\n",
    "\n",
    "pretrained_model_name_or_path: str = \"distilbert-base-uncased\"\n",
    "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)\n",
    "config: AutoConfig = AutoConfig.from_pretrained(pretrained_model_name_or_path)\n",
    "model: AutoModel = AutoModel.from_pretrained(\n",
    "    pretrained_model_name_or_path, config=config\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">DistilBertConfig <span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"_name_or_path\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"distilbert-base-uncased\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"activation\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gelu\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"architectures\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"DistilBertForMaskedLM\"</span>\n",
       "  <span style=\"font-weight: bold\">]</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"attention_dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"dim\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"hidden_dim\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"initializer_range\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"max_position_embeddings\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"model_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"distilbert\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_heads\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_layers\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"pad_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"qa_dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"seq_classif_dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"sinusoidal_pos_embds\"</span>: false,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"tie_weights_\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"transformers_version\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"4.39.3\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"vocab_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30522</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "DistilBertConfig \u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"_name_or_path\"\u001b[0m: \u001b[32m\"distilbert-base-uncased\"\u001b[0m,\n",
       "  \u001b[32m\"activation\"\u001b[0m: \u001b[32m\"gelu\"\u001b[0m,\n",
       "  \u001b[32m\"architectures\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"DistilBertForMaskedLM\"\u001b[0m\n",
       "  \u001b[1m]\u001b[0m,\n",
       "  \u001b[32m\"attention_dropout\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"dim\"\u001b[0m: \u001b[1;36m768\u001b[0m,\n",
       "  \u001b[32m\"dropout\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"hidden_dim\"\u001b[0m: \u001b[1;36m3072\u001b[0m,\n",
       "  \u001b[32m\"initializer_range\"\u001b[0m: \u001b[1;36m0.02\u001b[0m,\n",
       "  \u001b[32m\"max_position_embeddings\"\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "  \u001b[32m\"model_type\"\u001b[0m: \u001b[32m\"distilbert\"\u001b[0m,\n",
       "  \u001b[32m\"n_heads\"\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
       "  \u001b[32m\"n_layers\"\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
       "  \u001b[32m\"pad_token_id\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "  \u001b[32m\"qa_dropout\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"seq_classif_dropout\"\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "  \u001b[32m\"sinusoidal_pos_embds\"\u001b[0m: false,\n",
       "  \u001b[32m\"tie_weights_\"\u001b[0m: true,\n",
       "  \u001b[32m\"transformers_version\"\u001b[0m: \u001b[32m\"4.39.3\"\u001b[0m,\n",
       "  \u001b[32m\"vocab_size\"\u001b[0m: \u001b[1;36m30522\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(config)\n",
    "# max_position_embeddings is the maximum length of the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Encoded_input: \n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2171</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2003</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5413</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2098</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2226</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1012</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]])</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]])}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Encoded_input: \n",
       "\u001b[1m{\u001b[0m\u001b[32m'input_ids'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m101\u001b[0m, \u001b[1;36m2026\u001b[0m, \u001b[1;36m2171\u001b[0m, \u001b[1;36m2003\u001b[0m, \u001b[1;36m5413\u001b[0m, \u001b[1;36m2098\u001b[0m, \u001b[1;36m2226\u001b[0m, \u001b[1;36m1012\u001b[0m,  \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'attention_mask'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BaseModelOutput</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">last_hidden_state</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0271</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0102</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0511</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0156</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2896</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2545</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3634</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1769</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4035</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1201</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2872</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2297</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0306</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0175</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3661</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1427</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3115</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2277</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0139</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3254</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2510</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0730</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1431</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0520</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5800</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0150</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4612</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1916</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4758</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5623</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6528</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1958</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0316</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1093</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6250</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4009</span><span style=\"font-weight: bold\">]]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">NativeLayerNormBackward0</span><span style=\"font-weight: bold\">&gt;)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">hidden_states</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">attentions</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output: \n",
       "\u001b[1;35mBaseModelOutput\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlast_hidden_state\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0271\u001b[0m, \u001b[1;36m-0.0102\u001b[0m, \u001b[1;36m-0.0511\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.0156\u001b[0m,  \u001b[1;36m0.2896\u001b[0m,  \u001b[1;36m0.2545\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.3634\u001b[0m, \u001b[1;36m-0.1769\u001b[0m, \u001b[1;36m-0.4035\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.1201\u001b[0m,  \u001b[1;36m0.2872\u001b[0m,  \u001b[1;36m0.2297\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.0306\u001b[0m, \u001b[1;36m-0.0175\u001b[0m, \u001b[1;36m-0.3661\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.1427\u001b[0m,  \u001b[1;36m0.3115\u001b[0m, \u001b[1;36m-0.2277\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[33m...\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.0139\u001b[0m, \u001b[1;36m-0.3254\u001b[0m, \u001b[1;36m-0.2510\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.0730\u001b[0m, \u001b[1;36m-0.1431\u001b[0m,  \u001b[1;36m0.0520\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.5800\u001b[0m,  \u001b[1;36m0.0150\u001b[0m, \u001b[1;36m-0.4612\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.1916\u001b[0m, \u001b[1;36m-0.4758\u001b[0m, \u001b[1;36m-0.5623\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.6528\u001b[0m,  \u001b[1;36m0.1958\u001b[0m, \u001b[1;36m-0.0316\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.1093\u001b[0m, \u001b[1;36m-0.6250\u001b[0m, \u001b[1;36m-0.4009\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mNativeLayerNormBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mhidden_states\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mattentions\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length: int = 128\n",
    "texts: list[str] = [\"My name is Chinedu.\"]\n",
    "encoded_input: dict[str, Any] = tokenizer(\n",
    "    texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "output: Tensor = model(**encoded_input)\n",
    "console.print(f\"Encoded_input: \\n{encoded_input}\")\n",
    "console.print(f\"Output: \\n{output}\")\n",
    "\n",
    "output.last_hidden_state.shape  # (1, 9, 768): (batch_size, sequence_length, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.0271, -0.0102, -0.0511,  ..., -0.0156,  0.2896,  0.2545],\n",
       "         [ 0.3634, -0.1769, -0.4035,  ..., -0.1201,  0.2872,  0.2297],\n",
       "         [-0.0306, -0.0175, -0.3661,  ..., -0.1427,  0.3115, -0.2277],\n",
       "         ...,\n",
       "         [ 0.0139, -0.3254, -0.2510,  ..., -0.0730, -0.1431,  0.0520],\n",
       "         [ 0.5800,  0.0150, -0.4612,  ...,  0.1916, -0.4758, -0.5623],\n",
       "         [ 0.6528,  0.1958, -0.0316,  ...,  0.1093, -0.6250, -0.4009]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids: Tensor = encoded_input[\"input_ids\"]\n",
    "attention_mask: Tensor = encoded_input[\"attention_mask\"]\n",
    "model(input_ids=input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the hidden state of the [CLS] token (first token). This is the token that\n",
    "# the model considers the entire input sequence to be (for Bidirectional models).\n",
    "cls_output: Tensor = output.last_hidden_state[:, 0, :]\n",
    "cls_output.shape  # (1, 768): (batch_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=4, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head\n",
    "num_classes: int = len(mappings)\n",
    "model_head: nn.Module = nn.Linear(config.dim, num_classes)\n",
    "model_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matric Multiplication\n",
    "```text\n",
    "(batch_size, seq_len, emb_dim) @ (emb_dim, num_classes) -> (batch_size, seq_len, num_classes)\n",
    "(1, 9, 768) @ (768, 4): Broadcasting adds a batch dimension to the left tensor.\n",
    "MatrixMul of the (seq_len, emb_dim) @ (emb_dim, num_classes) -> (seq_len, num_classes)\n",
    "Finally, add the batch_size\n",
    "(1, (9, 768)) @ (1, (768, 4))) -> (9, 768) @ (768, 4) -> (9, 4) -> (1, 9, 4)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3945, 0.2121, 0.1816, 0.2118], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits: Tensor = model_head(cls_output).squeeze(0)\n",
    "proba = torch.softmax(logits, dim=-1)\n",
    "proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr>\n",
    "\n",
    "## Putting It Together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BatchEncoding\n",
    "\n",
    "\n",
    "class Transformation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        max_length: int,\n",
    "        padding: bool = True,\n",
    "        truncation: bool = True,\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.truncation = truncation\n",
    "\n",
    "    def __call__(self, texts: str | list[str]) -> dict[str, Any]:\n",
    "        encoded_input: dict[str, Any] = self.tokenizer(\n",
    "            texts,\n",
    "            padding=self.padding,\n",
    "            truncation=self.truncation,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return encoded_input\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.tokenizer})\"\n",
    "\n",
    "\n",
    "class BackBone(nn.Module):\n",
    "    def __init__(\n",
    "        self, pretrained_model_name_or_path: str, fine_tune: bool = True\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_path = pretrained_model_name_or_path\n",
    "        self.backbone = self._get_backbone()\n",
    "        if fine_tune:\n",
    "            self.prepare_for_fine_tuning()\n",
    "\n",
    "        self.total_params = self._get_total_params()\n",
    "        self.trainable_params = self._get_trainable_params()\n",
    "\n",
    "    def forward(self, enc_input: Tensor) -> Tensor:\n",
    "        output: Tensor = self.backbone(**enc_input)\n",
    "        # Extract the [CLS] token's hidden state, which represents the entire input\n",
    "        # sequence in bidirectional models like BERT/DistilBERT.\n",
    "        cls_output: Tensor = output.last_hidden_state[:, 0, :]\n",
    "        return cls_output\n",
    "\n",
    "    def _get_backbone(self) -> AutoModel:\n",
    "        return AutoModel.from_pretrained(self.model_path)\n",
    "\n",
    "    def _get_total_params(self) -> int:\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "    def _get_trainable_params(self) -> int:\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    def prepare_for_fine_tuning(self) -> None:\n",
    "        \"\"\"\n",
    "        Prepares the model for fine-tuning by freezing most of the model's parameters.\n",
    "        This allows the model to be fine-tuned on a specific task while preserving the\n",
    "        learned representations from the pre-trained model.\n",
    "        \"\"\"\n",
    "        # Get the model ready for fine-tuning by `freezing` the model's parameters.\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Make the last `transformer block` layer trainable\n",
    "        for param in self.backbone.transformer.layer[-1].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Make the last `output_layer_norm` layer trainable\n",
    "        for param in self.backbone.transformer.layer[-1].output_layer_norm.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "class SoftmaxHead(nn.Module):\n",
    "    def __init__(self, emb_dim: int, num_classes: int, dim: int = -1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.head = nn.Sequential(nn.Linear(emb_dim, num_classes), nn.Softmax(dim=dim))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        probas: Tensor = self.head(x)\n",
    "        return probas\n",
    "\n",
    "\n",
    "class SpendClassifier(nn.Module):\n",
    "    def __init__(self, backbone: BackBone, head: SoftmaxHead) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.head = head\n",
    "\n",
    "    def forward(self, enc_input: BatchEncoding) -> Tensor:\n",
    "        cls_output: Tensor = self.backbone(enc_input)\n",
    "        probas: Tensor = self.head(cls_output).squeeze(0)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">362</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>\n",
       "Training params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">087</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">872</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total params: \u001b[1;36m66\u001b[0m,\u001b[1;36m362\u001b[0m,\u001b[1;36m880\u001b[0m\n",
       "Training params: \u001b[1;36m7\u001b[0m,\u001b[1;36m087\u001b[0m,\u001b[1;36m872\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SpendClassifier</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>backbone<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BackBone</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>backbone<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DistilBertModel</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span>embeddings<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embeddings</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>word_embeddings<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30522</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding_idx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>position_embeddings<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>transformer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Transformer</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>layer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TransformerBlock</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>attention<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MultiHeadSelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>q_lin<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>k_lin<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>v_lin<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>out_lin<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>sa_layer_norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>ffn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FFN</span><span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>lin1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>lin2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>activation<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>output_layer_norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SoftmaxHead</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Softmax</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">dim</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSpendClassifier\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mbackbone\u001b[1m)\u001b[0m: \u001b[1;35mBackBone\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mbackbone\u001b[1m)\u001b[0m: \u001b[1;35mDistilBertModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mword_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m30522\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[33mpadding_idx\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mposition_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mLayerNorm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-12\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mtransformer\u001b[1m)\u001b[0m: \u001b[1;35mTransformer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayer\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m6\u001b[0m x \u001b[1;35mTransformerBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mattention\u001b[1m)\u001b[0m: \u001b[1;35mMultiHeadSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mq_lin\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mk_lin\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mv_lin\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mout_lin\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0msa_layer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-12\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mffn\u001b[1m)\u001b[0m: \u001b[1;35mFFN\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlin1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlin2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0moutput_layer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-12\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mhead\u001b[1m)\u001b[0m: \u001b[1;35mSoftmaxHead\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mhead\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSoftmax\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdim\u001b[0m=\u001b[1;36m-1\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fine_tune: bool = True\n",
    "\n",
    "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)\n",
    "transformation = Transformation(tokenizer=tokenizer, max_length=max_length)\n",
    "backbone: BackBone = BackBone(\n",
    "    pretrained_model_name_or_path=pretrained_model_name_or_path, fine_tune=fine_tune\n",
    ")\n",
    "head: SoftmaxHead = SoftmaxHead(emb_dim=config.dim, num_classes=num_classes)\n",
    "model: SpendClassifier = SpendClassifier(backbone=backbone, head=head)\n",
    "console.print(\n",
    "    f\"Total params: {model.backbone.total_params:,}\\nTraining params: {model.backbone.trainable_params:,}\\n\"\n",
    ")\n",
    "console.print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2081, 0.1521, 0.2277, 0.4121], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not fine-tuned yet!\n",
    "text_1: str = \"REV-MONNIFY / FairMoney-Jane Doe- 022\"\n",
    "encoded_input: BatchEncoding = transformation(text_1)\n",
    "\n",
    "model(enc_input=encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpendDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, data: pl.DataFrame, text_column: str = \"Text\", label_column: str = \"Label\"\n",
    "    ) -> None:\n",
    "        self.texts: list[str] = [text for text in data.select(text_column).to_series()]\n",
    "        self.targets: list[int] = data.select(label_column).to_series().to_list()\n",
    "        assert len(self.texts) == len(\n",
    "            self.targets\n",
    "        ), \"Number of texts and targets don't match\"\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        text: str = self.texts[idx]\n",
    "        label: Tensor = torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "\n",
    "        return (text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('principal liquidation ilath aa', tensor(1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the dataset implementation\n",
    "torch.manual_seed(seed)\n",
    "sample_dataset: Dataset = SpendDataset(\n",
    "    data=train_data.head(5),\n",
    "    text_column=TEXT_COLUMN,\n",
    "    label_column=\"label\",\n",
    ")\n",
    "\n",
    "sample_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BatchEncoding, DataCollatorWithPadding\n",
    "from torch.utils.data import BatchSampler, DataLoader, Dataset, Sampler, default_collate\n",
    "\n",
    "\n",
    "def collate_fn(batch: list[tuple[str, int]]) -> dict[str, list]:\n",
    "    \"\"\"Collates a batch of text and label pairs into a dictionary of tensors.\n",
    "    i.e. dynamically pad the inputs received after tokenization.\n",
    "\n",
    "    Args:\n",
    "        batch (list[tuple[str, int]]): A list of tuples, where each tuple contains a text string\n",
    "        and a corresponding label integer.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list]: A dictionary containing the collated text and labels as lists of tensors.\n",
    "    \"\"\"\n",
    "    # Extract the data and labels and create a generator\n",
    "    texts, labels = zip(*batch)\n",
    "\n",
    "    # Tokenize the texts\n",
    "    encoded_inputs = tokenizer(\n",
    "        list(texts), padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    # Add labels to the encoded inputs\n",
    "    encoded_inputs[\"labels\"] = torch.tensor(labels)\n",
    "    return encoded_inputs\n",
    "\n",
    "\n",
    "# Required for the `tokenization_collate_fn`\n",
    "transformation: Transformation = Transformation(\n",
    "    tokenizer=tokenizer, max_length=max_length\n",
    ")\n",
    "\n",
    "\n",
    "def tokenization_collate_fn(\n",
    "    batch: list[tuple[str, int]]\n",
    ") -> tuple[BatchEncoding, Tensor]:\n",
    "    \"\"\"\n",
    "    Collates a batch of tokenized text and label pairs into a BatchEncoding and a Tensor.\n",
    "\n",
    "    Args:\n",
    "        batch (list[tuple[str, int]]): List of text strings and label integers.\n",
    "\n",
    "    Returns:\n",
    "        tuple[BatchEncoding, Tensor]: BatchEncoding of texts and a Tensor of labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the data and labels and create a generator\n",
    "    texts, labels = default_collate(batch)\n",
    "    # Tokenize the texts with padding and truncation\n",
    "    encodings: BatchEncoding = transformation(texts)\n",
    "    return encodings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[  101,  4054, 28763,  6335,  8988,  9779,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 13433,  2015,  4773,  7610,  2102, 10369,  6292,  6961,  2102,\n",
       "           8827,  2102,  2243, 11374,   102,     0,     0,     0,     0,     0],\n",
       "         [  101,  2364,  3037, 28763,  6335,  4017,  2595,  2078,   102,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 19817,  2546, 10424,  2213,  1045,  6979,  9626,  4574,  4179,\n",
       "          14405,  8747,  2401, 27178, 10581,  6979,  7929,  2080,   102,     0],\n",
       "         [  101, 19817,  2546,  4748,  8780,  5558, 10424,  2213,  4748,  2063,\n",
       "           1051,  5558, 27596,  1049,  2047, 24225,  5340, 16748, 23194,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
       " tensor([1, 2, 1, 3, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test collate function: It returns a tuple\n",
    "tokenization_collate_fn(sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  4054, 28763,  6335,  8988,  9779,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 13433,  2015,  4773,  7610,  2102, 10369,  6292,  6961,  2102,\n",
       "          8827,  2102,  2243, 11374,   102,     0,     0,     0,     0,     0],\n",
       "        [  101,  2364,  3037, 28763,  6335,  4017,  2595,  2078,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 19817,  2546, 10424,  2213,  1045,  6979,  9626,  4574,  4179,\n",
       "         14405,  8747,  2401, 27178, 10581,  6979,  7929,  2080,   102,     0],\n",
       "        [  101, 19817,  2546,  4748,  8780,  5558, 10424,  2213,  4748,  2063,\n",
       "          1051,  5558, 27596,  1049,  2047, 24225,  5340, 16748, 23194,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([1, 2, 1, 3, 1])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test collate function: It returns a dict\n",
    "collate_fn(sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset: Dataset = SpendDataset(\n",
    "    data=train_data, text_column=TEXT_COLUMN, label_column=\"label\"\n",
    ")\n",
    "val_dataset: Dataset = SpendDataset(\n",
    "    data=val_data, text_column=TEXT_COLUMN, label_column=\"label\"\n",
    ")\n",
    "test_dataset: Dataset = SpendDataset(\n",
    "    data=test_data, text_column=TEXT_COLUMN, label_column=\"label\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "batch_size: int = 16\n",
    "num_workers: int = 0\n",
    "\n",
    "train_loader: DataLoader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=tokenization_collate_fn,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader: DataLoader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=tokenization_collate_fn,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader: DataLoader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=tokenization_collate_fn,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using collate_fn\n",
    "# for inp_batch in train_loader:\n",
    "#     # Shape: (batch_size, max_length)\n",
    "#     print(f\"input_ids: {inp_batch['input_ids'].shape}\")\n",
    "#     print(f\"attention_mask: {inp_batch['attention_mask'].shape}\")\n",
    "#     print(f\"labels: {inp_batch['labels'].shape}\")\n",
    "#     print(\"\\n\\n\")\n",
    "\n",
    "#     break\n",
    "\n",
    "\n",
    "# print(f\"{len(train_loader) = }\")\n",
    "# print(f\"{len(val_loader) = }\")\n",
    "# print(f\"{len(test_loader) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([16, 26])\n",
      "attention_mask: torch.Size([16, 26])\n",
      "labels: torch.Size([16])\n",
      "\n",
      "\n",
      "\n",
      "len(train_loader) = 1012\n",
      "len(val_loader) = 113\n",
      "len(test_loader) = 125\n"
     ]
    }
   ],
   "source": [
    "# Using tokenization_collate_fn\n",
    "for inp_batch, target_batch in train_loader:\n",
    "    # Shape: (batch_size, max_length)\n",
    "    print(f\"input_ids: {inp_batch['input_ids'].shape}\")\n",
    "    print(f\"attention_mask: {inp_batch['attention_mask'].shape}\")\n",
    "    print(f\"labels: {target_batch.shape}\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "print(f\"{len(train_loader) = }\")\n",
    "print(f\"{len(val_loader) = }\")\n",
    "print(f\"{len(test_loader) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Training Workflow Using PyTorch\n",
    "\n",
    "- Split the data into train validation and test sets.\n",
    "\n",
    "- Prepare and create datasets.\n",
    "\n",
    "- Prepare dataloaders using the datasets.\n",
    "\n",
    "- Create functions for calculating:\n",
    "  - loss (batch and average)\n",
    "  - accuracy (or any other metric)\n",
    "\n",
    "- Training loop:\n",
    "  - Epochs\n",
    "  - Optimizer:\n",
    "    - Optimizer type(SGD, Adam, etc.)\n",
    "    - Learning rate\n",
    "    - Learning rate decay\n",
    "\n",
    "  - For every epoch:\n",
    "    - For every batch:\n",
    "      - Forward pass:\n",
    "        - Calc loss\n",
    "      - Backward pass:\n",
    "        - Reset gradients\n",
    "        - Backward pass\n",
    "        - Update weights\n",
    "        - Log metrics (loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_num_batches(data_loader: DataLoader, num_batches: int | None = None) -> int:\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    return num_batches\n",
    "\n",
    "\n",
    "def calc_loss_batch(\n",
    "    input_batch: BatchEncoding,\n",
    "    target_batch: Tensor,\n",
    "    model: nn.Module,\n",
    "    device: str | torch.device,\n",
    ") -> Tensor:\n",
    "    \"\"\"Calculates the loss for a batch of input and target data using the given model.\n",
    "\n",
    "    Args:\n",
    "        input_batch (torch.Tensor): The input batch of data.\n",
    "        target_batch (torch.Tensor): The target batch of labels.\n",
    "        model (torch.nn.Module): The model to be used for the loss calculation.\n",
    "        device (torch.device): The device (CPU or GPU) to use for the calculation.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The loss value for the batch.\n",
    "    \"\"\"\n",
    "    enc_input: dict[str, Any] = {\n",
    "        key: value.to(device) for key, value in input_batch.items()\n",
    "    }\n",
    "    target_batch: Tensor = target_batch.to(device)\n",
    "    logits: Tensor = model(enc_input)\n",
    "    loss: Tensor = F.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(\n",
    "    data_loader: DataLoader,\n",
    "    model: nn.Module,\n",
    "    device: str | torch.device,\n",
    "    num_batches: int | None = None,\n",
    ") -> float:\n",
    "    \"\"\"Calculates the average loss across a data loader for a given model.\n",
    "\n",
    "    Args:\n",
    "        data_loader (torch.utils.data.DataLoader): The data loader containing the input and\n",
    "        target data.\n",
    "        model (torch.nn.Module): The model to be used for the loss calculation.\n",
    "        device (torch.device): The device (CPU or GPU) to use for the calculation.\n",
    "        num_batches (int, optional): The maximum number of batches to evaluate. If None,\n",
    "        all batches in the data loader will be used.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss of the model on the data loader.\n",
    "    \"\"\"\n",
    "    total_loss: float = 0.0\n",
    "\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    num_batches = _get_num_batches(data_loader, num_batches)\n",
    "\n",
    "    for idx, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if idx < num_batches:\n",
    "            enc_input: dict[str, Any] = {\n",
    "                key: value.to(device) for key, value in input_batch.items()\n",
    "            }\n",
    "            target_batch: Tensor = target_batch.to(device)\n",
    "            loss: Tensor = calc_loss_batch(enc_input, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    average_loss: float = total_loss / num_batches\n",
    "\n",
    "    return average_loss\n",
    "\n",
    "\n",
    "def calc_accuracy_loader(\n",
    "    data_loader: DataLoader,\n",
    "    model: nn.Module,\n",
    "    device: str | torch.device,\n",
    "    num_batches: int | None = None,\n",
    ") -> float:\n",
    "    \"\"\"Calculates the accuracy of a model on a given data loader.\n",
    "\n",
    "    Args:\n",
    "        data_loader (DataLoader): The data loader containing the input data and target labels.\n",
    "        model (torch.nn.Module): The model to be evaluated.\n",
    "        device (torch.device): The device (CPU or GPU) to use for the evaluation.\n",
    "        num_batches (int, optional): The maximum number of batches to evaluate. If None, all\n",
    "        batches in the data loader will be used.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the data loader.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    correct_predictions: int = 0\n",
    "    num_examples: int = 0\n",
    "\n",
    "    num_batches = _get_num_batches(data_loader, num_batches)\n",
    "\n",
    "    for idx, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if idx < num_batches:\n",
    "            # Move each element of input_batch to the device\n",
    "            enc_input: dict[str, Any] = {\n",
    "                key: value.to(device) for key, value in input_batch.items()\n",
    "            }\n",
    "            target_batch: Tensor = target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits: Tensor = model(enc_input)\n",
    "            predicted_labels: Tensor = torch.argmax(logits, dim=-1)\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "        else:\n",
    "            break\n",
    "    accuracy: float = correct_predictions / num_examples\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    eval_iter: int,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the performance of the given model on the training and validation data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to evaluate.\n",
    "        train_loader (DataLoader): The training data loader.\n",
    "        val_loader (DataLoader): The validation data loader.\n",
    "        device (torch.device): The device to use for evaluation (CPU or GPU).\n",
    "        eval_iter (int): The number of evaluation iterations to run.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following:\n",
    "            - train_loss (float): The average training loss.\n",
    "            - val_loss (float): The average validation loss.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "    model.train()  # Reset the model to training mode.\n",
    "\n",
    "    return (train_loss, val_loss)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str | torch.device,\n",
    "    num_epochs: int,\n",
    "    eval_freq: int,\n",
    "    eval_iter: int,\n",
    ") -> None:\n",
    "    \"\"\"Trains a model on a given dataset using a given optimizer and criterion.\"\"\"\n",
    "    # Initialize lists to track losses, accuracies and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss: Tensor = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += len(input_batch[\"input_ids\"])\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional: Evaluate after each batch\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(  # noqa\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Calculate the accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")  # noqa\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")  # noqa\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test The Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14583333333333334\n",
      "tensor(1.3447, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.423450509707133"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device: str | torch.device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "sample_loader: DataLoader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=tokenization_collate_fn,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# Using tokenization_collate_fn\n",
    "for input_batch, target_batch in sample_loader:\n",
    "    break\n",
    "\n",
    "print(\n",
    "    calc_accuracy_loader(\n",
    "        data_loader=train_loader, model=model, device=device, num_batches=3\n",
    "    )\n",
    ")\n",
    "print(calc_loss_batch(input_batch, target_batch, model, device))\n",
    "calc_loss_loader(sample_loader, model, device, num_batches=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">362</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>\n",
       "Training params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">087</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">872</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total params: \u001b[1;36m66\u001b[0m,\u001b[1;36m362\u001b[0m,\u001b[1;36m880\u001b[0m\n",
       "Training params: \u001b[1;36m7\u001b[0m,\u001b[1;36m087\u001b[0m,\u001b[1;36m872\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SpendClassifier</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>backbone<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BackBone</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>backbone<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DistilBertModel</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span>embeddings<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embeddings</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>word_embeddings<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30522</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding_idx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>position_embeddings<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>transformer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Transformer</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>layer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TransformerBlock</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>attention<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MultiHeadSelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>q_lin<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>k_lin<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>v_lin<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>out_lin<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>sa_layer_norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>ffn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FFN</span><span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>lin1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>lin2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>activation<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>output_layer_norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SoftmaxHead</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Softmax</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">dim</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSpendClassifier\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mbackbone\u001b[1m)\u001b[0m: \u001b[1;35mBackBone\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mbackbone\u001b[1m)\u001b[0m: \u001b[1;35mDistilBertModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mword_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m30522\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[33mpadding_idx\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mposition_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mLayerNorm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-12\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mtransformer\u001b[1m)\u001b[0m: \u001b[1;35mTransformer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayer\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m6\u001b[0m x \u001b[1;35mTransformerBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mattention\u001b[1m)\u001b[0m: \u001b[1;35mMultiHeadSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mq_lin\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mk_lin\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mv_lin\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mout_lin\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0msa_layer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-12\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mffn\u001b[1m)\u001b[0m: \u001b[1;35mFFN\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlin1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlin2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0moutput_layer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-12\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mhead\u001b[1m)\u001b[0m: \u001b[1;35mSoftmaxHead\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mhead\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSoftmax\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdim\u001b[0m=\u001b[1;36m-1\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fine_tune: bool = True\n",
    "\n",
    "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)\n",
    "transformation = Transformation(tokenizer=tokenizer, max_length=max_length)\n",
    "backbone: BackBone = BackBone(\n",
    "    pretrained_model_name_or_path=pretrained_model_name_or_path, fine_tune=fine_tune\n",
    ")\n",
    "head: SoftmaxHead = SoftmaxHead(emb_dim=config.dim, num_classes=num_classes)\n",
    "model: SpendClassifier = SpendClassifier(backbone=backbone, head=head)\n",
    "console.print(\n",
    "    f\"Total params: {model.backbone.total_params:,}\\nTraining params: {model.backbone.trainable_params:,}\\n\"\n",
    ")\n",
    "console.print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEFORE Fine Tuning ===\n",
      "Training accuracy: 28.75%\n",
      "Validation accuracy: 31.87%\n",
      "Test accuracy: 24.38%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== BEFORE Fine Tuning ===\")\n",
    "torch.manual_seed(123)\n",
    "\n",
    "device: str | torch.device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "train_accuracy: float = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy: float = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy: float = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Train (Fine-Tune) The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "num_epochs: int = 5\n",
    "eval_freq: int = 100\n",
    "eval_iter: int = 5  # number of batches\n",
    "learning_rate = 3e-5\n",
    "weight_decay = 0.1\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.384, Val loss 1.369\n",
      "Ep 1 (Step 000100): Train loss 1.082, Val loss 0.986\n",
      "Ep 1 (Step 000200): Train loss 0.953, Val loss 0.898\n",
      "Ep 1 (Step 000300): Train loss 0.909, Val loss 0.836\n",
      "Ep 1 (Step 000400): Train loss 0.811, Val loss 0.826\n",
      "Ep 1 (Step 000500): Train loss 0.841, Val loss 0.823\n",
      "Ep 1 (Step 000600): Train loss 0.810, Val loss 0.788\n",
      "Ep 1 (Step 000700): Train loss 0.761, Val loss 0.796\n",
      "Ep 1 (Step 000800): Train loss 0.766, Val loss 0.781\n",
      "Ep 1 (Step 000900): Train loss 0.782, Val loss 0.784\n",
      "Ep 1 (Step 001000): Train loss 0.795, Val loss 0.770\n",
      "Training accuracy: 96.25% | Validation accuracy: 96.25%\n",
      "Ep 2 (Step 001100): Train loss 0.782, Val loss 0.773\n",
      "Ep 2 (Step 001200): Train loss 0.778, Val loss 0.779\n",
      "Ep 2 (Step 001300): Train loss 0.771, Val loss 0.779\n",
      "Ep 2 (Step 001400): Train loss 0.779, Val loss 0.779\n",
      "Ep 2 (Step 001500): Train loss 0.768, Val loss 0.774\n",
      "Ep 2 (Step 001600): Train loss 0.782, Val loss 0.780\n",
      "Ep 2 (Step 001700): Train loss 0.746, Val loss 0.776\n",
      "Ep 2 (Step 001800): Train loss 0.750, Val loss 0.777\n",
      "Ep 2 (Step 001900): Train loss 0.783, Val loss 0.771\n",
      "Ep 2 (Step 002000): Train loss 0.819, Val loss 0.779\n",
      "Training accuracy: 98.75% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 002100): Train loss 0.800, Val loss 0.780\n",
      "Ep 3 (Step 002200): Train loss 0.785, Val loss 0.777\n",
      "Ep 3 (Step 002300): Train loss 0.744, Val loss 0.776\n",
      "Ep 3 (Step 002400): Train loss 0.798, Val loss 0.770\n",
      "Ep 3 (Step 002500): Train loss 0.747, Val loss 0.769\n",
      "Ep 3 (Step 002600): Train loss 0.769, Val loss 0.769\n",
      "Ep 3 (Step 002700): Train loss 0.756, Val loss 0.769\n",
      "Ep 3 (Step 002800): Train loss 0.748, Val loss 0.766\n",
      "Ep 3 (Step 002900): Train loss 0.782, Val loss 0.771\n",
      "Ep 3 (Step 003000): Train loss 0.757, Val loss 0.768\n",
      "Training accuracy: 96.25% | Validation accuracy: 97.50%\n",
      "Ep 4 (Step 003100): Train loss 0.771, Val loss 0.767\n",
      "Ep 4 (Step 003200): Train loss 0.775, Val loss 0.767\n",
      "Ep 4 (Step 003300): Train loss 0.744, Val loss 0.765\n",
      "Ep 4 (Step 003400): Train loss 0.768, Val loss 0.768\n",
      "Ep 4 (Step 003500): Train loss 0.754, Val loss 0.767\n",
      "Ep 4 (Step 003600): Train loss 0.746, Val loss 0.768\n",
      "Ep 4 (Step 003700): Train loss 0.784, Val loss 0.772\n",
      "Ep 4 (Step 003800): Train loss 0.769, Val loss 0.771\n",
      "Ep 4 (Step 003900): Train loss 0.781, Val loss 0.764\n",
      "Ep 4 (Step 004000): Train loss 0.756, Val loss 0.767\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 004100): Train loss 0.757, Val loss 0.757\n",
      "Ep 5 (Step 004200): Train loss 0.803, Val loss 0.756\n",
      "Ep 5 (Step 004300): Train loss 0.780, Val loss 0.756\n",
      "Ep 5 (Step 004400): Train loss 0.744, Val loss 0.756\n",
      "Ep 5 (Step 004500): Train loss 0.769, Val loss 0.756\n",
      "Ep 5 (Step 004600): Train loss 0.756, Val loss 0.761\n",
      "Ep 5 (Step 004700): Train loss 0.746, Val loss 0.757\n",
      "Ep 5 (Step 004800): Train loss 0.755, Val loss 0.756\n",
      "Ep 5 (Step 004900): Train loss 0.744, Val loss 0.756\n",
      "Ep 5 (Step 005000): Train loss 0.754, Val loss 0.756\n",
      "Training accuracy: 98.75% | Validation accuracy: 98.75%\n",
      "Training completed in 19.58 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "start_time: float = time.time()\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=eval_freq,\n",
    "    eval_iter=eval_iter,\n",
    ")\n",
    "\n",
    "end_time: float = time.time()\n",
    "execution_time_minutes: float = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_eval import plot_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor: Tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor: Tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(\n",
    "    epochs_tensor, examples_seen_tensor, train_losses, val_losses, save_plot=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor: Tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor: Tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(\n",
    "    epochs_tensor,\n",
    "    examples_seen_tensor,\n",
    "    train_accs,\n",
    "    val_accs,\n",
    "    label=\"accuracy\",\n",
    "    save_plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 98.49%\n",
      "Validation accuracy: 98.17%\n",
      "Test accuracy: 97.95%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy: float = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy: float = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy: float = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_transaction(\n",
    "    text: str, model: nn.Module, transformation: Any, device: str | torch.device\n",
    ") -> dict[str, Any]:\n",
    "    model.eval()\n",
    "\n",
    "    labels: list[str] = [\"bills\", \"loan\", \"savingsAndInvestments\", \"noSpend\"]\n",
    "    cleaned_text: str = (\n",
    "        DataCleaner(data=pl.DataFrame(data={\"text\": text}))\n",
    "        .prepare_data()\n",
    "        .select([\"cleaned_text\"])\n",
    "        .to_series()\n",
    "        .to_list()[0]\n",
    "    )\n",
    "\n",
    "    encoded_input: BatchEncoding = transformation(cleaned_text)\n",
    "    # Move each element of input_batch to the device\n",
    "    enc_input: dict[str, Any] = {\n",
    "        key: value.to(device) for key, value in encoded_input.items()\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits: torch.Tensor = model(enc_input)\n",
    "    probas: Tensor = F.softmax(logits, dim=-1).squeeze(0)\n",
    "\n",
    "    spend_labels: list[tuple[str, int]] = [\n",
    "        (label, round(proba.item(), 2)) for label, proba in zip(labels, probas)\n",
    "    ]\n",
    "    # Sort using the proba\n",
    "    spend_labels = sorted(spend_labels, key=lambda x: x[1], reverse=True)\n",
    "    sorted_spend_labels: list[dict[str, float]] = [\n",
    "        {label: proba} for label, proba in spend_labels\n",
    "    ]\n",
    "\n",
    "    return {\"transaction\": text, \"spend_labels\": sorted_spend_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save And Load Model\n",
    "\n",
    "\n",
    "```python\n",
    "# Save\n",
    "torch.save(model.state_dict(), \"model_name.pth\")\n",
    "\n",
    "\n",
    "# Load\n",
    "model_state_dict = torch.load(\"model_name.pth\")\n",
    "model.load_state_dict(model_state_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "# torch.save(model.state_dict(), \"models/hf_spend_classifier.pth\")\n",
    "\n",
    "# Load Model\n",
    "model_state_dict = torch.load(\"models/hf_spend_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'transaction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Payment of Bolt Fare to Philip'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'spend_labels'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bills'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.47</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'loan'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'savingsAndInvestments'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'noSpend'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18</span><span style=\"font-weight: bold\">}]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'transaction'\u001b[0m: \u001b[32m'Payment of Bolt Fare to Philip'\u001b[0m,\n",
       "    \u001b[32m'spend_labels'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'bills'\u001b[0m: \u001b[1;36m0.47\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'loan'\u001b[0m: \u001b[1;36m0.18\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'savingsAndInvestments'\u001b[0m: \u001b[1;36m0.18\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'noSpend'\u001b[0m: \u001b[1;36m0.18\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bills\n",
    "text_1: str = \"Payment of Bolt Fare to Philip\"\n",
    "\n",
    "console.print(classify_transaction(text_1, model, transformation, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'transaction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'TRF/Monthly contribution /FRM JOSEPH DOE TO MIKE'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'spend_labels'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'savingsAndInvestments'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.47</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bills'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'loan'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'noSpend'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18</span><span style=\"font-weight: bold\">}]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'transaction'\u001b[0m: \u001b[32m'TRF/Monthly contribution /FRM JOSEPH DOE TO MIKE'\u001b[0m,\n",
       "    \u001b[32m'spend_labels'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'savingsAndInvestments'\u001b[0m: \u001b[1;36m0.47\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'bills'\u001b[0m: \u001b[1;36m0.18\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'loan'\u001b[0m: \u001b[1;36m0.18\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'noSpend'\u001b[0m: \u001b[1;36m0.18\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Savings\n",
    "text_1: str = \"TRF/Monthly contribution /FRM JOSEPH DOE TO MIKE\"\n",
    "\n",
    "console.print(classify_transaction(text_1, model, transformation, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'transaction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'REV-MONNIFY / FairMoney-Jane Doe- 022'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'spend_labels'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'loan'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.48</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bills'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'savingsAndInvestments'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'noSpend'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">}]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'transaction'\u001b[0m: \u001b[32m'REV-MONNIFY / FairMoney-Jane Doe- 022'\u001b[0m,\n",
       "    \u001b[32m'spend_labels'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'loan'\u001b[0m: \u001b[1;36m0.48\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'bills'\u001b[0m: \u001b[1;36m0.17\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'savingsAndInvestments'\u001b[0m: \u001b[1;36m0.17\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'noSpend'\u001b[0m: \u001b[1;36m0.17\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loan\n",
    "text_1: str = \"REV-MONNIFY / FairMoney-Jane Doe- 022\"\n",
    "\n",
    "console.print(classify_transaction(text_1, model, transformation, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'transaction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Trf from Neidu to Femi'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'spend_labels'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'noSpend'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.48</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bills'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'loan'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'savingsAndInvestments'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">}]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'transaction'\u001b[0m: \u001b[32m'Trf from Neidu to Femi'\u001b[0m,\n",
       "    \u001b[32m'spend_labels'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'noSpend'\u001b[0m: \u001b[1;36m0.48\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'bills'\u001b[0m: \u001b[1;36m0.17\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'loan'\u001b[0m: \u001b[1;36m0.17\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'savingsAndInvestments'\u001b[0m: \u001b[1;36m0.17\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NoSpend\n",
    "text_1: str = \"Trf from Neidu to Femi\"\n",
    "\n",
    "console.print(classify_transaction(text_1, model, transformation, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'transaction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a a rano nig'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'spend_labels'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'noSpend'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.48</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bills'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'loan'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'savingsAndInvestments'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">}]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'transaction'\u001b[0m: \u001b[32m'a a rano nig'\u001b[0m,\n",
       "    \u001b[32m'spend_labels'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'noSpend'\u001b[0m: \u001b[1;36m0.48\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'bills'\u001b[0m: \u001b[1;36m0.17\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'loan'\u001b[0m: \u001b[1;36m0.17\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'savingsAndInvestments'\u001b[0m: \u001b[1;36m0.17\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_1: str = \"a a rano nig\"\n",
    "\n",
    "console.print(classify_transaction(text_1, model, transformation, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>nuban</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>desc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35295</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal Liquidation 099ILAT2222305WW 220811001238AF54</td>\n",
       "      <td>loan</td>\n",
       "      <td>principal liquidation ilatww af</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35641</td>\n",
       "      <td>1</td>\n",
       "      <td>POS/WEB PMT PALMCREDIT/1879176020 PSTK LANG</td>\n",
       "      <td>loan</td>\n",
       "      <td>pos web pmt palmcredit  pstk lang</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35542</td>\n",
       "      <td>1</td>\n",
       "      <td>Main Interest Liquidation 099ILAT21330000N 211126054644CD14</td>\n",
       "      <td>loan</td>\n",
       "      <td>main interest liquidation ilatn cd</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34100</td>\n",
       "      <td>1</td>\n",
       "      <td>Main Interest Liquidation 099ILAT2223706QY 2208252054344587</td>\n",
       "      <td>loan</td>\n",
       "      <td>main interest liquidation ilatqy</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34197</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal Liquidation 099ILAT222620076 2209190807442EB9</td>\n",
       "      <td>loan</td>\n",
       "      <td>principal liquidation ilat eb</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34981</td>\n",
       "      <td>1</td>\n",
       "      <td>TRF//FRM OGUNGBE ABAYOMI SAMUEL TO  / FairMoney-Aba MONNIFY - 232</td>\n",
       "      <td>loan</td>\n",
       "      <td>trf frm ogungbe abayomi samuel fairmoney aba monnify</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34544</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal Liquidation 099ILAT2219700CA 2207161204274A0E</td>\n",
       "      <td>loan</td>\n",
       "      <td>principal liquidation ilatca ae</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34726</td>\n",
       "      <td>1</td>\n",
       "      <td>CASHIGO INTERNATIONAL LIMITED- 057</td>\n",
       "      <td>loan</td>\n",
       "      <td>cashigo international limited</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35559</td>\n",
       "      <td>1</td>\n",
       "      <td>Main Interest Liquidation 099ILAT2225100IS 22090814054198C5</td>\n",
       "      <td>loan</td>\n",
       "      <td>main interest liquidation ilatis c</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35675</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal Liquidation 099ILAT21329047Q 211125122144CFF8</td>\n",
       "      <td>loan</td>\n",
       "      <td>principal liquidation ilatq cff</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34664</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal Liquidation 099ILAT2224903P7 2209062133335E7F</td>\n",
       "      <td>loan</td>\n",
       "      <td>principal liquidation ilatp ef</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34664</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal Liquidation 099ILAT2224903P7 2209062133335E7F</td>\n",
       "      <td>loan</td>\n",
       "      <td>principal liquidation ilatp ef</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>35766</td>\n",
       "      <td>1</td>\n",
       "      <td>TRF/Loan refund/FRM AJAYI BOLANLE J. TO  LUQMAN OLUWA ABIMBOLA - 232</td>\n",
       "      <td>loan</td>\n",
       "      <td>trf loan refund frm ajayi bolanle j luqman oluwa abimbola</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33936</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal Liquidation 099ILAT2132900I9 211125204730F5EC</td>\n",
       "      <td>loan</td>\n",
       "      <td>principal liquidation ilati fec</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35476</td>\n",
       "      <td>1</td>\n",
       "      <td>Main Interest Liquidation 099ILAT2132100H0 21111716173510F2</td>\n",
       "      <td>loan</td>\n",
       "      <td>main interest liquidation ilath f</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34150</td>\n",
       "      <td>1</td>\n",
       "      <td>Main Interest Liquidation 099ILAT2231504FN 2211111651005901</td>\n",
       "      <td>loan</td>\n",
       "      <td>main interest liquidation ilatfn</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35988</td>\n",
       "      <td>1</td>\n",
       "      <td>TRF/Loan from MEVA FLOURISH DAILY GLOBAL ENT/FRM IBENWA JANE UJUNWA TO  MARIAM IGE - 033</td>\n",
       "      <td>loan</td>\n",
       "      <td>trf loan meva flourish daily global ent frm ibenwa jane ujunwa mariam ige</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34619</td>\n",
       "      <td>1</td>\n",
       "      <td>Main Interest Liquidation 099ILAT2229101XC 22101810000720DB</td>\n",
       "      <td>loan</td>\n",
       "      <td>main interest liquidation ilatxc db</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>34596</td>\n",
       "      <td>1</td>\n",
       "      <td>TRF/Loan payment /FRM HAASTRUP ALEXANDER ADESINA TO HAASTRUP IYABO395233</td>\n",
       "      <td>loan</td>\n",
       "      <td>trf loan payment frm haastrup alexander adesina haastrup iyabo</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34344</td>\n",
       "      <td>1</td>\n",
       "      <td>Main Interest Liquidation 099ILAT2213900K7 220519180553D04B</td>\n",
       "      <td>loan</td>\n",
       "      <td>main interest liquidation ilatk db</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  nuban  \\\n",
       "0        35295      1   \n",
       "1        35641      1   \n",
       "2        35542      1   \n",
       "3        34100      1   \n",
       "4        34197      1   \n",
       "5        34981      1   \n",
       "6        34544      1   \n",
       "7        34726      1   \n",
       "8        35559      1   \n",
       "9        35675      1   \n",
       "10       34664      1   \n",
       "11       34664      1   \n",
       "12       35766      1   \n",
       "13       33936      1   \n",
       "14       35476      1   \n",
       "15       34150      1   \n",
       "16       35988      1   \n",
       "17       34619      1   \n",
       "18       34596      1   \n",
       "19       34344      1   \n",
       "\n",
       "                                                                                 description  \\\n",
       "0                                    Principal Liquidation 099ILAT2222305WW 220811001238AF54   \n",
       "1                                               POS/WEB PMT PALMCREDIT/1879176020 PSTK LANG    \n",
       "2                                Main Interest Liquidation 099ILAT21330000N 211126054644CD14   \n",
       "3                                Main Interest Liquidation 099ILAT2223706QY 2208252054344587   \n",
       "4                                    Principal Liquidation 099ILAT222620076 2209190807442EB9   \n",
       "5                          TRF//FRM OGUNGBE ABAYOMI SAMUEL TO  / FairMoney-Aba MONNIFY - 232   \n",
       "6                                    Principal Liquidation 099ILAT2219700CA 2207161204274A0E   \n",
       "7                                                         CASHIGO INTERNATIONAL LIMITED- 057   \n",
       "8                                Main Interest Liquidation 099ILAT2225100IS 22090814054198C5   \n",
       "9                                    Principal Liquidation 099ILAT21329047Q 211125122144CFF8   \n",
       "10                                   Principal Liquidation 099ILAT2224903P7 2209062133335E7F   \n",
       "11                                   Principal Liquidation 099ILAT2224903P7 2209062133335E7F   \n",
       "12                      TRF/Loan refund/FRM AJAYI BOLANLE J. TO  LUQMAN OLUWA ABIMBOLA - 232   \n",
       "13                                   Principal Liquidation 099ILAT2132900I9 211125204730F5EC   \n",
       "14                               Main Interest Liquidation 099ILAT2132100H0 21111716173510F2   \n",
       "15                               Main Interest Liquidation 099ILAT2231504FN 2211111651005901   \n",
       "16  TRF/Loan from MEVA FLOURISH DAILY GLOBAL ENT/FRM IBENWA JANE UJUNWA TO  MARIAM IGE - 033   \n",
       "17                               Main Interest Liquidation 099ILAT2229101XC 22101810000720DB   \n",
       "18                  TRF/Loan payment /FRM HAASTRUP ALEXANDER ADESINA TO HAASTRUP IYABO395233   \n",
       "19                               Main Interest Liquidation 099ILAT2213900K7 220519180553D04B   \n",
       "\n",
       "   label  \\\n",
       "0   loan   \n",
       "1   loan   \n",
       "2   loan   \n",
       "3   loan   \n",
       "4   loan   \n",
       "5   loan   \n",
       "6   loan   \n",
       "7   loan   \n",
       "8   loan   \n",
       "9   loan   \n",
       "10  loan   \n",
       "11  loan   \n",
       "12  loan   \n",
       "13  loan   \n",
       "14  loan   \n",
       "15  loan   \n",
       "16  loan   \n",
       "17  loan   \n",
       "18  loan   \n",
       "19  loan   \n",
       "\n",
       "                                                                  cleaned_text  \\\n",
       "0                                              principal liquidation ilatww af   \n",
       "1                                            pos web pmt palmcredit  pstk lang   \n",
       "2                                           main interest liquidation ilatn cd   \n",
       "3                                            main interest liquidation ilatqy    \n",
       "4                                                principal liquidation ilat eb   \n",
       "5                        trf frm ogungbe abayomi samuel fairmoney aba monnify    \n",
       "6                                              principal liquidation ilatca ae   \n",
       "7                                               cashigo international limited    \n",
       "8                                           main interest liquidation ilatis c   \n",
       "9                                              principal liquidation ilatq cff   \n",
       "10                                              principal liquidation ilatp ef   \n",
       "11                                              principal liquidation ilatp ef   \n",
       "12                  trf loan refund frm ajayi bolanle j luqman oluwa abimbola    \n",
       "13                                             principal liquidation ilati fec   \n",
       "14                                           main interest liquidation ilath f   \n",
       "15                                           main interest liquidation ilatfn    \n",
       "16  trf loan meva flourish daily global ent frm ibenwa jane ujunwa mariam ige    \n",
       "17                                         main interest liquidation ilatxc db   \n",
       "18              trf loan payment frm haastrup alexander adesina haastrup iyabo   \n",
       "19                                          main interest liquidation ilatk db   \n",
       "\n",
       "    desc_length  \n",
       "0            31  \n",
       "1            33  \n",
       "2            34  \n",
       "3            33  \n",
       "4            29  \n",
       "5            53  \n",
       "6            31  \n",
       "7            30  \n",
       "8            34  \n",
       "9            31  \n",
       "10           30  \n",
       "11           30  \n",
       "12           58  \n",
       "13           31  \n",
       "14           33  \n",
       "15           33  \n",
       "16           74  \n",
       "17           35  \n",
       "18           62  \n",
       "19           34  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(pl.col(\"label\").str.contains(\"loan\")).sample(n=20).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: 1,742,257 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8549</td>\n",
       "      <td>FGN ELECTRONIC MONEY TRANSFER LEVY</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.spendOnTransfers, cashflow.firstDay, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8549</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.ussdTransactions, cashflow.firstDay, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8549</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.ussdTransactions, cashflow.firstDay, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8549</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.ussdTransactions, cashflow.firstDay, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8549</td>\n",
       "      <td>Quantum USSD</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.ussdTransactions, cashflow.firstDay, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id                         description  \\\n",
       "0        8549  FGN ELECTRONIC MONEY TRANSFER LEVY   \n",
       "1        8549                        Quantum USSD   \n",
       "2        8549                        Quantum USSD   \n",
       "3        8549                        Quantum USSD   \n",
       "4        8549                        Quantum USSD   \n",
       "\n",
       "                                                                                                                                                                                                                                                            tags  \n",
       "0  balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.spendOnTransfers, cashflow.firstDay, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "1                                           balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.ussdTransactions, cashflow.firstDay, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange  \n",
       "2                                           balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.ussdTransactions, cashflow.firstDay, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange  \n",
       "3                                           balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.ussdTransactions, cashflow.firstDay, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange  \n",
       "4                                           balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.ussdTransactions, cashflow.firstDay, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp: str = \"../data_prep/trans_TAGS_4.parquet\"\n",
    "unseen_data: pl.DataFrame = (\n",
    "    pl.read_parquet(fp)\n",
    "    .filter(pl.col(\"type\").str.contains(\"D\"))\n",
    "    .drop([\"nuban\", \"date\", \"type\", \"amount\"])\n",
    ")\n",
    "print(f\"Shape of data: {unseen_data.shape[0]:,} \\n\")\n",
    "unseen_data = unseen_data.with_columns(\n",
    "    tags=pl.col(\"tags\").map_elements(lambda x: \", \".join(x))\n",
    ")\n",
    "unseen_data.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7669</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1679560504 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7546</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1945072675 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8619</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/2365489167 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8096</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/2059320772 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8166</td>\n",
       "      <td>TRF/Thanks/FRM OLUNIYI ADEYEMI OLUGBILE TO PIGGYVEST/ENIOLAKOLADE PRAISE- 035</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.savingsAndInvestments, spend.spendOnTransfers, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8248</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1767570624 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8215</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1636361639 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8096</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1935167297 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8610</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1791820837 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8096</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/2116189151 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8339</td>\n",
       "      <td>TRF//FRM ISAAC SUNDAY GODWIN TO PIGGYVEST/ISAACGODWIN SUNDAY- 035</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.savingsAndInvestments, spend.spendOnTransfers, transactionpattern.recurringExpense, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8730</td>\n",
       "      <td>POS/WEB PMT COWRYWISE /1656124987 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7570</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/2043560647 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9046</td>\n",
       "      <td>POS/WEB PMT COWRYWISE/BSLH0142110270 LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8046</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1982594220 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8538</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/2106571475 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8619</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/2230205540 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9531</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1826767933 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8096</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1911555222 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9662</td>\n",
       "      <td>POS/WEB PMT PIGGYVEST/1798121846 PSTK LANG</td>\n",
       "      <td>balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  \\\n",
       "0         7669   \n",
       "1         7546   \n",
       "2         8619   \n",
       "3         8096   \n",
       "4         8166   \n",
       "5         8248   \n",
       "6         8215   \n",
       "7         8096   \n",
       "8         8610   \n",
       "9         8096   \n",
       "10        8339   \n",
       "11        8730   \n",
       "12        7570   \n",
       "13        9046   \n",
       "14        8046   \n",
       "15        8538   \n",
       "16        8619   \n",
       "17        9531   \n",
       "18        8096   \n",
       "19        9662   \n",
       "\n",
       "                                                                      description  \\\n",
       "0                                     POS/WEB PMT PIGGYVEST/1679560504 PSTK LANG    \n",
       "1                                     POS/WEB PMT PIGGYVEST/1945072675 PSTK LANG    \n",
       "2                                     POS/WEB PMT PIGGYVEST/2365489167 PSTK LANG    \n",
       "3                                     POS/WEB PMT PIGGYVEST/2059320772 PSTK LANG    \n",
       "4   TRF/Thanks/FRM OLUNIYI ADEYEMI OLUGBILE TO PIGGYVEST/ENIOLAKOLADE PRAISE- 035   \n",
       "5                                     POS/WEB PMT PIGGYVEST/1767570624 PSTK LANG    \n",
       "6                                     POS/WEB PMT PIGGYVEST/1636361639 PSTK LANG    \n",
       "7                                     POS/WEB PMT PIGGYVEST/1935167297 PSTK LANG    \n",
       "8                                     POS/WEB PMT PIGGYVEST/1791820837 PSTK LANG    \n",
       "9                                     POS/WEB PMT PIGGYVEST/2116189151 PSTK LANG    \n",
       "10              TRF//FRM ISAAC SUNDAY GODWIN TO PIGGYVEST/ISAACGODWIN SUNDAY- 035   \n",
       "11                                   POS/WEB PMT COWRYWISE /1656124987 PSTK LANG    \n",
       "12                                    POS/WEB PMT PIGGYVEST/2043560647 PSTK LANG    \n",
       "13                                     POS/WEB PMT COWRYWISE/BSLH0142110270 LANG    \n",
       "14                                    POS/WEB PMT PIGGYVEST/1982594220 PSTK LANG    \n",
       "15                                    POS/WEB PMT PIGGYVEST/2106571475 PSTK LANG    \n",
       "16                                    POS/WEB PMT PIGGYVEST/2230205540 PSTK LANG    \n",
       "17                                    POS/WEB PMT PIGGYVEST/1826767933 PSTK LANG    \n",
       "18                                    POS/WEB PMT PIGGYVEST/1911555222 PSTK LANG    \n",
       "19                                    POS/WEB PMT PIGGYVEST/1798121846 PSTK LANG    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                    tags  \n",
       "0   balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "1   balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "2                                        balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "3   balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "4                                                                                         balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.savingsAndInvestments, spend.spendOnTransfers, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange  \n",
       "5                                        balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "6                                        balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "7                                        balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "8   balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "9   balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "10                                                   balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.savingsAndInvestments, spend.spendOnTransfers, transactionpattern.recurringExpense, transactionpattern.transactionBetween10000And100000, transactionpattern.mostFrequentBalanceRange  \n",
       "11                                       balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "12                                       balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "13                                       balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "14                                       balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "15                                       balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "16                                       balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "17  balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.recurringExpense, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "18                                       balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  \n",
       "19                                       balance, behavioural.accountSweep, behavioural.inflowOutflowRate, debit, spend.posSpend, spend.savingsAndInvestments, spend.webSpend, transactionpattern.transactionLessThan10000, transactionpattern.mostFrequentTransactionRange, transactionpattern.mostFrequentBalanceRange  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_data.filter(pl.col(\"tags\").str.contains(\"savings\")).sample(n=20).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cfb88397-e54b-11ee-8a77-025b06f85973</td>\n",
       "      <td>70000.00</td>\n",
       "      <td>TRANSFER BETWEEN CUSTOMERS via Internet Banking Lexus GX460 Rental-23/09/2022 from BABAOYE OLASUBOMI THADDEUS to KINGZ AUTOS RENTAL SERVICES</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween10000And100000\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2b6305d7-0d0c-11ef-8a77-025b06f85973</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>TRANSFER BETWEEN CUSTOMERS Via USSD GTBank Transfer 00000000201018045621509143070000 50000202208231225/21.5/6.98 from BABAOYE OLASUBOMI THADDEUS to KINGZ AUTOS RENTAL SERVICES</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"spend.ussdTransactions\", \"transactionpattern.recurringExpense\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afe19ced-d094-11ee-8a77-025b06f85973</td>\n",
       "      <td>126962.66</td>\n",
       "      <td>RESTRUCTURE FEES</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween100000And500000\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32307b42-e125-11ee-8a77-025b06f85973</td>\n",
       "      <td>89574.68</td>\n",
       "      <td>MANAGEMENT FEES</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bankCharges\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>753f1aaa-d643-11ee-8a77-025b06f85973</td>\n",
       "      <td>114592.08</td>\n",
       "      <td>total ss</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween100000And500000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>227824ac-d62c-11ee-8a77-025b06f85973</td>\n",
       "      <td>15000.00</td>\n",
       "      <td>petroleum</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86b914fa-1918-11ef-8a77-025b06f85973</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>TRANSFER BETWEEN CUSTOMERS Via USSD GTBank Transfer 00000000201018045621509143070000 50000202208231225/21.5/6.98 from BABAOYE OLASUBOMI THADDEUS to KINGZ AUTOS RENTAL SERVICES</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"spend.ussdTransactions\", \"transactionpattern.recurringExpense\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73e0dc4a-06e4-11ef-8a77-025b06f85973</td>\n",
       "      <td>126962.66</td>\n",
       "      <td>RESTRUCTURE FEES</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween100000And500000\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eeaa102c-d701-11ee-8a77-025b06f85973</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>a a rano nig</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>753ee919-d643-11ee-8a77-025b06f85973</td>\n",
       "      <td>17000.00</td>\n",
       "      <td>fenchurch</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77b190c5-e853-11ee-8a77-025b06f85973</td>\n",
       "      <td>26000.00</td>\n",
       "      <td>NIBSS Instant Payment Outward 000013210923202833000341815026 via GTWORLD Initial payment for electrical work TO ABIODUN MOSES ADEOGUN 126.875/REF:GW2392739770000002600021092320 f</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.mobileSpend\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween10000And100000\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22785378-d62c-11ee-8a77-025b06f85973</td>\n",
       "      <td>27000.00</td>\n",
       "      <td>petrocam</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33b421a4-f582-11ee-8a77-025b06f85973</td>\n",
       "      <td>28000.00</td>\n",
       "      <td>BWORLDUSER Mobile Recharge/MTN Direct Top-up (Prepaid)/070537358263</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.airtime\", \"spend.bills\", \"spend.mobileSpend\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>86dfc452-1918-11ef-8a77-025b06f85973</td>\n",
       "      <td>126962.66</td>\n",
       "      <td>RESTRUCTURE FEES</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween100000And500000\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>501e0e93-0085-11ef-8a77-025b06f85973</td>\n",
       "      <td>28000.00</td>\n",
       "      <td>BWORLDUSER Mobile Recharge/MTN Direct Top-up (Prepaid)/070537358263</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.airtime\", \"spend.bills\", \"spend.mobileSpend\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6b9bc8c1-d643-11ee-8a77-025b06f85973</td>\n",
       "      <td>27000.00</td>\n",
       "      <td>petrocam</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2d351138-e13c-11ee-8a77-025b06f85973</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>NIBSS Instant Payment Outward 000013220807220302000383319028 lya Nikes Rent Refund for Oroyinyin St. TO AL-MONSOUR PROPERTIES LIMITED 53.75/REF:00001322080722030200038 3319028</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween100000And500000\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7d6867ad-137c-11ef-8a77-025b06f85973</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>TRANSFER BETWEEN CUSTOMERS via Internet Banking GX-460 rental 20th/21st/22nd Aug 2022 from BABAOYE OLASUBOMI THADDEUS to KINGZ AUTOS RENTAL SERVICES</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween100000And500000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dff9b3f7-d670-11ee-8a77-025b06f85973</td>\n",
       "      <td>50161.25</td>\n",
       "      <td>TRANSFER BETWEEN CUSTOMERS 771652893432|140550249699|nnpcfawhak@gmail.c om|NNPC RETAIL LIMITED|08034009534|DEPARTMENT OF PETROLEUM RESOURCES (DPR) - 02320020150161.25999T REF:02392739770000002050P00501612500000000 000079439766</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>eea81808-d701-11ee-8a77-025b06f85973</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>transfer commission</td>\n",
       "      <td>[\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bankCharges\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id     amount  \\\n",
       "0   cfb88397-e54b-11ee-8a77-025b06f85973   70000.00   \n",
       "1   2b6305d7-0d0c-11ef-8a77-025b06f85973   50000.00   \n",
       "2   afe19ced-d094-11ee-8a77-025b06f85973  126962.66   \n",
       "3   32307b42-e125-11ee-8a77-025b06f85973   89574.68   \n",
       "4   753f1aaa-d643-11ee-8a77-025b06f85973  114592.08   \n",
       "5   227824ac-d62c-11ee-8a77-025b06f85973   15000.00   \n",
       "6   86b914fa-1918-11ef-8a77-025b06f85973   50000.00   \n",
       "7   73e0dc4a-06e4-11ef-8a77-025b06f85973  126962.66   \n",
       "8   eeaa102c-d701-11ee-8a77-025b06f85973   20000.00   \n",
       "9   753ee919-d643-11ee-8a77-025b06f85973   17000.00   \n",
       "10  77b190c5-e853-11ee-8a77-025b06f85973   26000.00   \n",
       "11  22785378-d62c-11ee-8a77-025b06f85973   27000.00   \n",
       "12  33b421a4-f582-11ee-8a77-025b06f85973   28000.00   \n",
       "13  86dfc452-1918-11ef-8a77-025b06f85973  126962.66   \n",
       "14  501e0e93-0085-11ef-8a77-025b06f85973   28000.00   \n",
       "15  6b9bc8c1-d643-11ee-8a77-025b06f85973   27000.00   \n",
       "16  2d351138-e13c-11ee-8a77-025b06f85973  200000.00   \n",
       "17  7d6867ad-137c-11ef-8a77-025b06f85973  200000.00   \n",
       "18  dff9b3f7-d670-11ee-8a77-025b06f85973   50161.25   \n",
       "19  eea81808-d701-11ee-8a77-025b06f85973   20000.00   \n",
       "\n",
       "                                                                                                                                                                                                                            description  \\\n",
       "0                                                                                         TRANSFER BETWEEN CUSTOMERS via Internet Banking Lexus GX460 Rental-23/09/2022 from BABAOYE OLASUBOMI THADDEUS to KINGZ AUTOS RENTAL SERVICES    \n",
       "1                                                      TRANSFER BETWEEN CUSTOMERS Via USSD GTBank Transfer 00000000201018045621509143070000 50000202208231225/21.5/6.98 from BABAOYE OLASUBOMI THADDEUS to KINGZ AUTOS RENTAL SERVICES    \n",
       "2                                                                                                                                                                                                                     RESTRUCTURE FEES    \n",
       "3                                                                                                                                                                                                                      MANAGEMENT FEES    \n",
       "4                                                                                                                                                                                                                              total ss   \n",
       "5                                                                                                                                                                                                                             petroleum   \n",
       "6                                                      TRANSFER BETWEEN CUSTOMERS Via USSD GTBank Transfer 00000000201018045621509143070000 50000202208231225/21.5/6.98 from BABAOYE OLASUBOMI THADDEUS to KINGZ AUTOS RENTAL SERVICES    \n",
       "7                                                                                                                                                                                                                     RESTRUCTURE FEES    \n",
       "8                                                                                                                                                                                                                          a a rano nig   \n",
       "9                                                                                                                                                                                                                             fenchurch   \n",
       "10                                                  NIBSS Instant Payment Outward 000013210923202833000341815026 via GTWORLD Initial payment for electrical work TO ABIODUN MOSES ADEOGUN 126.875/REF:GW2392739770000002600021092320 f    \n",
       "11                                                                                                                                                                                                                             petrocam   \n",
       "12                                                                                                                                                                  BWORLDUSER Mobile Recharge/MTN Direct Top-up (Prepaid)/070537358263   \n",
       "13                                                                                                                                                                                                                    RESTRUCTURE FEES    \n",
       "14                                                                                                                                                                  BWORLDUSER Mobile Recharge/MTN Direct Top-up (Prepaid)/070537358263   \n",
       "15                                                                                                                                                                                                                             petrocam   \n",
       "16                                                     NIBSS Instant Payment Outward 000013220807220302000383319028 lya Nikes Rent Refund for Oroyinyin St. TO AL-MONSOUR PROPERTIES LIMITED 53.75/REF:00001322080722030200038 3319028    \n",
       "17                                                                                TRANSFER BETWEEN CUSTOMERS via Internet Banking GX-460 rental 20th/21st/22nd Aug 2022 from BABAOYE OLASUBOMI THADDEUS to KINGZ AUTOS RENTAL SERVICES    \n",
       "18  TRANSFER BETWEEN CUSTOMERS 771652893432|140550249699|nnpcfawhak@gmail.c om|NNPC RETAIL LIMITED|08034009534|DEPARTMENT OF PETROLEUM RESOURCES (DPR) - 02320020150161.25999T REF:02392739770000002050P00501612500000000 000079439766    \n",
       "19                                                                                                                                                                                                                  transfer commission   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                 tags  \n",
       "0                                                                                                                   [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween10000And100000\"]  \n",
       "1   [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"spend.ussdTransactions\", \"transactionpattern.recurringExpense\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "2                                                                                                                                            [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween100000And500000\"]  \n",
       "3                                                                                                                        [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bankCharges\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\"]  \n",
       "4                                                                                             [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween100000And500000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "5                                                                                              [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "6   [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"spend.ussdTransactions\", \"transactionpattern.recurringExpense\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "7                                                                                                                                            [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween100000And500000\"]  \n",
       "8                                                                                              [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "9                                                                                              [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "10                                                                                             [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.mobileSpend\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween10000And100000\"]  \n",
       "11                                                                                             [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "12                                                       [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.airtime\", \"spend.bills\", \"spend.mobileSpend\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "13                                                                                                                                           [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween100000And500000\"]  \n",
       "14                                                       [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.airtime\", \"spend.bills\", \"spend.mobileSpend\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "15                                                                                             [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "16                                                                                                                 [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween100000And500000\"]  \n",
       "17                                                                  [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween100000And500000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "18                                                                   [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  \n",
       "19                                              [\"balance\", \"behavioural.accountSweep\", \"behavioural.inflowOutflowRate\", \"debit\", \"spend.bankCharges\", \"spend.bills\", \"spend.spendOnTransfers\", \"transactionpattern.transactionBetween10000And100000\", \"transactionpattern.mostFrequentBalanceRange\"]  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp: str = \"../data_prep/staging_db.parquet\"\n",
    "unseen_data_2: pl.DataFrame = (\n",
    "    pl.read_parquet(fp)\n",
    "    .filter(pl.col(\"type\").str.contains(\"D\"))\n",
    "    .drop(\n",
    "        [\n",
    "            \"date\",\n",
    "            \"type\",\n",
    "            \"balance\",\n",
    "            # \"amount\",\n",
    "            \"created_at\",\n",
    "            \"updated_at\",\n",
    "            \"analysis_id\",\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# unseen_data_2.head().to_pandas()\n",
    "\n",
    "unseen_data_2.filter(\n",
    "    ((pl.col(\"tags\").str.contains(\"bills\")) & (pl.col(\"amount\").ge(15_000)))\n",
    ").sample(n=20).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch p_311",
   "language": "python",
   "name": "torch_p11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
