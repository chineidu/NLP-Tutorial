{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation For LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "numpy    : 1.26.4\n",
      "pandas   : 2.2.1\n",
      "polars   : 0.20.18\n",
      "torch    : 2.2.2\n",
      "lightning: 2.2.1\n",
      "\n",
      "conda environment: torch_p11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,torch,lightning --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characers: 20,479\n",
      "\n",
      "\n",
      "The first 100 characters: ========================================\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
     ]
    }
   ],
   "source": [
    "## Load the data\n",
    "fp: str = \"../../data/the-verdict.txt\"\n",
    "\n",
    "with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(f\"Total number of characers: {len(data):,}\\n\\n\")\n",
    "print(f\"The first 100 characters: {'====' * 10}\\n{data[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " ' ',\n",
       " 'HAD',\n",
       " ' ',\n",
       " 'always',\n",
       " ' ',\n",
       " 'thought',\n",
       " ' ',\n",
       " 'Jack',\n",
       " ' ',\n",
       " 'Gisburn',\n",
       " ' ',\n",
       " 'rather',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'cheap',\n",
       " ' ',\n",
       " 'genius',\n",
       " '--',\n",
       " 'though',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'good',\n",
       " ' ',\n",
       " 'fellow',\n",
       " ' ',\n",
       " 'enough',\n",
       " '--',\n",
       " 'so',\n",
       " ' ',\n",
       " 'it',\n",
       " ' ',\n",
       " 'was',\n",
       " ' ',\n",
       " 'no',\n",
       " ' ',\n",
       " 'g']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the text on white spaces and punctuation. The words are intentionally NOT normalized.\n",
    "# This is because it enables the LLM to differentiate between proper and regular nouns, etc.\n",
    "text: str = data[:100]\n",
    "pattern: str = r'([,.?_!\"()\\']|--|\\s)'\n",
    "re.split(pattern=pattern, string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'HAD',\n",
       " 'always',\n",
       " 'thought',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'cheap',\n",
       " 'genius',\n",
       " '--',\n",
       " 'though',\n",
       " 'a',\n",
       " 'good',\n",
       " 'fellow',\n",
       " 'enough',\n",
       " '--',\n",
       " 'so',\n",
       " 'it',\n",
       " 'was',\n",
       " 'no',\n",
       " 'g']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove whitespaces\n",
    "preprocessed: list[str] = re.split(pattern=pattern, string=text)\n",
    "preprocessed = [ch for ch in preprocessed if ch.strip()]\n",
    "preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4649, 20479)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The entire data\n",
    "# Remove whitespaces\n",
    "preprocessed: list[str] = re.split(pattern=pattern, string=data)\n",
    "preprocessed = [ch for ch in preprocessed if ch.strip()]\n",
    "len(preprocessed), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary. i.e. a dict containing all the distinct words mapped to unique ineger values.\n",
    "unk_token: str = \"<|unk|>\"\n",
    "end_of_text: str = \"<|endoftext|>\"\n",
    "vocab: dict[str, any] = {\n",
    "    ch: idx for idx, ch in enumerate(sorted(set(preprocessed)), start=0)\n",
    "}\n",
    "vocab[unk_token] = len(vocab) + 1\n",
    "vocab[end_of_text] = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1160, 738, 1013, 1160, 738, 1160, 1160, 1160, 5, 1019, 1160, 119, 1160, 1160, 738, 1160, 1160, 3, 2, 1160, 5, 1160, 4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tokens to IDs (encode)\n",
    "text: str = (\n",
    "    \"Because of the scale of many ML systems, they consume a massive amount of data - ('Neidu, 2024)\"\n",
    ")\n",
    "tok_text: list[str] = re.split(pattern=pattern, string=text)\n",
    "tok_text = [ch for ch in tok_text if ch.strip()]\n",
    "tok_IDs: list[int] = [\n",
    "    vocab.get(ch) if ch in vocab else vocab.get(unk_token) for ch in tok_text\n",
    "]\n",
    "\n",
    "\", \".join([str(ch) for ch in tok_IDs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|unk|> of the <|unk|> of <|unk|> <|unk|> <|unk|>, they <|unk|> a <|unk|> <|unk|> of <|unk|> <|unk|>(' <|unk|>, <|unk|>)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert token IDs back to tokens\n",
    "idx_to_text: dict[int, str] = {idx: ch for ch, idx in vocab.items()}\n",
    "\n",
    "res: list[str] = [idx_to_text.get(idx) for idx in tok_IDs]\n",
    "\n",
    "# Remove the whitespaces after punctuation\n",
    "pattern_1: str = r'\\s+([,.?!\"()\\'])'\n",
    "res: str = \" \".join(res)\n",
    "res = re.sub(pattern=pattern_1, repl=r\"\\1\", string=res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens to IDs (encode)\n",
    "text: str = (\n",
    "    \"Because of the scale of many ML systems, they consume a massive amount of data - ('Neidu, 2024)\"\n",
    ")\n",
    "tok_text: list[str] = re.split(pattern=pattern, string=text)\n",
    "tok_text = [ch for ch in tok_text if ch.strip()]\n",
    "tok_IDs: list[int] = [\n",
    "    vocab.get(ch) if ch in vocab else vocab.get(unk_token) for ch in tok_text\n",
    "]\n",
    "\n",
    "\", \".join([str(ch) for ch in tok_IDs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    \"\"\"\n",
    "    A simple tokenizer that splits text into tokens based on a predefined vocabulary.\n",
    "\n",
    "    The `SimpleTokenizerV1` class provides methods to encode text into a list of token IDs and decode a list\n",
    "    of token IDs back into text. It uses a predefined vocabulary to map between tokens and their corresponding IDs.\n",
    "\n",
    "    Args:\n",
    "        vocab (dict[str, int]): A dictionary mapping tokens to their corresponding IDs.\n",
    "\n",
    "    Methods:\n",
    "        encode(text: str) -> list[int]:\n",
    "            Tokenize a string into a list of token IDs.\n",
    "        decode(tok_IDs: list[int]) -> str:\n",
    "            Convert a list of token IDs back into a string.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab: dict[str, int]):\n",
    "        self.vocab = vocab\n",
    "        self.pattern_1: str = r'([,.?_!\"()\\']|--|\\s)'\n",
    "        self.pattern_2: str = r'\\s+([,.?!\"()\\'])'\n",
    "        self.idx_to_text: dict[int, str] = {idx: ch for ch, idx in self.vocab.items()}\n",
    "\n",
    "    def encode(self, text: str) -> list[int]:\n",
    "        \"\"\"Tokenize a string into a list of tokens.\"\"\"\n",
    "        unk_token: str = \"<|unk|>\"\n",
    "        tok_text: list[str] = re.split(pattern=self.pattern_1, string=text)\n",
    "        tok_text = [ch for ch in tok_text if ch.strip()]\n",
    "        tok_IDs: list[int] = [\n",
    "            vocab.get(ch) if ch in vocab else vocab.get(unk_token) for ch in tok_text\n",
    "        ]\n",
    "        return tok_IDs\n",
    "\n",
    "    def decode(self, tok_IDs: list[int]) -> str:\n",
    "        \"\"\"Convert a list of tokens into a string.\"\"\"\n",
    "        text: str = \" \".join([self.idx_to_text.get(idx) for idx in tok_IDs])\n",
    "        text = re.sub(pattern=self.pattern_2, repl=r\"\\1\", string=text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1160, 595, 1013, 517, 1160, 579, 1013, 1160, 10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text: str = \"Who is the greatest striker in the world?\"\n",
    "tokenizer: SimpleTokenizerV1 = SimpleTokenizerV1(vocab=vocab)\n",
    "tok_IDs: list[int] = tokenizer.encode(text)\n",
    "tok_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|> is the greatest <|unk|> in the <|unk|>?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tok_IDs=tok_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1: str = \"Hello, do you like tea?\"\n",
    "text2: str = \"In the sunlit terraces of the palace.\"\n",
    "text: str = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1160, 5, 362, 1155, 642, 1000, 10, 1161, 57, 1013, 981, 1009, 738, 1013, 1160, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byte Pair Encoding\n",
    "\n",
    "```sh\n",
    "pip install tiktoken\n",
    "```\n",
    "\n",
    "- It encodes unknown words properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8241, 318, 262, 6000, 19099, 287, 262, 995, 30]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "text: str = \"Who is the greatest striker in the world?\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tok_IDs: list[int] = tokenizer.encode(text)\n",
    "tok_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is the greatest striker in the world?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tok_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8241,\n",
       " 318,\n",
       " 262,\n",
       " 6000,\n",
       " 19099,\n",
       " 287,\n",
       " 262,\n",
       " 995,\n",
       " 30,\n",
       " 220,\n",
       " 50256,\n",
       " 9552,\n",
       " 318,\n",
       " 32017,\n",
       " 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_of_text = \"<|endoftext|>\"\n",
    "\n",
    "text: str = f\"Who is the greatest striker in the world? {end_of_text} AI is booming!\"\n",
    "tok_IDs: list[int] = tokenizer.encode(text, allowed_special={end_of_text})\n",
    "tok_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is the greatest striker in the world? <|endoftext|> AI is booming!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tok_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1925, 500, 312, 84, 464, 13681]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does BPE handle unknown workds/tokens??\n",
    "text: str = \"ChineiduTheGreat\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tok_IDs: list[int] = tokenizer.encode(text, allowed_special={end_of_text})\n",
    "tok_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ch', 'ine', 'id', 'u', 'The', 'Great')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BPE breaks down unkowned tokens into subwords and individual characters. This prevents BPE from replacing\n",
    "# unknown tokens with a special token sunch as <|unk|>\n",
    "(\n",
    "    tokenizer.decode([1925]),  # Ch\n",
    "    tokenizer.decode([500]),  # ine\n",
    "    tokenizer.decode([312]),  # id\n",
    "    tokenizer.decode([84]),  # u\n",
    "    tokenizer.decode([464]),  # The\n",
    "    tokenizer.decode([13681]),  # Great\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sampling With A Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([40, 367, 2885, 1464, 1807], 5145)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the entire data using BPE\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tok_data: list[int] = tokenizer.encode(data)\n",
    "\n",
    "tok_data[:5], len(tok_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= [40, 367, 2885, 1464]\n",
      "y= [367, 2885, 1464, 1807]\n"
     ]
    }
   ],
   "source": [
    "# Create input-target pairs for the next-word prediction\n",
    "enc_sample: list[int] = tok_data[:50]\n",
    "context_size: int = 4\n",
    "x: list[int] = enc_sample[:context_size]\n",
    "y: list[int] = enc_sample[1 : context_size + 1]\n",
    "\n",
    "print(f\"{x= }\")\n",
    "print(f\"{y= }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] ---> 367\n",
      "[40, 367] ---> 2885\n",
      "[40, 367, 2885] ---> 1464\n",
      "[40, 367, 2885, 1464] ---> 1807\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1, context_size + 1):\n",
    "    print(f\"{enc_sample[:idx]} ---> {enc_sample[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I --->  H\n",
      "I H ---> AD\n",
      "I HAD --->  always\n",
      "I HAD always --->  thought\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1, context_size + 1):\n",
    "    print(\n",
    "        f\"{tokenizer.decode(enc_sample[:idx])} ---> {tokenizer.decode([enc_sample[idx]])}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, text: str, tokenizer: Any, max_length: int, stride: int):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "        print(f\"{len(token_ids)=:,}\")\n",
    "\n",
    "        for idx in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk: list[int] = token_ids[idx : (idx + max_length)]\n",
    "            target_chunk: list[int] = token_ids[idx + 1 : (idx + max_length + 1)]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, ...]:\n",
    "        x = self.input_ids[idx]\n",
    "        y = self.target_ids[idx]\n",
    "        return (x, y)\n",
    "\n",
    "\n",
    "def create_dataloader(\n",
    "    text: str,\n",
    "    batch_size: int = 4,\n",
    "    max_length: int = 256,\n",
    "    stride: int = 128,\n",
    "    shuffle: bool = True,\n",
    "    drop_last: bool = True,\n",
    ") -> DataLoader:\n",
    "    \"\"\"Create a dataloader for the given text data.\"\"\"\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset: Dataset = GPTDataset(\n",
    "        text=text, tokenizer=tokenizer, max_length=max_length, stride=stride\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(token_ids)=9\n",
      "dataset_.input_ids=[tensor([  40,  367, 2885, 1464]), tensor([ 367, 2885, 1464, 1807]), tensor([2885, 1464, 1807, 3619]), tensor([1464, 1807, 3619,  402]), tensor([1807, 3619,  402,  271])], \n",
      "dataset_.target_ids=[tensor([ 367, 2885, 1464, 1807]), tensor([2885, 1464, 1807, 3619]), tensor([1464, 1807, 3619,  402]), tensor([1807, 3619,  402,  271]), tensor([3619,  402,  271,   65])]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "dataset_ = GPTDataset(text=data[:30], tokenizer=tokenizer, max_length=4, stride=1)\n",
    "print(f\"{dataset_.input_ids=}, \\n{dataset_.target_ids=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  40,  367, 2885, 1464]), tensor([ 367, 2885, 1464, 1807]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(token_ids)=9\n",
      "dataset_.input_ids=[tensor([  40,  367, 2885, 1464]), tensor([2885, 1464, 1807, 3619]), tensor([1807, 3619,  402,  271])], \n",
      "dataset_.target_ids=[tensor([ 367, 2885, 1464, 1807]), tensor([1464, 1807, 3619,  402]), tensor([3619,  402,  271,   65])]\n"
     ]
    }
   ],
   "source": [
    "dataset_ = GPTDataset(text=data[:30], tokenizer=tokenizer, max_length=4, stride=2)\n",
    "print(f\"{dataset_.input_ids=}, \\n{dataset_.target_ids=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(token_ids)=5,145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[  40,  367, 2885, 1464],\n",
       "         [ 367, 2885, 1464, 1807],\n",
       "         [2885, 1464, 1807, 3619],\n",
       "         [1464, 1807, 3619,  402]]),\n",
       " tensor([[ 367, 2885, 1464, 1807],\n",
       "         [2885, 1464, 1807, 3619],\n",
       "         [1464, 1807, 3619,  402],\n",
       "         [1807, 3619,  402,  271]])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = create_dataloader(\n",
    "    text=data, batch_size=4, max_length=4, stride=1, shuffle=False, drop_last=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "\n",
    "first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1807,  3619,   402,   271],\n",
       "         [ 3619,   402,   271, 10899],\n",
       "         [  402,   271, 10899,  2138],\n",
       "         [  271, 10899,  2138,   257]]),\n",
       " tensor([[ 3619,   402,   271, 10899],\n",
       "         [  402,   271, 10899,  2138],\n",
       "         [  271, 10899,  2138,   257],\n",
       "         [10899,  2138,   257,  7026]])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "second_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(token_ids)=5,145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">inputs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">367</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2885</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1464</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2885</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1464</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1807</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3619</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1807</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3619</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10899</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2138</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10899</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2138</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7026</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7026</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15632</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15632</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">922</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5891</span><span style=\"font-weight: bold\">]])</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">targets</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">367</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2885</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1464</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1807</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1464</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1807</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3619</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3619</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10899</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10899</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2138</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2138</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7026</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15632</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7026</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15632</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">922</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">922</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5891</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1576</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33minputs\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m   \u001b[1;36m40\u001b[0m,   \u001b[1;36m367\u001b[0m,  \u001b[1;36m2885\u001b[0m,  \u001b[1;36m1464\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m2885\u001b[0m,  \u001b[1;36m1464\u001b[0m,  \u001b[1;36m1807\u001b[0m,  \u001b[1;36m3619\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1807\u001b[0m,  \u001b[1;36m3619\u001b[0m,   \u001b[1;36m402\u001b[0m,   \u001b[1;36m271\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m402\u001b[0m,   \u001b[1;36m271\u001b[0m, \u001b[1;36m10899\u001b[0m,  \u001b[1;36m2138\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m10899\u001b[0m,  \u001b[1;36m2138\u001b[0m,   \u001b[1;36m257\u001b[0m,  \u001b[1;36m7026\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m257\u001b[0m,  \u001b[1;36m7026\u001b[0m, \u001b[1;36m15632\u001b[0m,   \u001b[1;36m438\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m15632\u001b[0m,   \u001b[1;36m438\u001b[0m,  \u001b[1;36m2016\u001b[0m,   \u001b[1;36m257\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m2016\u001b[0m,   \u001b[1;36m257\u001b[0m,   \u001b[1;36m922\u001b[0m,  \u001b[1;36m5891\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[33mtargets\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m367\u001b[0m,  \u001b[1;36m2885\u001b[0m,  \u001b[1;36m1464\u001b[0m,  \u001b[1;36m1807\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1464\u001b[0m,  \u001b[1;36m1807\u001b[0m,  \u001b[1;36m3619\u001b[0m,   \u001b[1;36m402\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m3619\u001b[0m,   \u001b[1;36m402\u001b[0m,   \u001b[1;36m271\u001b[0m, \u001b[1;36m10899\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m271\u001b[0m, \u001b[1;36m10899\u001b[0m,  \u001b[1;36m2138\u001b[0m,   \u001b[1;36m257\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m2138\u001b[0m,   \u001b[1;36m257\u001b[0m,  \u001b[1;36m7026\u001b[0m, \u001b[1;36m15632\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m7026\u001b[0m, \u001b[1;36m15632\u001b[0m,   \u001b[1;36m438\u001b[0m,  \u001b[1;36m2016\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m438\u001b[0m,  \u001b[1;36m2016\u001b[0m,   \u001b[1;36m257\u001b[0m,   \u001b[1;36m922\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m257\u001b[0m,   \u001b[1;36m922\u001b[0m,  \u001b[1;36m5891\u001b[0m,  \u001b[1;36m1576\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using stride=2\n",
    "stride: int = 2\n",
    "\n",
    "dataloader = create_dataloader(\n",
    "    text=data, batch_size=8, max_length=4, stride=stride, shuffle=False, drop_last=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "console.print(f\"{inputs=}, \\n{targets=}\")\n",
    "\n",
    "# e.g. slide by 2 index positions\n",
    "# [   40,   367,  2885,  1464],\n",
    "# [ 2885,  1464,  1807,  3619]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "\n",
    "\n",
    "HOST = \"\"\n",
    "DATABASE = \"\"\n",
    "USER = \"\"\n",
    "PASSWORD = \"\"\n",
    "\n",
    "db_connection = mysql.connect(\n",
    "    host=HOST,\n",
    "    #   database=DATABASE,\n",
    "    user=USER,\n",
    "    password=PASSWORD,\n",
    ")\n",
    "\n",
    "print(\"Connected to:\", db_connection.get_server_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
