{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Mechanism\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,torch,lightning --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Vector\n",
    "\n",
    "- Context vector is the weighted sum of the input vectors that captures the relevent information from the entire sequence for a given position. i.e. it can be thought of as an enriched embedding vector of the inout\n",
    "\n",
    "#### Calculate Context Vector\n",
    "\n",
    "- Attention Score: \n",
    "  - it's calculated by finding the dot product of the token's query vector and the key vector of the other tokens in the sequence.\n",
    "  - The scores are normalized using softmax to produce the attention weights.\n",
    "- Multiply the embedded input tokens with their corresponding attention weights and sum the resulting vectors to get the context vector.\n",
    "- This is done for each position in the sequence to get the context vector for the entire sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Trainable Parameters (Simplified Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed: int = 5\n",
    "\n",
    "# Assume that we have an input with a 3-D embeddings shown below:\n",
    "inputs: Tensor = torch.tensor(\n",
    "    [\n",
    "        [0.43, 0.15, 0.89],  # Your (x^1)\n",
    "        [0.55, 0.87, 0.66],  # journey (x^2)\n",
    "        [0.57, 0.85, 0.64],  # starts (x^3)\n",
    "        [0.22, 0.58, 0.33],  # with (x^4)\n",
    "        [0.77, 0.25, 0.10],  # one (x^5)\n",
    "        [0.05, 0.80, 0.55],  # step (x^6)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Calculate the context vector for the 2nd token (x^2)\n",
    "# 1: Cal the attention scores\n",
    "query: Tensor = inputs[1]\n",
    "attn_scores_index_1: Tensor = torch.empty(inputs.shape[0])\n",
    "\n",
    "for idx, x_1 in enumerate(inputs):\n",
    "    # Cal the dot product of the query vector and each key vector in the input\n",
    "    attn_scores_index_1[idx] = torch.dot(x_1, query)\n",
    "\n",
    "print(f\"{attn_scores_index_1 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Normalize the attention scores to obtain the attention weights\n",
    "attn_scores_weights_1: Tensor = torch.softmax(attn_scores_index_1, dim=-1)\n",
    "print(f\"{attn_scores_weights_1 = }\")\n",
    "attn_scores_weights_1.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape: tuple = tuple(inputs.shape)\n",
    "attn_scores_weights_1_shape: tuple = tuple(attn_scores_weights_1.shape)\n",
    "print(f\"{attn_scores_weights_1_shape = } AND {inputs_shape = }\")\n",
    "\n",
    "# 3: Calculate the context vector as the weighted average of the values\n",
    "# Transpose the inputs so that we can perform matrix multiplication\n",
    "context_vector_1: Tensor = attn_scores_weights_1 @ inputs\n",
    "context_vector_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate The Attention Weights Of The Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the attention scores\n",
    "print(f\"{inputs.shape = } AND {inputs.T.shape = }\")\n",
    "attn_scores: Tensor = inputs @ inputs.T\n",
    "print(f\"\\n{attn_scores.shape = }\")\n",
    "\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate the attention weights. i.e. normalize the attention scores using softmax\n",
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(f\"\\n{attn_weights.shape = }\")\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate the context vector\n",
    "print(f\"{attn_weights.shape = } AND {inputs.shape = }\")\n",
    "\n",
    "context_vector: Tensor = attn_weights @ inputs\n",
    "context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr>\n",
    "\n",
    "## Implement Self-Attention With Trainable Parameters\n",
    "\n",
    "- AKA **Scaled Dot-Product Attention**\n",
    "- Add weight matrices that are updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the trainable attention weights for a given token in the input\n",
    "x_1: Tensor = inputs[1]\n",
    "print(f\"{x_1.shape = }\")\n",
    "# Embedding dimension\n",
    "d_in: int = x_1.shape[-1]\n",
    "# Output embedding size\n",
    "d_out: int = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "# Trainable parameters: requires_grad=False (to reduce the clutter and keep things simple)\n",
    "W_query: Tensor = nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
    "W_key: Tensor = nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
    "W_value: Tensor = nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
    "\n",
    "# Compute the query, key, and value tensors for the given index\n",
    "query_1: Tensor = torch.matmul(x_1, W_query)\n",
    "key_1: Tensor = torch.matmul(x_1, W_key)\n",
    "value_1: Tensor = torch.matmul(x_1, W_value)\n",
    "\n",
    "# Compute the key and value tensors for ALL the input\n",
    "query: Tensor = torch.matmul(inputs, W_query)\n",
    "key: Tensor = torch.matmul(inputs, W_key)\n",
    "value: Tensor = torch.matmul(inputs, W_value)\n",
    "\n",
    "print(f\"{query_1.shape = }\")\n",
    "query_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{query_1.shape = } | {key_1.shape = } | {value_1.shape = }\")\n",
    "print(f\"{query.shape = } | {key.shape = } | {value.shape = }\")\n",
    "print()\n",
    "\n",
    "# Calculate the attention scores\n",
    "# For a single token in the query\n",
    "attn_score_1: Tensor = torch.matmul(query_1, key.T)  # query_1 @ key_1\n",
    "\n",
    "# For all the tokens in the query\n",
    "attn_scores: Tensor = torch.matmul(query, key.T)\n",
    "\n",
    "print(f\"{attn_score_1.shape =} | {attn_score_1 = }\")\n",
    "print()\n",
    "print(f\"{attn_scores.shape = } | {attn_scores = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the scaled attention weights. It's scaled by the square root of\n",
    "# the dimension size to improve the training performance and avoid small gradients.\n",
    "attn_weights_1: Tensor = torch.softmax(attn_score_1 / (d_out**0.5), dim=-1)\n",
    "attn_weights: Tensor = torch.softmax(attn_scores / (d_out**0.5), dim=-1)\n",
    "\n",
    "\n",
    "print(f\"{attn_weights_1.shape =} | {attn_weights_1 = }\")\n",
    "print()\n",
    "print(f\"{attn_weights.shape = } | {attn_weights = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{attn_weights_1.shape = } | {value.shape = }\")\n",
    "print(f\"{attn_weights.shape = } | {value.shape = }\")\n",
    "\n",
    "context_vector_1: Tensor = attn_weights_1 @ value\n",
    "context_vector: Tensor = attn_weights @ value\n",
    "print()\n",
    "print(f\"{context_vector_1 = }\\n\\n\")\n",
    "\n",
    "print(f\"{context_vector = }\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query, Key and Value\n",
    "\n",
    "- **Query** : The query is analogous to a `search` in a `database`. It represents the current item/token the model focuses on.\n",
    "- **Key** : The key is analogous to the `index` in a `database`. It represents the item/token that the model compares the query to.\n",
    "- **Value** : The value is analogous to the `value` in a `key-value` pair. It represents the actual content or representation of the item/token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in: int, d_out: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_out = d_out\n",
    "\n",
    "        self.W_q = nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_k = nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_v = nn.Parameter(torch.randn(d_in, d_out))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        queries: Tensor = torch.matmul(x, W_query)\n",
    "        keys: Tensor = torch.matmul(x, W_key)\n",
    "        values: Tensor = torch.matmul(x, W_value)\n",
    "        attn_scores: Tensor = queries @ keys.T\n",
    "        attn_weights: Tensor = torch.softmax(attn_scores / self.d_out**0.5, dim=-1)\n",
    "        context_vector: Tensor = torch.matmul(attn_weights, values)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "self_attn_v1 = SelfAttention_v1(d_in=d_in, d_out=d_out)\n",
    "print(f\"{self_attn_v1 = }\")\n",
    "print(self_attn_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update\n",
    "\n",
    "- Improve the `SelfAttention_v1` implementation using PyTorch's `nn.Linear` layers instead of `nn.Parameter` layers.\n",
    "\n",
    "- This is because:\n",
    "  - `nn.Linear` performs effective matrix multiplication when the bias units are disabled.\n",
    "  - `nn.Linear` has a an optimized weight initialization scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in: int, d_out: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_out = d_out\n",
    "\n",
    "        self.W_q = nn.Linear(d_in, d_out)\n",
    "        self.W_k = nn.Linear(d_in, d_out)\n",
    "        self.W_v = nn.Linear(d_in, d_out)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        queries: Tensor = torch.matmul(x, W_query)\n",
    "        keys: Tensor = torch.matmul(x, W_key)\n",
    "        values: Tensor = torch.matmul(x, W_value)\n",
    "        attn_scores: Tensor = queries @ keys.T\n",
    "        attn_weights: Tensor = torch.softmax(attn_scores / self.d_out**0.5, dim=-1)\n",
    "        context_vector: Tensor = torch.matmul(attn_weights, values)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "self_attn_v1 = SelfAttention_v2(d_in=d_in, d_out=d_out)\n",
    "print(f\"{self_attn_v1 = }\")\n",
    "print(self_attn_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
