{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune GPT Model\n",
    "\n",
    "- We'll be finetuning the LLM on a specific target task, such as classifying text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "numpy    : 1.26.4\n",
      "pandas   : 2.2.1\n",
      "polars   : 0.20.18\n",
      "torch    : 2.2.2\n",
      "lightning: 2.2.1\n",
      "\n",
      "conda environment: torch_p11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,torch,lightning --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M: dict[str, Any] = {\n",
    "    \"vocab_size\": 50_257,\n",
    "    \"context_length\": 1_024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(\n",
    "    url: str, zip_path: str, extracted_path: str, data_file_path: Path\n",
    ") -> None:\n",
    "    original_file_path: Path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "\n",
    "    if data_file_path.exists():\n",
    "        console.print(\n",
    "            f\"{str(data_file_path)!r} already exists. Skipping download and extraction.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # Download the file to the specified directory\n",
    "    with request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzip the file to the specified directory\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    console.print(f\"File downloaded and saved as {data_file_path!r}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'sms_spam_collection/SMSSpamCollection.tsv'</span> already exists. Skipping download and extraction.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'sms_spam_collection/SMSSpamCollection.tsv'\u001b[0m already exists. Skipping download and extraction.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url: str = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path: str = \"sms_spam_collection.zip\"\n",
    "extracted_path: str = \"sms_spam_collection\"\n",
    "data_file_path: Path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "download_and_unzip_spam_data(\n",
    "    url=url,\n",
    "    zip_path=zip_path,\n",
    "    extracted_path=extracted_path,\n",
    "    data_file_path=data_file_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,278 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Label</th><th>Text</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;ham&quot;</td><td>&quot;Go until juron…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Ok lar... Joki…</td></tr><tr><td>&quot;spam&quot;</td><td>&quot;Free entry in …</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;U dun say so e…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Nah I don&#x27;t th…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌───────┬───────────────────────────────────┐\n",
       "│ Label ┆ Text                              │\n",
       "│ ---   ┆ ---                               │\n",
       "│ str   ┆ str                               │\n",
       "╞═══════╪═══════════════════════════════════╡\n",
       "│ ham   ┆ Go until jurong point, crazy.. A… │\n",
       "│ ham   ┆ Ok lar... Joking wif u oni...     │\n",
       "│ spam  ┆ Free entry in 2 a wkly comp to w… │\n",
       "│ ham   ┆ U dun say so early hor... U c al… │\n",
       "│ ham   ┆ Nah I don't think he goes to usf… │\n",
       "└───────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df: pl.DataFrame = pl.read_csv(\n",
    "    source=data_file_path,\n",
    "    separator=\"\\t\",\n",
    "    has_header=False,\n",
    ").rename({\"column_1\": \"Label\", \"column_2\": \"Text\"})\n",
    "\n",
    "print(f\"{df.shape[0]:,} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Label</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;spam&quot;</td><td>697</td></tr><tr><td>&quot;ham&quot;</td><td>4581</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────┬──────┐\n",
       "│ Label ┆ len  │\n",
       "│ ---   ┆ ---  │\n",
       "│ str   ┆ u32  │\n",
       "╞═══════╪══════╡\n",
       "│ spam  ┆ 697  │\n",
       "│ ham   ┆ 4581 │\n",
       "└───────┴──────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group_by(\"Label\").agg(pl.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_data(\n",
    "    data: pl.DataFrame, seed: int = 123, print_shape: bool = False\n",
    ") -> pl.DataFrame:\n",
    "\n",
    "    sample_size: int = int(data.filter(pl.col(\"Label\").eq(\"spam\")).shape[0] * 1.2)\n",
    "    print(f\"sample_size: {sample_size:,}\")\n",
    "    spam: pl.DataFrame = data.filter(pl.col(\"Label\").eq(\"spam\"))\n",
    "    ham: pl.DataFrame = data.filter(pl.col(\"Label\").eq(\"ham\")).sample(\n",
    "        n=sample_size, seed=seed\n",
    "    )\n",
    "    data_df: pl.DataFrame = pl.concat([spam, ham], how=\"vertical\").sample(\n",
    "        seed=seed, fraction=1, shuffle=True\n",
    "    )\n",
    "    if print_shape:\n",
    "        print(f\"Data shape: {data_df.shape[0]:,} rows\")\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size: 836\n",
      "Data shape: 1,533 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Label</th><th>Text</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;spam&quot;</td><td>&quot;T-Mobile custo…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;How will I cre…</td></tr><tr><td>&quot;spam&quot;</td><td>&quot;important info…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;I love to give…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;We stopped to …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌───────┬───────────────────────────────────┐\n",
       "│ Label ┆ Text                              │\n",
       "│ ---   ┆ ---                               │\n",
       "│ str   ┆ str                               │\n",
       "╞═══════╪═══════════════════════════════════╡\n",
       "│ spam  ┆ T-Mobile customer you may now cl… │\n",
       "│ ham   ┆ How will I creep on you now? ;_;  │\n",
       "│ spam  ┆ important information 4 orange u… │\n",
       "│ ham   ┆ I love to give massages. I use l… │\n",
       "│ ham   ┆ We stopped to get ice cream and … │\n",
       "└───────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed: int = 123\n",
    "\n",
    "data = generate_sample_data(data=df, seed=seed, print_shape=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Label</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;spam&quot;</td><td>697</td></tr><tr><td>&quot;ham&quot;</td><td>836</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────┬─────┐\n",
       "│ Label ┆ len │\n",
       "│ ---   ┆ --- │\n",
       "│ str   ┆ u32 │\n",
       "╞═══════╪═════╡\n",
       "│ spam  ┆ 697 │\n",
       "│ ham   ┆ 836 │\n",
       "└───────┴─────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.group_by(\"Label\").agg(pl.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">shape: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "┌───────┬───────────────────────────────────┐\n",
       "│ Label ┆ Text                              │\n",
       "│ ---   ┆ ---                               │\n",
       "│ i32   ┆ str                               │\n",
       "╞═══════╪═══════════════════════════════════╡\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>     ┆ T-Mobile customer you may now cl… │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>     ┆ How will I creep on you now? ;_;  │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>     ┆ important information <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> orange u… │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>     ┆ I love to give massages. I use l… │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>     ┆ We stopped to get ice cream and … │\n",
       "└───────┴───────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "shape: \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "┌───────┬───────────────────────────────────┐\n",
       "│ Label ┆ Text                              │\n",
       "│ ---   ┆ ---                               │\n",
       "│ i32   ┆ str                               │\n",
       "╞═══════╪═══════════════════════════════════╡\n",
       "│ \u001b[1;36m1\u001b[0m     ┆ T-Mobile customer you may now cl… │\n",
       "│ \u001b[1;36m0\u001b[0m     ┆ How will I creep on you now? ;_;  │\n",
       "│ \u001b[1;36m1\u001b[0m     ┆ important information \u001b[1;36m4\u001b[0m orange u… │\n",
       "│ \u001b[1;36m0\u001b[0m     ┆ I love to give massages. I use l… │\n",
       "│ \u001b[1;36m0\u001b[0m     ┆ We stopped to get ice cream and … │\n",
       "└───────┴───────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode the labels\n",
    "data = data.with_columns(\n",
    "    Label=pl.when(pl.col(\"Label\").eq(\"ham\")).then(pl.lit(0)).otherwise(pl.lit(1))\n",
    ")\n",
    "\n",
    "console.print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape = (1241, 2), val_data.shape = (138, 2), test_data.shape = (154, 2)\n"
     ]
    }
   ],
   "source": [
    "## Split the data into tran, validation and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data: pl.DataFrame\n",
    "val_data: pl.DataFrame\n",
    "test_data: pl.DataFrame\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "    data, stratify=data.select(\"Label\"), test_size=0.1, random_state=seed\n",
    ")\n",
    "train_data, val_data = train_test_split(\n",
    "    train_data, stratify=train_data.select(\"Label\"), test_size=0.1, random_state=seed\n",
    ")\n",
    "\n",
    "print(f\"{train_data.shape = }, {val_data.shape = }, {test_data.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌───────┬─────┐\n",
      "│ Label ┆ len │\n",
      "│ ---   ┆ --- │\n",
      "│ i32   ┆ u32 │\n",
      "╞═══════╪═════╡\n",
      "│ 1     ┆ 564 │\n",
      "│ 0     ┆ 677 │\n",
      "└───────┴─────┘\n",
      "shape: (2, 2)\n",
      "┌───────┬─────┐\n",
      "│ Label ┆ len │\n",
      "│ ---   ┆ --- │\n",
      "│ i32   ┆ u32 │\n",
      "╞═══════╪═════╡\n",
      "│ 0     ┆ 75  │\n",
      "│ 1     ┆ 63  │\n",
      "└───────┴─────┘\n",
      "shape: (2, 2)\n",
      "┌───────┬─────┐\n",
      "│ Label ┆ len │\n",
      "│ ---   ┆ --- │\n",
      "│ i32   ┆ u32 │\n",
      "╞═══════╪═════╡\n",
      "│ 1     ┆ 70  │\n",
      "│ 0     ┆ 84  │\n",
      "└───────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# Save the data\n",
    "save_path: Path = Path(\"../../data/sms_data\")\n",
    "train_data.write_parquet(file=save_path / \"train.parquet\", use_pyarrow=True)\n",
    "val_data.write_parquet(file=save_path / \"val.parquet\", use_pyarrow=True)\n",
    "test_data.write_parquet(file=save_path / \"test.parquet\", use_pyarrow=True)\n",
    "\n",
    "print(train_data.group_by(\"Label\").agg(pl.len()))\n",
    "print(val_data.group_by(\"Label\").agg(pl.len()))\n",
    "print(test_data.group_by(\"Label\").agg(pl.len()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets And Data Loaders\n",
    "\n",
    "- Pad all the texts to the same length.\n",
    "- Pad using the index of the pad token.\n",
    "  - `\"<|endoftext|>\"` is the padding token.\n",
    "  - it has an index of 50256 (using tiktoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pl.DataFrame,\n",
    "        tokenizer: Any,\n",
    "        max_length: int | None = None,\n",
    "        pad_token: int = 50_256,\n",
    "    ) -> None:\n",
    "        self.data = data\n",
    "        self.encoded_texts: list[int] = [\n",
    "            tokenizer.encode(text) for text in self.data.select(\"Text\").to_series()\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length: int = self._calculate_max_length()\n",
    "        else:\n",
    "            assert (\n",
    "                max_length > 0\n",
    "            ), \"max_length must be a positive integer or None, not a negative integer.\"\n",
    "            self.max_length = max_length\n",
    "\n",
    "        # Truncate text\n",
    "        self.encoded_texts = [\n",
    "            tok_ids[: -self.max_length] for tok_ids in self.encoded_texts\n",
    "        ]\n",
    "        # Pad Text\n",
    "        self.encoded_texts = [\n",
    "            tok_ids + [pad_token] * (self.max_length - len(tok_ids))\n",
    "            for tok_ids in self.encoded_texts\n",
    "        ]\n",
    "        # Targets\n",
    "        self.targets = self.data.select(\"Label\").to_series()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        text: Tensor = torch.tensor(self.encoded_texts[idx], dtype=torch.long)\n",
    "        label: Tensor = torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "\n",
    "        return (text, label)\n",
    "\n",
    "    def _calculate_max_length(self) -> int:\n",
    "        return max([len(tok_ids) for tok_ids in self.encoded_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# end_of_text: str = \"<|endoftext|>\"\n",
    "# tokenizer.encode(text, allowed_special={end_of_text})\n",
    "\n",
    "train_dataset: Dataset = SpamDataset(data=train_data, tokenizer=tokenizer)\n",
    "val_dataset: Dataset = SpamDataset(\n",
    "    data=val_data, tokenizer=tokenizer, max_length=train_dataset.max_length\n",
    ")\n",
    "test_dataset: Dataset = SpamDataset(\n",
    "    data=test_data, tokenizer=tokenizer, max_length=train_dataset.max_length\n",
    ")\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "batch_size: int = 8\n",
    "num_workers: int = 0\n",
    "\n",
    "train_loader: DataLoader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader: DataLoader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader: DataLoader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_batch.shape = torch.Size([8, 257])\n",
      "target_batch.shape = torch.Size([8])\n",
      "\n",
      "\n",
      "len(train_loader) = 155\n",
      "len(val_loader) = 18\n",
      "len(test_loader) = 20\n"
     ]
    }
   ],
   "source": [
    "for inp_batch, target_batch in train_loader:\n",
    "    print(f\"{inp_batch.shape = }\")\n",
    "    print(f\"{target_batch.shape = }\\n\\n\")\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "print(f\"{len(train_loader) = }\")\n",
    "print(f\"{len(val_loader) = }\")\n",
    "print(f\"{len(test_loader) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHOICE: str = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT: str = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50_257,  # Vocabulary size\n",
    "    \"context_length\": 1_024,  # Context length\n",
    "    \"drop_rate\": 0.0,  # Dropout rate\n",
    "    \"qkv_bias\": True,  # Query-key-value bias\n",
    "}\n",
    "model_configs: dict[str, dict] = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[MODEL_CHOICE])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG.get(\"context_length\"), (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG.get('context_length')}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG.get('context_length')}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch p_311",
   "language": "python",
   "name": "torch_p11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
