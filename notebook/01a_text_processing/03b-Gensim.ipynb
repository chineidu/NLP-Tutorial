{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "- Using Gensim (LDA, LSI, HDP, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "numpy    : 1.26.4\n",
      "pandas   : 2.2.1\n",
      "polars   : 0.20.18\n",
      "mlxtend  : 0.23.1\n",
      "omegaconf: 2.3.0\n",
      "gensim   : 4.3.3\n",
      "\n",
      "conda environment: torch_p11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,mlxtend,omegaconf,gensim --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# auto reload imports# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(500)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# [Gensim](https://radimrehurek.com/gensim/index.html)\n",
    "\n",
    "- `Gensim` = **“Generate Similar”**\n",
    "- Gensim is a free open-source Python library for representing documents as semantic vectors, as efficiently (computer-wise) and painlessly (human-wise) as possible.\n",
    "- It's designed to process raw, unstructured digital texts (“plain text”) using unsupervised machine learning algorithms.\n",
    "\n",
    "#### Installation\n",
    "\n",
    "```sh\n",
    "pip install --upgrade gensim\n",
    "\n",
    "```\n",
    "\n",
    "### Use cases\n",
    "\n",
    "- Train large-scale NLP semantic models.\n",
    "- Represent text as semantic vectors.\n",
    "- Find semantically related documents.\n",
    "\n",
    "\n",
    "### Core Concepts of Gensim\n",
    "\n",
    "- `Document`: some text.\n",
    "- `Corpus`: a collection of documents.\n",
    "- `Vector`: a mathematically convenient representation of a document.\n",
    "- `Model`: an algorithm for transforming vectors from one representation to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords = {'the', 'in', 'for', 'a', 'of', 'to', 'and'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">texts = <span style=\"font-weight: bold\">[[</span><span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'machine'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'interface'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'lab'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'abc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'computer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'applications'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'survey'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'opinion'</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'computer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'time'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'eps'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'interface'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'management'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'engineering'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'testing'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'eps'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'relation'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'perceived'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'time'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'error'</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'measurement'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'generation'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'random'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'binary'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'unordered'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'trees'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'intersection'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paths'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trees'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'minors'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'iv'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'widths'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'trees'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'well'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'quasi'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ordering'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'minors'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survey'</span><span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "texts = \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'human'\u001b[0m, \u001b[32m'machine'\u001b[0m, \u001b[32m'interface'\u001b[0m, \u001b[32m'lab'\u001b[0m, \u001b[32m'abc'\u001b[0m, \u001b[32m'computer'\u001b[0m, \u001b[32m'applications'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'survey'\u001b[0m, \u001b[32m'user'\u001b[0m, \u001b[32m'opinion'\u001b[0m,\n",
       "\u001b[32m'computer'\u001b[0m, \u001b[32m'system'\u001b[0m, \u001b[32m'response'\u001b[0m, \u001b[32m'time'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'eps'\u001b[0m, \u001b[32m'user'\u001b[0m, \u001b[32m'interface'\u001b[0m, \u001b[32m'management'\u001b[0m, \u001b[32m'system'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'system'\u001b[0m, \n",
       "\u001b[32m'human'\u001b[0m, \u001b[32m'system'\u001b[0m, \u001b[32m'engineering'\u001b[0m, \u001b[32m'testing'\u001b[0m, \u001b[32m'eps'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'relation'\u001b[0m, \u001b[32m'user'\u001b[0m, \u001b[32m'perceived'\u001b[0m, \u001b[32m'response'\u001b[0m, \u001b[32m'time'\u001b[0m, \u001b[32m'error'\u001b[0m,\n",
       "\u001b[32m'measurement'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'generation'\u001b[0m, \u001b[32m'random'\u001b[0m, \u001b[32m'binary'\u001b[0m, \u001b[32m'unordered'\u001b[0m, \u001b[32m'trees'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'intersection'\u001b[0m, \u001b[32m'graph'\u001b[0m, \u001b[32m'paths'\u001b[0m, \n",
       "\u001b[32m'trees'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'graph'\u001b[0m, \u001b[32m'minors'\u001b[0m, \u001b[32m'iv'\u001b[0m, \u001b[32m'widths'\u001b[0m, \u001b[32m'trees'\u001b[0m, \u001b[32m'well'\u001b[0m, \u001b[32m'quasi'\u001b[0m, \u001b[32m'ordering'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'graph'\u001b[0m, \u001b[32m'minors'\u001b[0m, \u001b[32m'survey'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstartion purpose only! Gensim handles large corpora by streaming documents,\n",
    "# avoiding memory overload.\n",
    "text_corpus: list[str] = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]\n",
    "\n",
    "# Create a set of frequent words\n",
    "stopwords: set[str] = set(\"for a of the and to in\".split())\n",
    "print(f\"{stopwords = }\")\n",
    "\n",
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "texts: list[list[str]] = [\n",
    "    [word for word in document.lower().split() if word not in stopwords]\n",
    "    for document in text_corpus\n",
    "]\n",
    "console.print(f\"{texts = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">frequency = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">defaultdict</span><span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'int'</span><span style=\"font-weight: bold\">&gt;</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'machine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'interface'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'lab'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'abc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'computer'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'applications'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survey'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'opinion'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'eps'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'management'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'engineering'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'testing'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'relation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'perceived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'error'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'measurement'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'generation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'random'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'binary'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'unordered'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'trees'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'intersection'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paths'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'minors'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'iv'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'widths'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'well'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'quasi'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ordering'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "frequency = \u001b[1;35mdefaultdict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'int'\u001b[0m\u001b[1m>\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'human'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'machine'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'interface'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'lab'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'abc'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'computer'\u001b[0m: \n",
       "\u001b[1;36m2\u001b[0m, \u001b[32m'applications'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'survey'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'user'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'opinion'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'system'\u001b[0m: \u001b[1;36m4\u001b[0m, \u001b[32m'response'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'time'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'eps'\u001b[0m: \u001b[1;36m2\u001b[0m, \n",
       "\u001b[32m'management'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'engineering'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'testing'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'relation'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'perceived'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'error'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'measurement'\u001b[0m: \u001b[1;36m1\u001b[0m, \n",
       "\u001b[32m'generation'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'random'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'binary'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'unordered'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'trees'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'intersection'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'graph'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'paths'\u001b[0m: \u001b[1;36m1\u001b[0m, \n",
       "\u001b[32m'minors'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'iv'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'widths'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'well'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'quasi'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'ordering'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">processed_corpus = <span style=\"font-weight: bold\">[[</span><span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'interface'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'computer'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'survey'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'computer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'time'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'eps'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'interface'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'eps'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'time'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'trees'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'trees'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'minors'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'trees'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'minors'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survey'</span><span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "processed_corpus = \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'human'\u001b[0m, \u001b[32m'interface'\u001b[0m, \u001b[32m'computer'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'survey'\u001b[0m, \u001b[32m'user'\u001b[0m, \u001b[32m'computer'\u001b[0m, \u001b[32m'system'\u001b[0m, \u001b[32m'response'\u001b[0m, \n",
       "\u001b[32m'time'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'eps'\u001b[0m, \u001b[32m'user'\u001b[0m, \u001b[32m'interface'\u001b[0m, \u001b[32m'system'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'system'\u001b[0m, \u001b[32m'human'\u001b[0m, \u001b[32m'system'\u001b[0m, \u001b[32m'eps'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'user'\u001b[0m, \u001b[32m'response'\u001b[0m, \n",
       "\u001b[32m'time'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'trees'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'graph'\u001b[0m, \u001b[32m'trees'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'graph'\u001b[0m, \u001b[32m'minors'\u001b[0m, \u001b[32m'trees'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[32m'graph'\u001b[0m, \u001b[32m'minors'\u001b[0m, \u001b[32m'survey'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Count the word frequencies\n",
    "frequency: defaultdict[str, int] = defaultdict(int)\n",
    "\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "\n",
    "console.print(f\"{frequency = }\")\n",
    "\n",
    "# Keep ONLY tokens that occur more than once\n",
    "processed_corpus: list[list[str]] = [\n",
    "    [token for token in text if frequency[token] > 1] for text in texts\n",
    "]\n",
    "console.print(f\"{processed_corpus = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">dictionary.items</span><span style=\"font-weight: bold\">()</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ItemsView</span><span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">gensim.corpora.dictionary.Dictionary</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x13e486a50</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mdictionary.items\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m = \u001b[1;35mItemsView\u001b[0m\u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mgensim.corpora.dictionary.Dictionary\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x13e486a50\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "\n",
    "# Create a dictionary that contains the token_id and the token_text\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "console.print(f\"{dictionary.items() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector\n",
    "\n",
    "- A mathematical way of representing documents in a multi-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dictionary.token2id = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'computer'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'human'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'interface'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survey'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'time'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'eps'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'trees'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'minors'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "dictionary.token2id = \u001b[1m{\u001b[0m\u001b[32m'computer'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'human'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'interface'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'response'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'survey'\u001b[0m: \u001b[1;36m4\u001b[0m, \u001b[32m'system'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'time'\u001b[0m: \n",
       "\u001b[1;36m6\u001b[0m, \u001b[32m'user'\u001b[0m: \u001b[1;36m7\u001b[0m, \u001b[32m'eps'\u001b[0m: \u001b[1;36m8\u001b[0m, \u001b[32m'trees'\u001b[0m: \u001b[1;36m9\u001b[0m, \u001b[32m'graph'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'minors'\u001b[0m: \u001b[1;36m11\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">new_vec = <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "new_vec = \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vector: a mathematical way of representing documents in a multi-dimensional space.\n",
    "\n",
    "# View the token ids\n",
    "console.print(f\"{dictionary.token2id = }\")\n",
    "\n",
    "# Vectorize a document\n",
    "new_doc: str = \"Human computer interaction\"\n",
    "new_vec: list[tuple[int, int]] = dictionary.doc2bow(new_doc.lower().split())\n",
    "console.print(f\"{new_vec = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment\n",
    "\n",
    "```py\n",
    "# Explaination of the result is shown below\n",
    "new_vec = [(0, 1), (1, 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: (0, 0) is in dictionary: True\n",
      "computer: (1, 1) is in dictionary: True\n",
      "interaction: (2, 1) is in dictionary: False\n"
     ]
    }
   ],
   "source": [
    "new_doc_list: list[str] = new_doc.lower().split()\n",
    "\n",
    "for idx, token in enumerate(new_doc_list):\n",
    "    flag: bool = token in dictionary.values()\n",
    "    count_: int = new_doc.count(token)\n",
    "    print(f\"{token}: ({idx}, {count_}) is in dictionary: {flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">bow_corpus = <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>, <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>, <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>, <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>, <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>, <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>, <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>, <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>, <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "bow_corpus = \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m9\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m9\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m9\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m11\u001b[0m, \n",
       "\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m11\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vectorize the entire using a BoW (Bag of Words) approach. i.e. count the\n",
    "# number of times a word appears in a document.\n",
    "bow_corpus: list[list[tuple[int, int]]] = [\n",
    "    dictionary.doc2bow(doc) for doc in processed_corpus\n",
    "]\n",
    "console.print(f\"{bow_corpus = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Model\n",
    "\n",
    "- It refers to `transformation` from one document representation to another.\n",
    "- E.g. `TF-IDF` model transforms word frequency counts based on word rarity in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">doc_vec = <span style=\"font-weight: bold\">[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5898341626740045</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8075244024440723</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "doc_vec = \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m0.5898341626740045\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m11\u001b[0m, \u001b[1;36m0.8075244024440723\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "\n",
    "# Train the model\n",
    "tfidf: models.TfidfModel = models.TfidfModel(corpus=bow_corpus)\n",
    "\n",
    "# Transform an input document\n",
    "doc: list[str] = \"System Minors\".lower().split()\n",
    "doc_bow: list[tuple[int, int]] = dictionary.doc2bow(doc)\n",
    "doc_vec: list[tuple[int, float]] = tfidf[doc_bow]\n",
    "console.print(f\"{doc_vec = }\")\n",
    "\n",
    "#  system: 0.5898341626740045, minors: 0.8075244024440723\n",
    "# [(5, 0.5898341626740045), (11, 0.8075244024440723)]\n",
    "# Because system occurs a lot more than minors in the corpus, it has a lower tf-idf score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Similariites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">sims = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.    , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3245</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4171</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7185</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.    , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.    , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.    , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.    ,\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.    <span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">float32</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "sims = \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m.    , \u001b[1;36m0.3245\u001b[0m, \u001b[1;36m0.4171\u001b[0m, \u001b[1;36m0.7185\u001b[0m, \u001b[1;36m0\u001b[0m.    , \u001b[1;36m0\u001b[0m.    , \u001b[1;36m0\u001b[0m.    , \u001b[1;36m0\u001b[0m.    ,\n",
       "       \u001b[1;36m0\u001b[0m.    \u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "\n",
    "# Prepare for similarity search\n",
    "num_features: int = 12  # number of features (dimensions)\n",
    "corpus_vector: list[tuple[int, float]] = tfidf[bow_corpus]\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(\n",
    "    corpus=corpus_vector, num_features=num_features\n",
    ")\n",
    "\n",
    "query_doc: list[str] = \"System engineering\".lower().split()\n",
    "query_doc_bow: list[tuple[int, int]] = dictionary.doc2bow(query_doc)\n",
    "query_doc_vector: list[tuple[int, float]] = tfidf[query_doc_bow]\n",
    "sims: list[tuple[int, float]] = index[query_doc_vector]\n",
    "console.print(f\"{sims = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Human machine interface for lab abc computer applications',\n",
      " 'A survey of user opinion of computer system response time',\n",
      " 'The EPS user interface management system',\n",
      " 'System and human system engineering testing of EPS',\n",
      " 'Relation of user perceived response time to error measurement',\n",
      " 'The generation of random binary unordered trees',\n",
      " 'The intersection graph of paths in trees',\n",
      " 'Graph minors IV Widths of trees and well quasi ordering',\n",
      " 'Graph minors A survey']\n"
     ]
    }
   ],
   "source": [
    "# Compare `text_corpus` with `sims`\n",
    "pprint(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc 3: similarity=0.718481\n",
      "doc 2: similarity=0.417076\n",
      "doc 1: similarity=0.324487\n",
      "doc 0: similarity=0.000000\n",
      "doc 4: similarity=0.000000\n",
      "doc 5: similarity=0.000000\n",
      "doc 6: similarity=0.000000\n",
      "doc 7: similarity=0.000000\n",
      "doc 8: similarity=0.000000\n"
     ]
    }
   ],
   "source": [
    "# Sort\n",
    "for idx, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"doc {idx}: similarity={score:4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "#### Loading Data Effciently\n",
    "\n",
    "- Streaming data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_open import open  # for transparently opening remote files\n",
    "\n",
    "\n",
    "# Copied from https://radimrehurek.com/gensim/tut1.html\n",
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        for line in open(\"https://radimrehurek.com/mycorpus.txt\"):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCorpus:\n",
    "    def __init__(self, text: str = \"text\") -> None:\n",
    "        self.text = text\n",
    "        self.data: pl.LazyFrame = pl.scan_csv(\"../../data/test.csv\").select([self.text])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        for row in self.data.collect().iter_rows(named=True):\n",
    "            text: str = row[self.text]\n",
    "            yield dictionary.doc2bow(text.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCustomCorpus()\n"
     ]
    }
   ],
   "source": [
    "corpus_memory_friendly: MyCustomCorpus = MyCustomCorpus(text=\"text\")\n",
    "\n",
    "print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "stopwords: set[str] = set(\"i is for a of the and to in on my\".split())\n",
    "df: pl.DataFrame = pl.read_csv(\"../../data/test.csv\")\n",
    "processed_corpus: list[list[str]] = [\n",
    "    line.lower().split() for line in df[\"text\"].to_list()\n",
    "]\n",
    "\n",
    "dictionary: Dictionary = Dictionary(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1)]\n",
      "[(5, 1), (6, 2), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)]\n",
      "[(6, 4), (8, 1), (20, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)]\n"
     ]
    }
   ],
   "source": [
    "for idx, vec in enumerate(corpus_memory_friendly):\n",
    "    if idx < 3:\n",
    "        print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<10 unique tokens: ['messi', 'soccer', 'jesus', 'team', 'has']...>\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing\n",
    "fp: str = \"../../data/test.csv\"\n",
    "df: pl.DataFrame = pl.read_csv(fp)\n",
    "processed_corpus: list[list[str]] = [\n",
    "    line.lower().split() for line in df[\"text\"].to_list()\n",
    "]\n",
    "\n",
    "dictionary: Dictionary = Dictionary(processed_corpus)\n",
    "\n",
    "# Extract the ids of the stopwords\n",
    "stop_ids: list[int] = [\n",
    "    dictionary.token2id[s_word] for s_word in stopwords if s_word in dictionary.token2id\n",
    "]\n",
    "\n",
    "# Extract ids of words with frequency less than 2\n",
    "low_frequency_ids: list[int] = [\n",
    "    tokenid for tokenid, docfreq in dictionary.dfs.items() if docfreq < 2\n",
    "]\n",
    "# Remove the ids\n",
    "dictionary.filter_tokens(stop_ids + low_frequency_ids)\n",
    "\n",
    "# Remove gaps in id sequence after words are filtered\n",
    "dictionary.compactify()\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Corpus Formats\n",
    "\n",
    "- Gensim serially processes `Vector Space` corpus files, reading/writing one document at a time without loading the entire corpus into memory.\n",
    "\n",
    "#### Save Corpus\n",
    "\n",
    "- One of the more notable file formats is the `Market Matrix` format. To save a corpus in the Matrix Market format:\n",
    "\n",
    "```py\n",
    "# Create a toy corpus of 2 documents, as a plain Python list\n",
    "# make one document empty, for the heck of it\n",
    "corpus: list[list[tuple[int, float]]] = [[(1, 0.5)], []]  \n",
    "\n",
    "# Save the corpus in Matrix Market format\n",
    "corpora.MmCorpus.serialize('/tmp/corpus.mm', corpus)\n",
    "```\n",
    "\n",
    "- Other formats include:\n",
    "  - `Joachim’s SVMlight` format\n",
    "  - `Blei’s LDA-C` format\n",
    "  - `GibbsLDA++` format.\n",
    "\n",
    "```py\n",
    "corpora.SvmLightCorpus.serialize('/tmp/corpus.svmlight', corpus)\n",
    "corpora.BleiCorpus.serialize('/tmp/corpus.lda-c', corpus)\n",
    "corpora.LowCorpus.serialize('/tmp/corpus.low', corpus)\n",
    "```\n",
    "\n",
    "#### Load The Corpus\n",
    "\n",
    "- Conversely, to load a corpus iterator from a Matrix Market file:\n",
    "\n",
    "```py\n",
    "corpus = corpora.MmCorpus('/tmp/corpus.mm')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatibility With NumPy And SciPy\n",
    "\n",
    "- Gensim also contains efficient utility functions to help converting from/to numpy matrices.\n",
    "\n",
    "```py\n",
    "import gensim\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "# random matrix as an example\n",
    "numpy_matrix: np.ndarray = np.random.randint(10, size=[5, 2])  \n",
    "corpus = gensim.matutils.Dense2Corpus(numpy_matrix)\n",
    "\n",
    "# convert from gensim corpus to numpy matrix\n",
    "numpy_matrix = gensim.matutils.corpus2dense(corpus, num_terms=number_of_corpus_features)\n",
    "```\n",
    "<br>\n",
    "\n",
    "#### From/to scipy.sparse matrices\n",
    "\n",
    "\n",
    "```py\n",
    "import scipy.sparse\n",
    "\n",
    "# random sparse matrix as an example\n",
    "scipy_sparse_matrix = scipy.sparse.random(5, 2)  # random sparse matrix as example\n",
    "corpus = gensim.matutils.Sparse2Corpus(scipy_sparse_matrix)\n",
    "scipy_csc_matrix = gensim.matutils.corpus2csc(corpus)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading And Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'0.600*\"messi\" + 0.557*\"soccer\" + 0.339*\"jesus\" + 0.290*\"team\" + 0.274*\"has\" + 0.234*\"religion\" + </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">-0.000*\"religious\" + -0.000*\"together.\" + -0.000*\"are\" + -0.000*\"prayer\"'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'-0.500*\"together.\" + -0.500*\"prayer\" + -0.500*\"religious\" + -0.500*\"are\" + -0.000*\"team\" + 0.000*\"jesus\" +</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">0.000*\"religion\" + -0.000*\"has\" + 0.000*\"soccer\" + -0.000*\"messi\"'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[32m'0.600*\"messi\" + 0.557*\"soccer\" + 0.339*\"jesus\" + 0.290*\"team\" + 0.274*\"has\" + 0.234*\"religion\" + \u001b[0m\n",
       "\u001b[32m-0.000*\"religious\" + -0.000*\"together.\" + -0.000*\"are\" + -0.000*\"prayer\"'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'-0.500*\"together.\" + -0.500*\"prayer\" + -0.500*\"religious\" + -0.500*\"are\" + -0.000*\"team\" + 0.000*\"jesus\" +\u001b[0m\n",
       "\u001b[32m0.000*\"religion\" + -0.000*\"has\" + 0.000*\"soccer\" + -0.000*\"messi\"'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim.interfaces import TransformedCorpus\n",
    "\n",
    "\n",
    "doc_bow: list[list[tuple[int, int]]] = [\n",
    "    dictionary.doc2bow(text) for text in processed_corpus\n",
    "]\n",
    "tfidf_model: models.TfidfModel = models.TfidfModel(dictionary=dictionary)\n",
    "corpus_tfidf: TransformedCorpus = tfidf_model[doc_bow]\n",
    "\n",
    "lsi_model: models.LsiModel = models.LsiModel(\n",
    "    corpus=corpus_tfidf, id2word=dictionary, num_topics=2\n",
    ")\n",
    "corpus_lsi: TransformedCorpus = lsi_model[corpus_tfidf]\n",
    "\n",
    "# lsi_model.show_topics()\n",
    "console.print(lsi_model.print_topics(num_topics=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment\n",
    "\n",
    "```text\n",
    "(0, '0.600*\"messi\" + 0.557*\"soccer\" + 0.339*\"jesus\" + 0.290*\"team\" + 0.274*\"has\" + 0.234*\"religion\" + 0.000*\"religious\" + 0.000*\"are\" + 0.000*\"prayer\" + 0.000*\"together.\"')\n",
    "\n",
    "- This means that for topic 0, `messi`, `soccer`, `jesus`, `team`, `has`, `religion` are all related words and contribute the most to the topic.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.7975568794650277)] | ['messi', 'is', 'the', 'best', 'soccer', 'player', 'in', 'the', 'world.']\n",
      "[(0, 0.5700679546502856)] | ['the', 'soccer', 'field', 'became', 'a', 'sacred', 'ground', 'for', 'the', 'local', 'community', 'and', 'a', 'way', 'to', 'glorify', 'jesus', 'christ.']\n",
      "[(0, 0.2898015362972963)] | ['a', 'divine', 'goal', 'changed', 'the', 'fate', 'of', 'the', 'underdog', 'team', 'thanks', 'to', 'the', 'great', 'passion', 'of', 'the', 'players.']\n",
      "[(0, 0.7975568794650277)] | ['soccer', 'players', 'prayed', 'together', 'before', 'a', 'crucial', 'match.', 'e.g.', 'messi']\n",
      "[(0, 0.5782949666969807)] | ['soccer', 'has', 'a', 'global', 'community.', 'the', 'team', 'was', 'awarded', 'a', 'medal.']\n",
      "[(0, 0.35962602219085765)] | ['religion', 'has', 'been', 'a', 'guiding', 'force', 'in', 'my', 'life,', 'helping', 'me', 'make', 'important', 'decisions.', 'thank', 'you', 'lord']\n",
      "[(1, -0.8660254037844388)] | ['prayer', 'and', 'meditation', 'are', 'essential', 'parts', 'of', 'my', 'religious', 'practice.']\n",
      "[(1, -0.7071067811865481)] | ['prayer', 'is', 'the', 'key.', 'do', 'not', 'forget', 'to', 'pray', 'together.']\n",
      "[(0, 0.4049990827491782)] | ['every', 'tongue', 'will', 'shout', 'that', 'jesus', 'is', 'the', 'lord.', 'religion', 'is', 'the', 'key', 'to', 'success.']\n",
      "[(1, -0.8660254037844389)] | ['religious', 'holidays', '(religion)', 'are', 'times', 'of', 'joy', 'and', 'reflection,', 'bringing', 'families', 'closer', 'together.']\n"
     ]
    }
   ],
   "source": [
    "for doc, as_text in zip(corpus_lsi, processed_corpus):\n",
    "    print(f\"{doc} | {as_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Comment\n",
    "\n",
    "```text\n",
    "Topic 0: Probably about soccer.\n",
    "(0, 0.7975568794650282)] | ['messi', 'is', 'the', 'best', 'soccer', 'player', 'in', 'the', 'world.']\n",
    "[(0, 0.5700679546502856)] | ['the', 'soccer', 'field', 'became', 'a', 'sacred', 'ground', 'for', 'the', 'local', 'community', 'and', 'a', 'way', 'to', 'glorify', 'jesus', 'christ.']\n",
    "\n",
    "# Topic 1: Probably about prayer/religious practice.\n",
    "[(1, 0.8660254037844384)] | ['prayer', 'and', 'meditation', 'are', 'essential', 'parts', 'of', 'my', 'religious', 'practice.']\n",
    "[(1, 0.7071067811865475)] | ['prayer', 'is', 'the', 'key.', 'do', 'not', 'forget', 'to', 'pray', 'together.']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "\n",
    "#### Save The Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LSI model\n",
    "lsi_model.save(\"../../models/lsi_model.lsi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'0.600*\"messi\" + 0.557*\"soccer\" + 0.339*\"jesus\" + 0.290*\"team\" + 0.274*\"has\" + 0.234*\"religion\" + </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">-0.000*\"religious\" + -0.000*\"together.\" + -0.000*\"are\" + -0.000*\"prayer\"'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'-0.500*\"together.\" + -0.500*\"prayer\" + -0.500*\"religious\" + -0.500*\"are\" + -0.000*\"team\" + 0.000*\"jesus\" +</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">0.000*\"religion\" + -0.000*\"has\" + 0.000*\"soccer\" + -0.000*\"messi\"'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[32m'0.600*\"messi\" + 0.557*\"soccer\" + 0.339*\"jesus\" + 0.290*\"team\" + 0.274*\"has\" + 0.234*\"religion\" + \u001b[0m\n",
       "\u001b[32m-0.000*\"religious\" + -0.000*\"together.\" + -0.000*\"are\" + -0.000*\"prayer\"'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'-0.500*\"together.\" + -0.500*\"prayer\" + -0.500*\"religious\" + -0.500*\"are\" + -0.000*\"team\" + 0.000*\"jesus\" +\u001b[0m\n",
       "\u001b[32m0.000*\"religion\" + -0.000*\"has\" + 0.000*\"soccer\" + -0.000*\"messi\"'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_lsi_model = models.LsiModel.load(\"../../models/lsi_model.lsi\")\n",
    "console.print(loaded_lsi_model.print_topics(num_topics=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Similarity Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type annotations\n",
    "from typing import TypeAlias, TypeVar\n",
    "\n",
    "\n",
    "BoW: TypeAlias = list[list[tuple[int, int]]]\n",
    "Corpus: TypeAlias = list[list[str]]\n",
    "VectorCorpus: TypeAlias = list[list[tuple[int, float]]]\n",
    "\n",
    "text_corpus: list[str] = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]\n",
    "\n",
    "# Create a set of frequent words\n",
    "stopwords: set[str] = set(\"for a of the and to in\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...>\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing\n",
    "processed_corpus: Corpus = [line.lower().split() for line in text_corpus]\n",
    "\n",
    "dictionary: Dictionary = Dictionary(processed_corpus)\n",
    "\n",
    "# Extract the ids of the stopwords\n",
    "stop_ids: list[int] = [\n",
    "    dictionary.token2id[s_word] for s_word in stopwords if s_word in dictionary.token2id\n",
    "]\n",
    "\n",
    "# Extract ids of words with frequency less than 2\n",
    "low_frequency_ids: list[int] = [\n",
    "    tokenid for tokenid, docfreq in dictionary.dfs.items() if docfreq < 2\n",
    "]\n",
    "# Remove the ids\n",
    "dictionary.filter_tokens(stop_ids + low_frequency_ids)\n",
    "\n",
    "# Remove gaps in id sequence after words are filtered\n",
    "dictionary.compactify()\n",
    "print(dictionary)\n",
    "\n",
    "corpus_bow: BoW = [dictionary.doc2bow(text) for text in processed_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel, TfidfModel\n",
    "\n",
    "\n",
    "# LSI is a transformation that finds patterns between words and topics by\n",
    "# mapping documents into a lower-dimensional space.\n",
    "lsi_model: LsiModel = LsiModel(corpus=corpus_bow, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_lsi = [(0, 0.46182100453271574), (1, -0.07002766527900064)]\n"
     ]
    }
   ],
   "source": [
    "# Rank nine documents by semantic similarity to the query \"Human computer interaction\",\n",
    "# ignoring external factors and focusing solely on word relationships within the text.\n",
    "doc: str = \"Human computer interaction\"\n",
    "vec_bow: BoW = dictionary.doc2bow(doc.lower().split())\n",
    "\n",
    "# Convert the query to LSI space.\n",
    "vec_lsi: VectorCorpus = lsi_model[vec_bow]\n",
    "print(f\"{vec_lsi = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Query Structures\n",
    "\n",
    "- To prepare for similarity queries, we need to enter all documents which we want to compare against subsequent queries.\n",
    "- In our case, they are the same nine documents used for training LSI, converted to 2-D LSA space. But that’s only incidental, we might also be indexing a different corpus altogether.\n",
    "\n",
    "**Warning ⚠️ !!**\n",
    "\n",
    "- The class `similarities.MatrixSimilarity` is only appropriate when the whole set of vectors fits into memory.\n",
    "- For example, a corpus of one million documents would require 2GB of RAM in a 256-dimensional LSI space, when used with this class.\n",
    "- Without 2GB of free RAM, you would need to use the `similarities.Similarity` class (more effi cient) instead.\n",
    "- This class operates in fixed memory, by splitting the index across multiple files on disk, called shards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9981  0.9375  0.9984  0.9866  0.9076 -0.1242 -0.1064 -0.0988  0.05  ]\n"
     ]
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "\n",
    "# Transform to LSIspace and index for quering\n",
    "index = similarities.MatrixSimilarity(lsi_model[corpus_bow])\n",
    "\n",
    "# === Persit and load index ===\n",
    "# index.save('index.index')\n",
    "# index = similarities.MatrixSimilarity.load('index.index')\n",
    "\n",
    "# === Calculate simularity ===\n",
    "sims: list[int] = index[vec_lsi]\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: Human computer interaction\n",
      "\n",
      "idx: 2 | similarity: 0.9984452724456787| The EPS user interface management system\n",
      "idx: 0 | similarity: 0.9980930089950562| Human machine interface for lab abc computer applications\n",
      "idx: 3 | similarity: 0.9865885972976685| System and human system engineering testing of EPS\n",
      "idx: 1 | similarity: 0.9374863505363464| A survey of user opinion of computer system response time\n",
      "idx: 4 | similarity: 0.9075594544410706| Relation of user perceived response time to error measurement\n",
      "idx: 8 | similarity: 0.050041764974594116| Graph minors A survey\n",
      "idx: 7 | similarity: -0.09879463911056519| Graph minors IV Widths of trees and well quasi ordering\n",
      "idx: 6 | similarity: -0.10639259219169617| The intersection graph of paths in trees\n",
      "idx: 5 | similarity: -0.12416791915893555| The generation of random binary unordered trees\n"
     ]
    }
   ],
   "source": [
    "# Format the result\n",
    "sorted_sims: tuple[int, float] = sorted(\n",
    "    enumerate(sims), key=lambda x: x[1], reverse=True\n",
    ")\n",
    "print(f\"query: {doc}\\n\")\n",
    "for idx, score in sorted_sims:\n",
    "    print(f\"idx: {idx} | similarity: {score}| {text_corpus[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment\n",
    "\n",
    "- The `EPS user interface management system` is directly related to `Human Computer Interaction` (HCI).\n",
    "- HCI is the study of how humans interact with computers.\n",
    "- A user interface management system is a software component specifically designed to create and manage the interaction between a user and a computer.\n",
    "- Even though there's no specific keyword match betweeen `EPS user interface management system` and `HCI`, the relationship between the two is still relevant because LSI uses semantic relatiohsips to find relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: Human computer interaction\n",
      "\n",
      "idx: 0 | similarity: 0.8164965510368347| Human machine interface for lab abc computer applications\n",
      "idx: 3 | similarity: 0.3477731943130493| System and human system engineering testing of EPS\n",
      "idx: 1 | similarity: 0.3141290247440338| A survey of user opinion of computer system response time\n",
      "idx: 2 | similarity: 0.0| The EPS user interface management system\n",
      "idx: 4 | similarity: 0.0| Relation of user perceived response time to error measurement\n",
      "idx: 5 | similarity: 0.0| The generation of random binary unordered trees\n",
      "idx: 6 | similarity: 0.0| The intersection graph of paths in trees\n",
      "idx: 7 | similarity: 0.0| Graph minors IV Widths of trees and well quasi ordering\n",
      "idx: 8 | similarity: 0.0| Graph minors A survey\n"
     ]
    }
   ],
   "source": [
    "# Using TF-IDF\n",
    "tfidf_model: TfidfModel = TfidfModel(\n",
    "    corpus=corpus_bow,\n",
    "    dictionary=dictionary,\n",
    ")\n",
    "vec_bow: BoW = tfidf_model[vec_bow]\n",
    "\n",
    "index_tfidf = similarities.SparseMatrixSimilarity(\n",
    "    tfidf_model[corpus_bow], num_features=len(dictionary)\n",
    ")\n",
    "\n",
    "# Calculate similarity\n",
    "sims_tfidf: list[float] = index_tfidf[vec_bow]\n",
    "\n",
    "# Format the result\n",
    "sorted_sims_tfidf: tuple[int, float] = sorted(\n",
    "    enumerate(sims_tfidf), key=lambda x: x[1], reverse=True\n",
    ")\n",
    "print(f\"query: {doc}\\n\")\n",
    "for idx, score in sorted_sims_tfidf:\n",
    "    print(f\"idx: {idx} | similarity: {score}| {text_corpus[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec / Paragraph Vector\n",
    "\n",
    "- `Doc2Vec` is a model (in Gensim) that creates vector representations of documents. i.e. it learns to map documents into a continuous vector space, similar to how `Word2Vec` maps words into a vector space.   \n",
    "\n",
    "#### Key points about Doc2Vec\n",
    "\n",
    "- Document as a Vector: Each document is represented as a dense vector, capturing its semantic and syntactic information.\n",
    "   \n",
    "- Neural Network Architecture: Doc2Vec uses a neural network architecture to learn these vector representations.\n",
    "   \n",
    "- Two Training Methods: There are two primary training methods:\n",
    "  - `Distributed Memory (DM)`: Predicts the current word based on the document vector and surrounding words.\n",
    "  - `Distributed Bag of Words (DBOW)`: Predicts the document based on randomly sampled words from the document.\n",
    "\n",
    "- Applications: Doc2Vec is widely used in tasks like `document similarity`, `clustering`, `classification`, and `recommendation systems`.\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "#### Prepare The Training And Test Data\n",
    "\n",
    "- For this tutorial, we’ll be training our model using the `Lee Background Corpus` included in gensim.\n",
    "- This corpus contains 314 documents selected from the Australian Broadcasting Corporation’s news mail service, which provides text e-mails of headline stories and covers a number of broad topics.\n",
    "- We’ll test our model by eye using the much shorter `Lee Corpus` which contains 50 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lee_train_file='/Users/neidu/miniconda3/envs/torch_p11/lib/python3.11/site-packages/gensim/test/test_data/lee_background.cor'\n",
      "lee_test_file='/Users/neidu/miniconda3/envs/torch_p11/lib/python3.11/site-packages/gensim/test/test_data/lee.cor'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set file names for train and test data\n",
    "test_data_dir: str = os.path.join(gensim.__path__[0], \"test\", \"test_data\")\n",
    "lee_train_file: str = os.path.join(test_data_dir, \"lee_background.cor\")\n",
    "lee_test_file: str = os.path.join(test_data_dir, \"lee.cor\")\n",
    "\n",
    "print(f\"{lee_train_file=}\\n{lee_test_file=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open\n",
    "from typing import List, Union, Iterator\n",
    "\n",
    "\n",
    "def read_corpus(\n",
    "    fname: str, tokens_only: bool = False\n",
    ") -> Iterator[Union[List[str], gensim.models.doc2vec.TaggedDocument]]:\n",
    "    \"\"\"\n",
    "    Read and process a corpus from a file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        The file name or path of the corpus.\n",
    "    tokens_only : bool, optional\n",
    "        If True, return only tokens. If False, return TaggedDocument objects.\n",
    "        Default is False.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    Union[List[str], gensim.models.doc2vec.TaggedDocument]\n",
    "        If tokens_only is True, yields a list of tokens for each line.\n",
    "        If tokens_only is False, yields a TaggedDocument object for each line.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function reads the file line by line, tokenizes each line,\n",
    "    and yields either a list of tokens or a TaggedDocument object.\n",
    "    \"\"\"\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # Convert a document into a list of lowercase tokens, ignoring tokens\n",
    "            # that are too short or too long\n",
    "            tokens: List[str] = gensim.utils.simple_preprocess(\n",
    "                line, min_len=2, max_len=15\n",
    "            )\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus: list[gensim.models.doc2vec.TaggedDocument] = list(\n",
    "    read_corpus(lee_train_file)\n",
    ")\n",
    "test_corpus: list[list[str]] = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_corpus[:2] = [TaggedDocument(words=['hundreds', 'of', 'people', 'have', 'been', 'forced', 'to', 'vacate', 'their', 'homes', 'in', 'the', 'southern', 'highlands', 'of', 'new', 'south', 'wales', 'as', 'strong', 'winds', 'today', 'pushed', 'huge', 'bushfire', 'towards', 'the', 'town', 'of', 'hill', 'top', 'new', 'blaze', 'near', 'goulburn', 'south', 'west', 'of', 'sydney', 'has', 'forced', 'the', 'closure', 'of', 'the', 'hume', 'highway', 'at', 'about', 'pm', 'aedt', 'marked', 'deterioration', 'in', 'the', 'weather', 'as', 'storm', 'cell', 'moved', 'east', 'across', 'the', 'blue', 'mountains', 'forced', 'authorities', 'to', 'make', 'decision', 'to', 'evacuate', 'people', 'from', 'homes', 'in', 'outlying', 'streets', 'at', 'hill', 'top', 'in', 'the', 'new', 'south', 'wales', 'southern', 'highlands', 'an', 'estimated', 'residents', 'have', 'left', 'their', 'homes', 'for', 'nearby', 'mittagong', 'the', 'new', 'south', 'wales', 'rural', 'fire', 'service', 'says', 'the', 'weather', 'conditions', 'which', 'caused', 'the', 'fire', 'to', 'burn', 'in', 'finger', 'formation', 'have', 'now', 'eased', 'and', 'about', 'fire', 'units', 'in', 'and', 'around', 'hill', 'top', 'are', 'optimistic', 'of', 'defending', 'all', 'properties', 'as', 'more', 'than', 'blazes', 'burn', 'on', 'new', 'year', 'eve', 'in', 'new', 'south', 'wales', 'fire', 'crews', 'have', 'been', 'called', 'to', 'new', 'fire', 'at', 'gunning', 'south', 'of', 'goulburn', 'while', 'few', 'details', 'are', 'available', 'at', 'this', 'stage', 'fire', 'authorities', 'says', 'it', 'has', 'closed', 'the', 'hume', 'highway', 'in', 'both', 'directions', 'meanwhile', 'new', 'fire', 'in', 'sydney', 'west', 'is', 'no', 'longer', 'threatening', 'properties', 'in', 'the', 'cranebrook', 'area', 'rain', 'has', 'fallen', 'in', 'some', 'parts', 'of', 'the', 'illawarra', 'sydney', 'the', 'hunter', 'valley', 'and', 'the', 'north', 'coast', 'but', 'the', 'bureau', 'of', 'meteorology', 'claire', 'richards', 'says', 'the', 'rain', 'has', 'done', 'little', 'to', 'ease', 'any', 'of', 'the', 'hundred', 'fires', 'still', 'burning', 'across', 'the', 'state', 'the', 'falls', 'have', 'been', 'quite', 'isolated', 'in', 'those', 'areas', 'and', 'generally', 'the', 'falls', 'have', 'been', 'less', 'than', 'about', 'five', 'millimetres', 'she', 'said', 'in', 'some', 'places', 'really', 'not', 'significant', 'at', 'all', 'less', 'than', 'millimetre', 'so', 'there', 'hasn', 'been', 'much', 'relief', 'as', 'far', 'as', 'rain', 'is', 'concerned', 'in', 'fact', 'they', 've', 'probably', 'hampered', 'the', 'efforts', 'of', 'the', 'firefighters', 'more', 'because', 'of', 'the', 'wind', 'gusts', 'that', 'are', 'associated', 'with', 'those', 'thunderstorms'], tags=[0]), TaggedDocument(words=['indian', 'security', 'forces', 'have', 'shot', 'dead', 'eight', 'suspected', 'militants', 'in', 'night', 'long', 'encounter', 'in', 'southern', 'kashmir', 'the', 'shootout', 'took', 'place', 'at', 'dora', 'village', 'some', 'kilometers', 'south', 'of', 'the', 'kashmiri', 'summer', 'capital', 'srinagar', 'the', 'deaths', 'came', 'as', 'pakistani', 'police', 'arrested', 'more', 'than', 'two', 'dozen', 'militants', 'from', 'extremist', 'groups', 'accused', 'of', 'staging', 'an', 'attack', 'on', 'india', 'parliament', 'india', 'has', 'accused', 'pakistan', 'based', 'lashkar', 'taiba', 'and', 'jaish', 'mohammad', 'of', 'carrying', 'out', 'the', 'attack', 'on', 'december', 'at', 'the', 'behest', 'of', 'pakistani', 'military', 'intelligence', 'military', 'tensions', 'have', 'soared', 'since', 'the', 'raid', 'with', 'both', 'sides', 'massing', 'troops', 'along', 'their', 'border', 'and', 'trading', 'tit', 'for', 'tat', 'diplomatic', 'sanctions', 'yesterday', 'pakistan', 'announced', 'it', 'had', 'arrested', 'lashkar', 'taiba', 'chief', 'hafiz', 'mohammed', 'saeed', 'police', 'in', 'karachi', 'say', 'it', 'is', 'likely', 'more', 'raids', 'will', 'be', 'launched', 'against', 'the', 'two', 'groups', 'as', 'well', 'as', 'other', 'militant', 'organisations', 'accused', 'of', 'targetting', 'india', 'military', 'tensions', 'between', 'india', 'and', 'pakistan', 'have', 'escalated', 'to', 'level', 'not', 'seen', 'since', 'their', 'war'], tags=[1])]\n",
      "test_corpus[:2] = [['the', 'national', 'executive', 'of', 'the', 'strife', 'torn', 'democrats', 'last', 'night', 'appointed', 'little', 'known', 'west', 'australian', 'senator', 'brian', 'greig', 'as', 'interim', 'leader', 'shock', 'move', 'likely', 'to', 'provoke', 'further', 'conflict', 'between', 'the', 'party', 'senators', 'and', 'its', 'organisation', 'in', 'move', 'to', 'reassert', 'control', 'over', 'the', 'party', 'seven', 'senators', 'the', 'national', 'executive', 'last', 'night', 'rejected', 'aden', 'ridgeway', 'bid', 'to', 'become', 'interim', 'leader', 'in', 'favour', 'of', 'senator', 'greig', 'supporter', 'of', 'deposed', 'leader', 'natasha', 'stott', 'despoja', 'and', 'an', 'outspoken', 'gay', 'rights', 'activist'], ['cash', 'strapped', 'financial', 'services', 'group', 'amp', 'has', 'shelved', 'million', 'plan', 'to', 'buy', 'shares', 'back', 'from', 'investors', 'and', 'will', 'raise', 'million', 'in', 'fresh', 'capital', 'after', 'profits', 'crashed', 'in', 'the', 'six', 'months', 'to', 'june', 'chief', 'executive', 'paul', 'batchelor', 'said', 'the', 'result', 'was', 'solid', 'in', 'what', 'he', 'described', 'as', 'the', 'worst', 'conditions', 'for', 'stock', 'markets', 'in', 'years', 'amp', 'half', 'year', 'profit', 'sank', 'per', 'cent', 'to', 'million', 'or', 'share', 'as', 'australia', 'largest', 'investor', 'and', 'fund', 'manager', 'failed', 'to', 'hit', 'projected', 'per', 'cent', 'earnings', 'growth', 'targets', 'and', 'was', 'battered', 'by', 'falling', 'returns', 'on', 'share', 'markets']]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{train_corpus[:2] = }\")\n",
    "print(f\"{test_corpus[:2] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import random\n",
    "\n",
    "seed: int = 123\n",
    "random.seed(seed)  # For Python's random module\n",
    "np.random.seed(seed)  # For NumPy's random module\n",
    "\n",
    "dim_size: int = 50  # Dimensionality of the feature vector\n",
    "min_count: int = 2  # Ignores all words with total frequency lower than this.\n",
    "\n",
    "# Init the model\n",
    "doc2vec_model: Doc2Vec = Doc2Vec(\n",
    "    vector_size=dim_size, min_count=min_count, epochs=40, seed=seed\n",
    ")\n",
    "\n",
    "# Build the vocab\n",
    "doc2vec_model.build_vocab(corpus_iterable=train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of times the word `penalty` occured in the vocab\n",
    "doc2vec_model.wv.get_vecattr(\"penalty\", \"count\")\n",
    "\n",
    "# List containing all the unique words in the corpus\n",
    "# doc2vec_model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_examples: int = doc2vec_model.corpus_count\n",
    "epochs: int = doc2vec_model.epochs\n",
    "doc2vec_model.train(\n",
    "    corpus_iterable=train_corpus, total_examples=total_examples, epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_vector = array([ 0.1617, -0.064 ,  0.0245, -0.1187, -0.3686,  0.172 , -0.1902,\n",
      "       -0.2376, -0.3974, -0.3207, -0.0542, -0.1656, -0.2313, -0.1436,\n",
      "       -0.3427,  0.158 ,  0.1501,  0.2184,  0.0466,  0.1842, -0.5212,\n",
      "       -0.0159,  0.1162,  0.2419, -0.0752, -0.253 , -0.0688,  0.1754,\n",
      "       -0.0394,  0.0684,  0.4041, -0.0774, -0.1579,  0.3044,  0.3721,\n",
      "       -0.1467, -0.1522, -0.1126,  0.0626, -0.1506,  0.0231,  0.0877,\n",
      "       -0.0038, -0.0513,  0.0347,  0.0329,  0.0891, -0.2206, -0.2755,\n",
      "       -0.1199], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(123)\n",
    "# Infer vectors of new documents (list of str that must have been tokenized the same way as the training data)\n",
    "# using trained doc2vec model\n",
    "doc_vector: np.ndarray = doc2vec_model.infer_vector(\n",
    "    [\"only\", \"you\", \"can\", \"prevent\", \"forest\", \"fire\"]\n",
    ")\n",
    "\n",
    "# Because the algorithms use randomization, repeated inferences of the same\n",
    "# text yield slightly different vectors.\n",
    "print(f\"{doc_vector = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_corpus[10].words[:5] = ['work', 'is', 'continuing', 'this', 'morning']\n",
      "n_docs = 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"{train_corpus[10].words[:5] = }\")\n",
    "\n",
    "n_docs: int = len(doc2vec_model.dv)\n",
    "print(f\"{n_docs = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example: list[str] = [\"RCIA\", \"CBN\", \"FBI\", \"CIA\"]\n",
    "example.index(\"FBI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model\n",
    "ranks: list = []\n",
    "second_ranks: list = []\n",
    "n_docs: int = len(doc2vec_model.dv)\n",
    "\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector: np.ndarray = doc2vec_model.infer_vector(train_corpus[doc_id].words)\n",
    "    # Calculate cosine similarity of the inferred vector and the vectors of all documents\n",
    "    sims: list[tuple[Any, float]] = doc2vec_model.dv.most_similar(\n",
    "        [inferred_vector], topn=n_docs\n",
    "    )\n",
    "    # Get the position of the document that is most similar to the inferred vector\n",
    "    rank = [docid for docid, _ in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 291, 1: 9}\n",
      "Percentage of correct rank: 97.0000%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "counter: dict[int, int] = dict(Counter(ranks))\n",
    "print(counter)\n",
    "correct_rank: float = (counter.get(0) / len(ranks)) * 100\n",
    "print(f\"Percentage of correct rank: {correct_rank:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (299): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>:\n",
      "\n",
      "MOST (299, 0.9481150507926941): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SECOND-MOST (104, 0.810865581035614): «australian cricket captain steve waugh has supported fast bowler brett lee after criticism of his intimidatory bowling to the south african tailenders in the first test in adelaide earlier this month lee was fined for giving new zealand tailender shane bond an unsportsmanlike send off during the third test in perth waugh says tailenders should not be protected from short pitched bowling these days you re earning big money you ve got responsibility to learn how to bat he said mean there no times like years ago when it was not professional and sort of bowlers code these days you re professional our batsmen work very hard at their batting and expect other tailenders to do likewise meanwhile waugh says his side will need to guard against complacency after convincingly winning the first test by runs waugh says despite the dominance of his side in the first test south africa can never be taken lightly it only one test match out of three or six whichever way you want to look at it so there lot of work to go he said but it nice to win the first battle definitely it gives us lot of confidence going into melbourne you know the big crowd there we love playing in front of the boxing day crowd so that will be to our advantage as well south africa begins four day match against new south wales in sydney on thursday in the lead up to the boxing day test veteran fast bowler allan donald will play in the warm up match and is likely to take his place in the team for the second test south african captain shaun pollock expects much better performance from his side in the melbourne test we still believe that we didn play to our full potential so if we can improve on our aspects the output we put out on the field will be lot better and we still believe we have side that is good enough to beat australia on our day he said»\n",
      "\n",
      "MEDIAN (160, 0.24944031238555908): «french moroccan man has been charged in the united states with conspiracy in the terrorist attacks of september it is the first indictment directly related to the suicide hijackings news of the charge came as president george bush delivered major foreign policy speech zaccarias moussaoui sought flying lessons month before the hijackings attorney general john ashcroft claims he was an active participant in the attacks moussaoui is charged with undergoing the same training receiving the same funding and pledging the same commitment to kill americans as the hijackers he said three months to the day since the attacks and president bush says missile defence is now more essential than ever before we must protect america and our friends against all forms of terror including the terror that could arrive on missile he said president bush says the united states now needs dramatically retooled military armed with hi tech weapons and real time intelligence»\n",
      "\n",
      "LEAST (243, -0.08139593154191971): «four afghan factions have reached agreement on an interim cabinet during talks in germany the united nations says the administration which will take over from december will be headed by the royalist anti taliban commander hamed karzai it concludes more than week of negotiations outside bonn and is aimed at restoring peace and stability to the war ravaged country the year old former deputy foreign minister who is currently battling the taliban around the southern city of kandahar is an ally of the exiled afghan king mohammed zahir shah he will serve as chairman of an interim authority that will govern afghanistan for six month period before loya jirga or grand traditional assembly of elders in turn appoints an month transitional government meanwhile united states marines are now reported to have been deployed in eastern afghanistan where opposition forces are closing in on al qaeda soldiers reports from the area say there has been gun battle between the opposition and al qaeda close to the tora bora cave complex where osama bin laden is thought to be hiding in the south of the country american marines are taking part in patrols around the air base they have secured near kandahar but are unlikely to take part in any assault on the city however the chairman of the joint chiefs of staff general richard myers says they are prepared for anything they are prepared for engagements they re robust fighting force and they re absolutely ready to engage if that required he said»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with an example:\n",
    "doc_id: int = 299\n",
    "\n",
    "print(f'Document ({doc_id}): «{\" \".join(train_corpus[doc_id].words)}»\\n')\n",
    "print(f\"SIMILAR/DISSIMILAR DOCS PER MODEL {doc2vec_model}:\\n\")\n",
    "for label, idx in [\n",
    "    (\"MOST\", 0),\n",
    "    (\"SECOND-MOST\", 1),\n",
    "    (\"MEDIAN\", len(sims) // 2),\n",
    "    (\"LEAST\", len(sims) - 1),\n",
    "]:\n",
    "    print(f'{label} {sims[idx]}: «{\" \".join(train_corpus[sims[idx][0]].words)}»\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on unseen data\n",
    "doc_id: int = 30\n",
    "\n",
    "print(f'Document ({doc_id}): «{\" \".join(train_corpus[doc_id].words)}»\\n')\n",
    "print(f\"SIMILAR/DISSIMILAR DOCS PER MODEL {doc2vec_model}:\\n\")\n",
    "for label, idx in [\n",
    "    (\"MOST\", 0),\n",
    "    (\"SECOND-MOST\", 1),\n",
    "    (\"MEDIAN\", len(sims) // 2),\n",
    "    (\"LEAST\", len(sims) - 1),\n",
    "]:\n",
    "    print(f'{label} {sims[idx]}: «{\" \".join(train_corpus[sims[idx][0]].words)}»\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8844, -0.933 , -2.0421, -1.338 ,  1.407 ,  0.9071, -1.2306,\n",
       "       -3.0632,  1.0605, -0.2622, -6.339 ,  0.2128, -0.765 , -0.3091,\n",
       "       -0.2524,  1.2702,  1.3959,  0.4881, -1.3269,  2.4444, -1.9201,\n",
       "        2.9225, -1.5212, -0.6452, -1.8507, -2.0662,  0.3528,  2.2103,\n",
       "        2.9182, -0.8491, -0.2386,  0.0938,  1.4504, -0.6888,  1.463 ,\n",
       "        0.9431,  0.4018, -0.7214,  4.6556, -1.3448, -0.2358, -1.7588,\n",
       "       -0.2456, -1.5534,  0.1865, -4.4272,  1.9735, -1.9831, -0.6817,\n",
       "       -1.7239], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_str_lengths(20)\n",
    "pl.set_random_seed(seed=123)\n",
    "\n",
    "\n",
    "fp: str = \"../data/articles_final_df.parquet\"\n",
    "articles_df: pl.DataFrame = pl.read_parquet(fp)\n",
    "print(f\"{articles_df.shape = }\")\n",
    "articles_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pl.DataFrame = pl.DataFrame(\n",
    "    {\n",
    "        \"id\": np.arange(0, 10),\n",
    "        \"text\": [\n",
    "            \"Messi is the best soccer player in the world.\",\n",
    "            \"The soccer field became a sacred ground for the local community and a way to glorify Jesus Christ.\",\n",
    "            \"A divine goal changed the fate of the underdog team thanks to the great passion of the players.\",\n",
    "            \"Soccer players prayed together before a crucial match. e.g. Messi\",\n",
    "            \"Soccer has a global community. The team was awarded a medal.\",\n",
    "            \"Religion has been a guiding force in my life, helping me make important decisions. Thank you Lord\",\n",
    "            \"Prayer and meditation are essential parts of my religious practice.\",\n",
    "            \"Prayer is the key. Do not forget to pray together.\",\n",
    "            \"Every tongue will shout that Jesus is the Lord. Religion is the key to success.\",\n",
    "            \"Religious holidays (religion) are times of joy and reflection, bringing families closer together.\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "df.write_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch p_311",
   "language": "python",
   "name": "torch_p11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
