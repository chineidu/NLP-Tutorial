{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs (Recurrent Neural Networks)\n",
    "\n",
    "## Basic RNN\n",
    "## Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "numpy    : 1.26.4\n",
      "pandas   : 2.2.1\n",
      "polars   : 0.20.18\n",
      "mlxtend  : 0.23.1\n",
      "omegaconf: 2.3.0\n",
      "\n",
      "conda environment: torch_p11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,mlxtend,omegaconf --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Literal, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Data\n",
    "\n",
    "- `Sequential data` refers to data that is ordered in a particular sequence or time series.\n",
    "- Each data point in a sequential dataset is `dependent` on the `previous data points`, and the `order` of the data is crucial for understanding the information it contains.\n",
    "- Time series data is sequential data where the order of examples is determined by time. Examples include stock prices and audio recordings.\n",
    "- Not all sequential data is time series. e.g. Text and DNA sequences are ordered but not time-based.\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Recurrent Neural Networks (RNNs)\n",
    "\n",
    "- `RNN` is a type of neural network designed to process sequential data.\n",
    "- Unlike feedforward neural networks that process data in a single pass, RNNs can process data across multiple time steps, making them ideal for tasks involving sequences like text, speech, and time series data.   \n",
    "\n",
    "### Key characteristics of RNNs\n",
    "\n",
    "- **Sequential Processing**: RNNs process data sequentially, allowing them to consider the context of previous inputs when making predictions.   \n",
    "- **Internal Memory**: RNNs have an internal memory, often represented as a hidden state, that stores information about past inputs. This memory allows the network to maintain context and make predictions based on the entire sequence.   \n",
    "- **Feedback Loop**: RNNs have a feedback loop that connects the output of a layer back to its input, creating a cyclic structure. This allows the network to learn long-term dependencies and capture patterns in sequential data.\n",
    "\n",
    "[![image.png](https://i.postimg.cc/3wSPP3Qn/image.png)](https://postimg.cc/cK393yHn)\n",
    "\n",
    "<br>\n",
    "\n",
    "[![image.png](https://i.postimg.cc/dtPzMWgP/image.png)](https://postimg.cc/Dm6CLc2B)\n",
    "\n",
    "### Common Types of Sequencing Tasks\n",
    "\n",
    "- **Many-to-one**: Input is a sequence, output is a fixed-size vector or scalar. Example: Sentiment analysis.\n",
    "- **One-to-many**: Input is standard, output is a sequence. e.g. in image captioning, a single image is given as input to a model, which then produces a sequence of words to describe the image (image caption).\n",
    "- **Many-to-many**: Both input and output are sequences. Can be further divided based on alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Recurrence vs Output Recurrence\n",
    "\n",
    "- **Hidden recurrence**: The recurrent connection is from the hidden layer to itself.\n",
    "- **Output recurrence**: The recurrent connection is from the output layer to either the hidden layer or itself.\n",
    "\n",
    "#### Two Types of Output Recurrence\n",
    "\n",
    "- **Output-to-hidden**: Connection from output layer at previous time step to hidden layer at current time step.\n",
    "- **Output-to-output**: Connection from output layer at previous time step to output layer at current time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "```sh\n",
    "pip install torchtext\n",
    "pip install torchdata\n",
    "pip install portalocker\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.datasets import IMDB\n",
    "\n",
    "from torch.utils.data.dataset import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Tokenize the input text by removing HTML tags, extracting emoticons,\n",
    "    and splitting the text into individual tokens.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The input text to be tokenized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        A list of tokens extracted from the input text.\n",
    "    \"\"\"\n",
    "    text = re.sub(\"<[^>]*>\", \"\", text)\n",
    "    emoticons: list[str] = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text.lower())\n",
    "    text = re.sub(\"[\\W]+\", \" \", text.lower()) + \" \".join(emoticons).replace(\"-\", \"\")\n",
    "    tokenized: list[str] = text.split()\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "train_dataset: list[tuple[int, str]] = list(IMDB(split=\"train\"))\n",
    "test_dataset: list[tuple[int, str]] = list(IMDB(split=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'),\n",
       " (1,\n",
       "  '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset: Subset\n",
    "valid_dataset: Subset\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset=train_dataset, lengths=[0.85, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 71,011\n"
     ]
    }
   ],
   "source": [
    "device: torch.device | str = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "# Find unique tokens (words)\n",
    "token_counts: Counter = Counter()\n",
    "\n",
    "\n",
    "for label, line in train_dataset:\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "\n",
    "print(f\"Vocab-size: {len(token_counts):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seeing': 1801, 'as': 39774, 'i': 74206}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "\n",
    "dict(islice(token_counts.items(), 0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from torchtext import __version__ as torchtext_version\n",
    "from pkg_resources import parse_version\n",
    "import torchtext\n",
    "\n",
    "\n",
    "def create_vocabulary(token_counts: dict[str, int]) -> vocab:\n",
    "    \"\"\"\n",
    "    Create a vocabulary from token counts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    token_counts : dict[str, int]\n",
    "        A dictionary mapping tokens to their frequency counts.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocab\n",
    "        A vocabulary object with special tokens and default index set.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The vocabulary is created by sorting tokens by frequency in descending order,\n",
    "    inserting special tokens '<pad>' and '<unk>', and setting a default index for\n",
    "    out-of-vocabulary tokens.\n",
    "    \"\"\"\n",
    "    # Sort tokens by frequency in descending order\n",
    "    sorted_tokens: list[tuple[str, int]] = sorted(\n",
    "        token_counts.items(), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "\n",
    "    # Create vocab object\n",
    "    vocabulary: vocab = vocab(OrderedDict(sorted_tokens))\n",
    "\n",
    "    # Insert special tokens\n",
    "    vocabulary.insert_token(\"<pad>\", 0)\n",
    "    vocabulary.insert_token(\"<unk>\", 1)\n",
    "\n",
    "    # Set default index for OOV tokens\n",
    "    vocabulary.set_default_index(1)\n",
    "\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "def encode_texts(text: str) -> list[int]:\n",
    "    \"\"\"\n",
    "    Encode a text string into a list of integer token indices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The input text to be encoded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[int]\n",
    "        A list of integer token indices representing the encoded text.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function uses a global `vocabulary` object to map tokens to their\n",
    "    corresponding integer indices. The input text is first tokenized using\n",
    "    a global `tokenizer` function before being encoded.\n",
    "    \"\"\"\n",
    "    global vocabulary\n",
    "\n",
    "    enc_text: list[int] = [vocabulary[token] for token in tokenizer(text)]\n",
    "    return enc_text\n",
    "\n",
    "\n",
    "def encode_labels(label: int | str) -> float:\n",
    "    \"\"\"\n",
    "    Encode labels into binary values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : int or str\n",
    "        The input label to be encoded. Can be either an integer or a string.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The encoded label as a float value (0.0 or 1.0).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    For torchtext versions > 0.10:\n",
    "        - 1 represents a negative review\n",
    "        - 2 represents a positive review\n",
    "    For torchtext versions <= 0.10:\n",
    "        - \"neg\" represents a negative review\n",
    "        - \"pos\" represents a positive review\n",
    "    \"\"\"\n",
    "    # Transform labels into 0 or 1\n",
    "    if parse_version(torchtext_version) > parse_version(\"0.10\"):\n",
    "        # 1 ~ negative, 2 ~ positive review\n",
    "        enc_label: float = 1.0 if label == 2 else 0.0\n",
    "    else:\n",
    "        enc_label: float = 1.0 if label == \"pos\" else 0.0\n",
    "\n",
    "    return enc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 35, 458, 1]\n",
      "[11, 7, 35, 458]\n"
     ]
    }
   ],
   "source": [
    "# Assuming token_counts is defined elsewhere\n",
    "vocabulary: vocab = create_vocabulary(token_counts)\n",
    "\n",
    "# Test the vocabulary\n",
    "test_tokens: list[str] = [\"this\", \"is\", \"an\", \"example\", \"thisTokenDoesNotExist\"]\n",
    "print([vocabulary[token] for token in test_tokens])\n",
    "\n",
    "\n",
    "# Test the encode_texts\n",
    "print(encode_texts(\"this is an example\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions for transformation\n",
    "def collate_fn(\n",
    "    batch: list[tuple[int, str]]\n",
    ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Collate function for processing batches of data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch : list[tuple[int, str]]\n",
    "        A list of tuples containing label (int) and text (str) pairs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n",
    "        A tuple containing:\n",
    "        - padded_texts: torch.Tensor of shape (batch_size, max_seq_length)\n",
    "        - labels: torch.Tensor of shape (batch_size,)\n",
    "        - lengths: torch.Tensor of shape (batch_size,)\n",
    "    \"\"\"\n",
    "    labels: list[int] = []\n",
    "    texts: list[torch.Tensor] = []\n",
    "    lengths: list[int] = []\n",
    "\n",
    "    for _label, _text in batch:\n",
    "        labels.append(encode_labels(_label))\n",
    "        tok_text: torch.Tensor = torch.tensor(encode_texts(_text), dtype=torch.int64)\n",
    "        texts.append(tok_text)\n",
    "        lengths.append(tok_text.size(0))\n",
    "\n",
    "    # Convert to tensor\n",
    "    labels_tensor: torch.Tensor = torch.tensor(labels)\n",
    "    lengths_tensor: torch.Tensor = torch.tensor(lengths)\n",
    "    padded_texts: torch.Tensor = nn.utils.rnn.pad_sequence(\n",
    "        texts, batch_first=True, padding_value=0.0\n",
    "    )\n",
    "\n",
    "    return padded_texts.to(device), labels_tensor.to(device), lengths_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a Small Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_batch = tensor([[ 318,   15,   10,  ...,    0,    0,    0],\n",
      "        [  48,   52,   51,  ...,  598,    2, 1591],\n",
      "        [4793, 8188,  127,  ...,    0,    0,    0],\n",
      "        [  15,    4, 9725,  ...,    0,    0,    0]])\n",
      "label_batch = tensor([0., 1., 0., 1.])\n",
      "length_batch = tensor([156, 864, 835, 541])\n",
      "text_batch.shape = torch.Size([4, 864])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    train_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print(f\"{text_batch = }\")\n",
    "print(f\"{label_batch = }\")\n",
    "print(f\"{length_batch = }\")\n",
    "print(f\"{text_batch.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Batch the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size: int = 32\n",
    "\n",
    "train_dlDataLoader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "valid_dlDataLoader = DataLoader(\n",
    "    valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "test_dlDataLoader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
